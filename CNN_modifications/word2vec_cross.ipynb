{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"word2vec_cross.ipynb","provenance":[{"file_id":"1sZlZWL7aYcsla5wvMM91-ZCkfR_19vG0","timestamp":1589965515847},{"file_id":"1NBK6cBXMzB9eoIWVaYMUZoyMn2zwIHt6","timestamp":1589914460202},{"file_id":"1uQ45aKC1kvpKNW_91iy6tqsoixHScEm8","timestamp":1589912225093},{"file_id":"1yqdy1wAa1K44GBjjCnjhVdfHdzv0FhOd","timestamp":1588956399944}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SH2wpCTYZdMh","colab_type":"code","colab":{}},"source":["import numpy as np\n","import multiprocessing as mp\n","import random,copy,string\n","from nltk.tokenize import word_tokenize\n","from scipy.stats import pearsonr\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.layers import Input, Convolution1D, MaxPooling1D, Flatten\n","from tensorflow.python.keras.layers import Lambda, multiply, concatenate, Dense\n","from tensorflow.python.keras.regularizers import l2\n","from tensorflow.python.keras.callbacks import Callback\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Q_ABwOwnYl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590827391086,"user_tz":-330,"elapsed":1294,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"dacf9fc0-493c-44f3-eeca-ba51d97fb220"},"source":["import os, string, random, time, math\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import torch\n","'''import mlflow\n","import mlflow.pytorch'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import mlflow\\nimport mlflow.pytorch'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"cuP_JYvpMMrF","colab_type":"code","colab":{}},"source":["from numpy import linalg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQcOsPfMJL1-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1590827391089,"user_tz":-330,"elapsed":1252,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"d6cc1533-87c3-4b2c-e6a0-db628e603a41"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"uLz42OGuar31","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1590827391091,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"3bc144b7-f48d-4c90-833b-c8d276a38bd5"},"source":["'''from google.colab import drive\n","drive.mount('/content/drive')'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ae7JCVPfnj-p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1590827391093,"user_tz":-330,"elapsed":1200,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"ae39a138-04d0-4ed5-e8fd-ea03529b9fc9"},"source":["#cd 'drive/My Drive'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive'\n","/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dAPg3_LAoKHs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1590827394644,"user_tz":-330,"elapsed":4722,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"185fcf51-b49c-455c-c533-dd033ce40c1d"},"source":["#ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34m2017_takelab+cnn\u001b[0m/                    processed_takelab_output_MSRpar.txt\n"," \u001b[01;34m2017_takelab_MLP\u001b[0m/                    processed_wv_wlsa.txt\n"," \u001b[01;34m2017_takelab_SVR\u001b[0m/                    processed_wv_wwv.txt\n"," cc.en.300.bin                        sts-dev.csv\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/                    sts-test.csv\n"," fasttext_cross_adam_model.pt         sts-train.csv\n"," fasttext_cross_cnn_code.ipynb        takelab_jc.txt\n"," fasttext_cross_epoch.pt              takelab_lin.txt\n"," fasttext_kl_adamax_model.pt          takelab_output_MSRpar.txt\n"," fasttext_kl_adam_model.pt            temp.ipynb\n"," fasttext_kl_cnn_code.ipynb           temp_word2vec_kl.ipynb\n"," full.txt                             \u001b[01;34mthesis\u001b[0m/\n","'Getting started.pdf'                 word2vec_cross_adam_model.pt\n"," GoogleNews-vectors-negative300.bin   word2vec_cross_cnn_code.ipynb\n"," jc_lin.txt                           word2vec_cross_epoch.pt\n"," model_cifar.pt                       word2vec_kl_cnn_code.ipynb\n"," processed_full.txt                   word2vec_kl_epoch.pt\n"," processed_jc_lin.txt                 word2vec_kl_model.pt\n"," processed_takelab_jc.txt             wv_wlsa.txt\n"," processed_takelab_lin.txt            wv_wwv.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aN1UtOJrZdM5","colab_type":"code","colab":{}},"source":["c = dict()\n","c['num_runs']   = 3\n","c['num_epochs'] = 2\n","c['num_batchs'] = 4\n","c['batch_size'] = 3\n","c['wordvectdim']  = 300\n","c['sentencepad']  = 60\n","c['num_classes']  = 6\n","c['cnnfilters']     = {1: 1800}\n","c['cnninitial']     = 'he_uniform'\n","c['cnnactivate']    = 'relu'\n","c['densedimension'] = list([1800])\n","c['denseinitial']   = 'he_uniform'\n","c['denseactivate']  = 'tanh'\n","c['optimizer']  = 'adam'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI95iihPfWFV","colab_type":"text"},"source":["# Loading word vectors"]},{"cell_type":"code","metadata":{"id":"IG9kzwY1TD_7","colab_type":"code","colab":{}},"source":["import gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkgQV8OJUrBG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1590827429982,"user_tz":-330,"elapsed":40016,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"047a1328-8f29-4275-9e10-7d002853e107"},"source":["word_vector = gensim.models.KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True, unicode_errors='ignore')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vr-1hkKAlgRi","colab_type":"text"},"source":["# Params"]},{"cell_type":"code","metadata":{"id":"F1YZLUtAldcF","colab_type":"code","colab":{}},"source":["class Params(object):\n","  def __init__(self, batch_size, epochs, seed, log_interval):\n","    self.batch_size = batch_size\n","    self.epochs = epochs\n","    self.seed = seed\n","    self.log_interval = log_interval\n","\n","args= Params(16,6,0,8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1oW_df2ZdRk","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"v87IpbJR9gDG","colab_type":"code","colab":{}},"source":["def matrixize(sentencelist, sentencepad):\n","  padding= np.zeros(300)\n","  matrix= np.zeros((len(sentencelist),sentencepad,300 ))\n","  m=0\n","  s=1\n","\n","  for i in range(len(sentencelist)):\n","    for j in range(len(sentencelist[i])):\n","      try:\n","        matrix[i][j]= word_vector[sentencelist[i][j]]\n","      except:\n","        #print(sentencelist[i][j])\n","        matrix[i][j]= np.random.normal(m,s,300)/linalg.norm(np.random.normal(m,s,300) + 1e-8)\n","\n","  return matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdRruMEiZdRt","colab_type":"code","colab":{}},"source":["def _load_data(filename):\n","        s0,s1,labels = [],[],[]\n","        lines=open(filename,'r').read().splitlines()\n","        for line in lines:\n","            _,_,_,_, label, s0x, s1x = line.rstrip().split('\\t')[:7]\n","            labels.append(float(label))\n","            s0.append([word.lower() for word in word_tokenize(s0x) if word not in string.punctuation])\n","            s1.append([word.lower() for word in word_tokenize(s1x) if word not in string.punctuation])\n","\n","        m0 = matrixize(s0, c['sentencepad'])\n","        m1 = matrixize(s1, c['sentencepad'])\n","        classes = np.zeros((len(labels),c['num_classes']))\n","        for i, label in enumerate(labels): # making probability distribution of classes\n","            if np.floor(label) + 1 < c['num_classes']:\n","                classes[i, int(np.floor(label)) + 1] = label - np.floor(label)\n","            classes[i, int(np.floor(label))] = np.floor(label) - label + 1\n","            \n","        return {'labels': labels, 's0': s0, 's1': s1, 'classes': classes, 'm0': m0, 'm1': m1}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vMYnoNCrdNYu","colab_type":"text"},"source":["# Sampling Batch"]},{"cell_type":"code","metadata":{"id":"grGwK-j0-ctQ","colab_type":"code","colab":{}},"source":["def _sample_pairs(data,batch_size):\n","  datacopy={}\n","  for i in data.keys():\n","    datacopy[i]= []\n","  for i in range(batch_size):\n","    index = np.random.randint(len(data['labels']))\n","    #print(index)\n","    for key,value in data.items():\n","      datacopy[key].append(value[index])\n","  datacopy['classes']= torch.tensor(datacopy['classes'])\n","  datacopy['m0']= torch.tensor(datacopy['m0'])\n","  datacopy['m1']= torch.tensor(datacopy['m1'])\n","  return datacopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT33frFDlodS","colab_type":"text"},"source":["# Defining CNN Model"]},{"cell_type":"code","metadata":{"id":"GnxSiUWpl-qn","colab_type":"code","colab":{}},"source":["import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSip9cpbZdTt","colab_type":"code","colab":{}},"source":["class CNN_Model(nn.Module):\n","  def __init__(self,nh=1800):\n","    super(CNN_Model, self).__init__()\n","    self.cnn= nn.Sequential(nn.Conv1d(300,1800,1),              #(bs,300,60) -> (bs, 1800, 60)\n","                            nn.LeakyReLU(0.01),\n","                            nn.MaxPool1d(kernel_size=60))       #(bs,1800,60)-> (bs, 1800, 1)\n","\n","    self.Linear= nn.Sequential(nn.Linear(3600,nh),            #(bs, 3600)  -> (bs, 1800 )\n","                               nn.LeakyReLU(0.01),\n","                               nn.Linear(nh,6),               #(bs,1800)   -> (bs,6)\n","                               nn.Softmax(dim=1))\n","                            \n","    \n","\n","  def forward(self,input1, input2):\n","    input1= self.cnn(input1)\n","    input2= self.cnn(input2)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    input1= torch.flatten(input1,1)\n","    input2= torch.flatten(input2,1)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    absdiff= abs(input1 - input2)\n","    mulDifference= input1 * input2\n","    concatenate = torch.cat((absdiff,mulDifference),1)\n","    #print(concatenate.shape)\n","    output= self.Linear(concatenate)\n","    #print(output.shape)\n","    return (output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qk5XamSwZBra","colab_type":"code","colab":{}},"source":["def weights_init(m):\n","    if isinstance(m, nn.Conv1d) or isinstance(m, torch.nn.Linear):\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        torch.nn.init.zeros_(m.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRUv6bDcmYpE","colab_type":"text"},"source":["# Defining Loss"]},{"cell_type":"code","metadata":{"id":"yx9uWC_TVYND","colab_type":"code","colab":{}},"source":["def _lossfunction(y_true,y_pred):\n","    \n","    #print(\"y_true.shape\",y_true.shape)\n","    #print(\"y_pred.shape\",y_pred.shape)\n","    ny_true = y_true[:,1] + 2*y_true[:,2] + 3*y_true[:,3] + 4*y_true[:,4] + 5*y_true[:,5]\n","    #print(ny_true)\n","    ny_pred = y_pred[:,1] + 2*y_pred[:,2] + 3*y_pred[:,3] + 4*y_pred[:,4] + 5*y_pred[:,5]\n","    #print(ny_pred)\n","    my_true = (ny_true.mean())\n","    #print(my_true)\n","    my_pred = (ny_pred.mean())\n","    #print(my_pred)\n","    var_true = (ny_true - my_true)**2\n","    var_pred = (ny_pred - my_pred)**2\n","    eps= 1e-14\n","    return -torch.sum((ny_true-my_true)*(ny_pred-my_pred),axis=-1) / (torch.sqrt(torch.sum(var_true,axis=-1)* torch.sum(var_pred,axis=-1)+eps))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6g9dYuH9x1Dx","colab_type":"text"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"QxQ4r7AzyWA-","colab_type":"text"},"source":["## Train setup"]},{"cell_type":"code","metadata":{"id":"QCWkAB75yili","colab_type":"code","colab":{}},"source":["def train_batch(net,trainload, opt,batch_size, device= 'cpu'):\n","  \n","  net.train().to(device)\n","  opt.zero_grad()\n","  \n","  \n","\n","  data= _sample_pairs(trainload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  true_output= (data['classes']).to(device,dtype= torch.float32)\n","  pred_output= net(input1,input2).to(torch.float32)\n","  loss= _lossfunction(true_output,pred_output)\n","\n","  #loss= criterion(pred_output,true_output)\n","  loss.backward()\n","  opt.step()\n","  #print(\"lossgf\",loss.item())\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUuqHGuH45FT","colab_type":"text"},"source":["## Validation Setup"]},{"cell_type":"code","metadata":{"id":"M6VfkAYo3RN5","colab_type":"code","colab":{}},"source":["def valid_batch(net,validation, opt,batch_size, device= 'cpu'):\n","  net.eval().to(device)\n","  \n","  data = _sample_pairs(validation,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  true_output= (data['classes']).to(device,dtype= torch.float32)\n","  pred_output= net(input1,input2).to(torch.float32)\n","  loss= _lossfunction(true_output,pred_output)\n","  #loss= criterion(pred_output,true_output)\n","  return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QWJNMId9pJIH","colab_type":"text"},"source":["# Full Training Setup"]},{"cell_type":"markdown","metadata":{"id":"J0cOkFXSb7mP","colab_type":"text"},"source":["## Adam"]},{"cell_type":"code","metadata":{"id":"Y5WzVLt2pPkA","colab_type":"code","colab":{}},"source":["def train_setup_Adam(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adam(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'word2vec_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YULxp2T-Ps9n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590781542087,"user_tz":-330,"elapsed":96544,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"1af12c32-5a8c-4824-ae2d-f5da29fc1319"},"source":["'''net= CNN_Model(1900)\n","train_setup(net, lr= 0.0007,epoch=6)'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'net= CNN_Model(1900)\\ntrain_setup(net, lr= 0.0007,epoch=6)'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"mSXGs0aNc7lB","colab_type":"text"},"source":["## Adadelta"]},{"cell_type":"code","metadata":{"id":"M3_bepxWdCGp","colab_type":"code","colab":{}},"source":["def train_setup_Adadleta(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adadelta(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'word2vec_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qFK1-o0IcCVj","colab_type":"text"},"source":["## Adamw"]},{"cell_type":"code","metadata":{"id":"bNba1PZYcSs7","colab_type":"code","colab":{}},"source":["def train_setup_AdamW(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.AdamW(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'word2vec_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fx0YqyHtcIIE","colab_type":"text"},"source":["## Adamax"]},{"cell_type":"code","metadata":{"id":"wWi94FnrdN4k","colab_type":"code","colab":{}},"source":["def train_setup_Adamax(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adamax(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(),'word2vec_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bbhRIxNcLiY","colab_type":"text"},"source":["## RMS prop"]},{"cell_type":"code","metadata":{"id":"TdQzIAL_daxS","colab_type":"code","colab":{}},"source":["def train_setup_Adamw(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.RMSprop(net.parameters(), lr=lr, momentum= momentum)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'word2vec_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3lxuhFAopUC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590781542092,"user_tz":-330,"elapsed":96503,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"9989ee40-8594-410b-c031-0f9c087272eb"},"source":["'''net= CNN_Model()\n","train_setup(net,device='cuda:0')'''\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"net= CNN_Model()\\ntrain_setup(net,device='cuda:0')\""]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"-dkld6lIWW8b","colab_type":"text"},"source":["# Evaluate"]},{"cell_type":"markdown","metadata":{"id":"2GQzXlEi-XHH","colab_type":"text"},"source":["## Evaluation Setup"]},{"cell_type":"code","metadata":{"id":"SkXPty0k-h9O","colab_type":"code","colab":{}},"source":["def eval_setup(net,batch_size = 1379, device = 'cpu'):\n","  \n","  net.load_state_dict(torch.load('word2vec_cross_epoch.pt'))\n","  net.eval().to(device)\n","  testload= _load_data('sts-test.csv')\n","  test_n_batch= int(len(testload['labels'])/batch_size)\n","  #print(len(testload['labels']))\n","  test_loss_arr = np.zeros(test_n_batch+ 1)\n","\n","\n","  data= _sample_pairs(testload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  pred_output= (net(input1,input2)).to('cpu')\n","  pred= pred_output.detach().numpy()\n","  prediction = np.dot(np.array(pred),np.arange(c['num_classes']))\n","  print('pred_shape',prediction.shape)\n","  goldlabels = data['labels']\n","  result=round((pearsonr(prediction, goldlabels)[0]),4)\n","  print(\"result\",result)\n","\n","  return result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDkaR6L8Sc6s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590781542094,"user_tz":-330,"elapsed":96477,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"edc23f7e-52cb-4b87-e73b-fc93f3a0fdcc"},"source":["'''net=CNN_Model(1800)\n","eval_setup(net,device = 'cuda:0')'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"net=CNN_Model(1800)\\neval_setup(net,device = 'cuda:0')\""]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"uACzDtuiU-_k","colab_type":"text"},"source":["# Hyper-parameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"p9X9B22WZX9Q","colab_type":"text"},"source":["## optim.sgd"]},{"cell_type":"code","metadata":{"id":"ZDX421f0VWRP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1590524777243,"user_tz":-330,"elapsed":138863,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"c5718fe2-e43c-4ad6-8225-041ba0ee1541"},"source":["\n","\n","'''for learning_rate in [0.01]:                    #with 0.001(try big momentum)\n","    for momemtum in [0.09,0.087]:\n","        for hidden_nodes in [1800]:\n","        \n","          expt_id = '%d_%d_%d' % (int(learning_rate*100), int(momemtum*100), hidden_nodes)\n","          print('\\nLR = %.4f, Momentum = %.4f, Hidden nodes = %d\\n' % (learning_rate, momemtum, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup(model,lr=learning_rate,momentum= momemtum ,device='cuda:0',epoch= args.epochs)\n","          eval_setup(model,device = 'cuda:0')'''\n","\n","            \n","\n","          \n","\n","          \n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"for learning_rate in [0.01]:                    #with 0.001(try big momentum)\\n    for momemtum in [0.09,0.087]:\\n        for hidden_nodes in [1800]:\\n        \\n          expt_id = '%d_%d_%d' % (int(learning_rate*100), int(momemtum*100), hidden_nodes)\\n          print('\\nLR = %.4f, Momentum = %.4f, Hidden nodes = %d\\n' % (learning_rate, momemtum, hidden_nodes))\\n\\n          model = CNN_Model(hidden_nodes)\\n          train_setup(model,lr=learning_rate,momentum= momemtum ,device='cuda:0',epoch= args.epochs)\\n          eval_setup(model,device = 'cuda:0')\""]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"xgdyqp0tZbt9","colab_type":"text"},"source":["##optim.adam"]},{"cell_type":"code","metadata":{"id":"YLNYDRpUZfR4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590784449855,"user_tz":-330,"elapsed":2783244,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"8eb1da5d-7efe-4da0-8ef3-5f226842248e"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0001,0.0005,0.0006]:\n","    \n","        for hidden_nodes in [1024,1600,1800]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adam(model,lr=learning_rate,device='cuda:0',epoch=args.epochs)\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'word2vec_cross_adam_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00010000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.763830 \tValidation Loss: -0.786344\n","Validation loss decreased (inf --> -0.786344).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.865497 \tValidation Loss: -0.779783\n","Epoch: 2 \tTraining Loss: -0.862831 \tValidation Loss: -0.784822\n","Epoch: 3 \tTraining Loss: -0.866886 \tValidation Loss: -0.768979\n","Epoch: 4 \tTraining Loss: -0.862398 \tValidation Loss: -0.773999\n","Epoch: 5 \tTraining Loss: -0.855634 \tValidation Loss: -0.764311\n","pred_shape (1379,)\n","result 0.744\n","best_model_score increased (-inf --> 0.744000).  Saving model ...\n","\n","LR = 0.00010000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.779523 \tValidation Loss: -0.779940\n","Validation loss decreased (inf --> -0.779940).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.867237 \tValidation Loss: -0.786726\n","Validation loss decreased (-0.779940 --> -0.786726).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.912579 \tValidation Loss: -0.773741\n","Epoch: 3 \tTraining Loss: -0.912250 \tValidation Loss: -0.767633\n","Epoch: 4 \tTraining Loss: -0.914031 \tValidation Loss: -0.762415\n","Epoch: 5 \tTraining Loss: -0.911800 \tValidation Loss: -0.739484\n","pred_shape (1379,)\n","result 0.7536\n","best_model_score increased (0.744000 --> 0.753600).  Saving model ...\n","\n","LR = 0.00010000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.771524 \tValidation Loss: -0.762904\n","Validation loss decreased (inf --> -0.762904).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.859554 \tValidation Loss: -0.768172\n","Validation loss decreased (-0.762904 --> -0.768172).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.911141 \tValidation Loss: -0.757588\n","Epoch: 3 \tTraining Loss: -0.909837 \tValidation Loss: -0.761597\n","Epoch: 4 \tTraining Loss: -0.901985 \tValidation Loss: -0.766265\n","Epoch: 5 \tTraining Loss: -0.910461 \tValidation Loss: -0.765146\n","pred_shape (1379,)\n","result 0.7477\n","\n","LR = 0.00050000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.773580 \tValidation Loss: -0.725824\n","Validation loss decreased (inf --> -0.725824).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.867123 \tValidation Loss: -0.775611\n","Validation loss decreased (-0.725824 --> -0.775611).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.925024 \tValidation Loss: -0.790279\n","Validation loss decreased (-0.775611 --> -0.790279).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.955974 \tValidation Loss: -0.793354\n","Validation loss decreased (-0.790279 --> -0.793354).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.967741 \tValidation Loss: -0.771129\n","Epoch: 5 \tTraining Loss: -0.966901 \tValidation Loss: -0.794023\n","Validation loss decreased (-0.793354 --> -0.794023).  Saving model ...\n","pred_shape (1379,)\n","result 0.7351\n","\n","LR = 0.00050000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.742893 \tValidation Loss: -0.773300\n","Validation loss decreased (inf --> -0.773300).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.861843 \tValidation Loss: -0.783316\n","Validation loss decreased (-0.773300 --> -0.783316).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.914570 \tValidation Loss: -0.777604\n","Epoch: 3 \tTraining Loss: -0.907604 \tValidation Loss: -0.796166\n","Validation loss decreased (-0.783316 --> -0.796166).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.941601 \tValidation Loss: -0.779453\n","Epoch: 5 \tTraining Loss: -0.938178 \tValidation Loss: -0.756420\n","pred_shape (1379,)\n","result 0.7468\n","\n","LR = 0.00050000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.754657 \tValidation Loss: -0.765172\n","Validation loss decreased (inf --> -0.765172).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.864549 \tValidation Loss: -0.783233\n","Validation loss decreased (-0.765172 --> -0.783233).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.915312 \tValidation Loss: -0.764588\n","Epoch: 3 \tTraining Loss: -0.909959 \tValidation Loss: -0.775141\n","Epoch: 4 \tTraining Loss: -0.914015 \tValidation Loss: -0.767628\n","Epoch: 5 \tTraining Loss: -0.907879 \tValidation Loss: -0.770668\n","pred_shape (1379,)\n","result 0.7339\n","\n","LR = 0.00060000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.772581 \tValidation Loss: -0.767127\n","Validation loss decreased (inf --> -0.767127).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.873748 \tValidation Loss: -0.769338\n","Validation loss decreased (-0.767127 --> -0.769338).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.926639 \tValidation Loss: -0.793004\n","Validation loss decreased (-0.769338 --> -0.793004).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.951926 \tValidation Loss: -0.773798\n","Epoch: 4 \tTraining Loss: -0.950053 \tValidation Loss: -0.784841\n","Epoch: 5 \tTraining Loss: -0.948842 \tValidation Loss: -0.789577\n","pred_shape (1379,)\n","result 0.7438\n","\n","LR = 0.00060000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.759829 \tValidation Loss: -0.771252\n","Validation loss decreased (inf --> -0.771252).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.865561 \tValidation Loss: -0.765242\n","Epoch: 2 \tTraining Loss: -0.850445 \tValidation Loss: -0.745662\n","Epoch: 3 \tTraining Loss: -0.857245 \tValidation Loss: -0.749625\n","Epoch: 4 \tTraining Loss: -0.837170 \tValidation Loss: -0.775940\n","Validation loss decreased (-0.771252 --> -0.775940).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.916538 \tValidation Loss: -0.788248\n","Validation loss decreased (-0.775940 --> -0.788248).  Saving model ...\n","pred_shape (1379,)\n","result 0.7686\n","best_model_score increased (0.753600 --> 0.768600).  Saving model ...\n","\n","LR = 0.00060000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.742288 \tValidation Loss: -0.741589\n","Validation loss decreased (inf --> -0.741589).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.861476 \tValidation Loss: -0.688933\n","Epoch: 2 \tTraining Loss: -0.861936 \tValidation Loss: -0.777073\n","Validation loss decreased (-0.741589 --> -0.777073).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.919995 \tValidation Loss: -0.798725\n","Validation loss decreased (-0.777073 --> -0.798725).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.953918 \tValidation Loss: -0.779186\n","Epoch: 5 \tTraining Loss: -0.946990 \tValidation Loss: -0.768864\n","pred_shape (1379,)\n","result 0.7577\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"twLVEUYYc0Fv","colab_type":"text"},"source":["## Adadelta"]},{"cell_type":"code","metadata":{"id":"z-ONcMX2dtbG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590477848200,"user_tz":-330,"elapsed":1518915,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"80ffac3b-3ede-459a-bd8a-25b646cee5cc"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.01,0.02,0.06]:\n","    \n","        for hidden_nodes in [1024,1600,1800]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adadleta(model,lr=learning_rate,device='cuda:0')\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'word2vec_cross_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.01000000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.616614 \tValidation Loss: -0.605659\n","Validation loss decreased (inf --> -0.605659).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.646019 \tValidation Loss: -0.636993\n","Validation loss decreased (-0.605659 --> -0.636993).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.670678 \tValidation Loss: -0.646871\n","Validation loss decreased (-0.636993 --> -0.646871).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.679009 \tValidation Loss: -0.693373\n","Validation loss decreased (-0.646871 --> -0.693373).  Saving model ...\n","pred_shape (1379,)\n","result 0.6496\n","best_model_score increased (-inf --> 0.649600).  Saving model ...\n","\n","LR = 0.01000000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.616065 \tValidation Loss: -0.619386\n","Validation loss decreased (inf --> -0.619386).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.654137 \tValidation Loss: -0.631456\n","Validation loss decreased (-0.619386 --> -0.631456).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.681396 \tValidation Loss: -0.675652\n","Validation loss decreased (-0.631456 --> -0.675652).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.704259 \tValidation Loss: -0.692876\n","Validation loss decreased (-0.675652 --> -0.692876).  Saving model ...\n","pred_shape (1379,)\n","result 0.679\n","best_model_score increased (0.649600 --> 0.679000).  Saving model ...\n","\n","LR = 0.01000000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.618496 \tValidation Loss: -0.613536\n","Validation loss decreased (inf --> -0.613536).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.646546 \tValidation Loss: -0.624460\n","Validation loss decreased (-0.613536 --> -0.624460).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.677604 \tValidation Loss: -0.687145\n","Validation loss decreased (-0.624460 --> -0.687145).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.709801 \tValidation Loss: -0.675127\n","pred_shape (1379,)\n","result 0.6411\n","\n","LR = 0.02000000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.625433 \tValidation Loss: -0.635773\n","Validation loss decreased (inf --> -0.635773).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.675283 \tValidation Loss: -0.656197\n","Validation loss decreased (-0.635773 --> -0.656197).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.721343 \tValidation Loss: -0.711637\n","Validation loss decreased (-0.656197 --> -0.711637).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.726142 \tValidation Loss: -0.700264\n","pred_shape (1379,)\n","result 0.6917\n","best_model_score increased (0.679000 --> 0.691700).  Saving model ...\n","\n","LR = 0.02000000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.636372 \tValidation Loss: -0.605771\n","Validation loss decreased (inf --> -0.605771).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.657156 \tValidation Loss: -0.631207\n","Validation loss decreased (-0.605771 --> -0.631207).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.673387 \tValidation Loss: -0.624008\n","Epoch: 3 \tTraining Loss: -0.670527 \tValidation Loss: -0.648152\n","Validation loss decreased (-0.631207 --> -0.648152).  Saving model ...\n","pred_shape (1379,)\n","result 0.5559\n","\n","LR = 0.02000000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.632924 \tValidation Loss: -0.614975\n","Validation loss decreased (inf --> -0.614975).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.682789 \tValidation Loss: -0.694148\n","Validation loss decreased (-0.614975 --> -0.694148).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.716190 \tValidation Loss: -0.693293\n","Epoch: 3 \tTraining Loss: -0.702387 \tValidation Loss: -0.699625\n","Validation loss decreased (-0.694148 --> -0.699625).  Saving model ...\n","pred_shape (1379,)\n","result 0.6623\n","\n","LR = 0.06000000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.659395 \tValidation Loss: -0.692817\n","Validation loss decreased (inf --> -0.692817).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.738071 \tValidation Loss: -0.736953\n","Validation loss decreased (-0.692817 --> -0.736953).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.750691 \tValidation Loss: -0.745373\n","Validation loss decreased (-0.736953 --> -0.745373).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.771820 \tValidation Loss: -0.760145\n","Validation loss decreased (-0.745373 --> -0.760145).  Saving model ...\n","pred_shape (1379,)\n","result 0.6912\n","\n","LR = 0.06000000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.666261 \tValidation Loss: -0.702228\n","Validation loss decreased (inf --> -0.702228).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.736486 \tValidation Loss: -0.749717\n","Validation loss decreased (-0.702228 --> -0.749717).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.762628 \tValidation Loss: -0.759762\n","Validation loss decreased (-0.749717 --> -0.759762).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.768097 \tValidation Loss: -0.748356\n","pred_shape (1379,)\n","result 0.6648\n","\n","LR = 0.06000000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.673524 \tValidation Loss: -0.709949\n","Validation loss decreased (inf --> -0.709949).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.722847 \tValidation Loss: -0.743906\n","Validation loss decreased (-0.709949 --> -0.743906).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.756174 \tValidation Loss: -0.758456\n","Validation loss decreased (-0.743906 --> -0.758456).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.765816 \tValidation Loss: -0.759737\n","Validation loss decreased (-0.758456 --> -0.759737).  Saving model ...\n","pred_shape (1379,)\n","result 0.6764\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AxYIrf5TaKHb","colab_type":"text"},"source":["## optim.AdamW"]},{"cell_type":"code","metadata":{"id":"q4pNDahtd6-G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590479396608,"user_tz":-330,"elapsed":3062021,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"d39a0b6c-04f4-405a-df3d-7c4ab6651e79"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0001,0.0002,0.0006]:\n","    \n","        for hidden_nodes in [1024,1600,1800]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adamw(model,lr=learning_rate,device='cuda:0')\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'word2vec_cross_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00010000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.655386 \tValidation Loss: -0.647266\n","Validation loss decreased (inf --> -0.647266).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.651338 \tValidation Loss: -0.659980\n","Validation loss decreased (-0.647266 --> -0.659980).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.654971 \tValidation Loss: -0.634847\n","Epoch: 3 \tTraining Loss: -0.652093 \tValidation Loss: -0.648497\n","pred_shape (1379,)\n","result nan\n","\n","LR = 0.00010000, Hidden nodes = 1600\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0 \tTraining Loss: -0.725891 \tValidation Loss: -0.716092\n","Validation loss decreased (inf --> -0.716092).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.724866 \tValidation Loss: -0.676003\n","Epoch: 2 \tTraining Loss: -0.725892 \tValidation Loss: -0.637315\n","Epoch: 3 \tTraining Loss: -0.727580 \tValidation Loss: -0.603493\n","pred_shape (1379,)\n","result 0.5896\n","best_model_score increased (-inf --> 0.589600).  Saving model ...\n","\n","LR = 0.00010000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.645589 \tValidation Loss: -0.656145\n","Validation loss decreased (inf --> -0.656145).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.642847 \tValidation Loss: -0.638018\n","Epoch: 2 \tTraining Loss: -0.642057 \tValidation Loss: -0.642251\n","Epoch: 3 \tTraining Loss: -0.637805 \tValidation Loss: -0.655323\n","pred_shape (1379,)\n","result 0.0526\n","\n","LR = 0.00020000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.641877 \tValidation Loss: -0.651110\n","Validation loss decreased (inf --> -0.651110).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.652203 \tValidation Loss: -0.641935\n","Epoch: 2 \tTraining Loss: -0.645473 \tValidation Loss: -0.636386\n","Epoch: 3 \tTraining Loss: -0.644257 \tValidation Loss: -0.653559\n","Validation loss decreased (-0.651110 --> -0.653559).  Saving model ...\n","pred_shape (1379,)\n","result 0.0562\n","\n","LR = 0.00020000, Hidden nodes = 1600\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3538: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n","  warnings.warn(PearsonRNearConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0 \tTraining Loss: -0.659922 \tValidation Loss: -0.622755\n","Validation loss decreased (inf --> -0.622755).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.654538 \tValidation Loss: -0.584550\n","Epoch: 2 \tTraining Loss: -0.662981 \tValidation Loss: -0.594376\n","Epoch: 3 \tTraining Loss: -0.660212 \tValidation Loss: -0.611915\n","pred_shape (1379,)\n","result 0.0591\n","\n","LR = 0.00020000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.565855 \tValidation Loss: -0.608054\n","Validation loss decreased (inf --> -0.608054).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.553918 \tValidation Loss: -0.575417\n","Epoch: 2 \tTraining Loss: -0.556033 \tValidation Loss: -0.598827\n","Epoch: 3 \tTraining Loss: -0.549968 \tValidation Loss: -0.583208\n","pred_shape (1379,)\n","result nan\n","\n","LR = 0.00060000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.639985 \tValidation Loss: -0.661437\n","Validation loss decreased (inf --> -0.661437).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.647877 \tValidation Loss: -0.657286\n","Epoch: 2 \tTraining Loss: -0.643230 \tValidation Loss: -0.627971\n","Epoch: 3 \tTraining Loss: -0.648053 \tValidation Loss: -0.630295\n","pred_shape (1379,)\n","result nan\n","\n","LR = 0.00060000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.665508 \tValidation Loss: -0.602949\n","Validation loss decreased (inf --> -0.602949).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.665277 \tValidation Loss: -0.592390\n","Epoch: 2 \tTraining Loss: -0.661945 \tValidation Loss: -0.608941\n","Validation loss decreased (-0.602949 --> -0.608941).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.655938 \tValidation Loss: -0.592260\n","pred_shape (1379,)\n","result nan\n","\n","LR = 0.00060000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.644949 \tValidation Loss: -0.652527\n","Validation loss decreased (inf --> -0.652527).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.646791 \tValidation Loss: -0.642250\n","Epoch: 2 \tTraining Loss: -0.653936 \tValidation Loss: -0.654676\n","Validation loss decreased (-0.652527 --> -0.654676).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.644216 \tValidation Loss: -0.634975\n","pred_shape (1379,)\n","result nan\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rifGk_VhbRJ-","colab_type":"text"},"source":["## opim.Adamax"]},{"cell_type":"code","metadata":{"id":"-gJ-9k8kd_50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"status":"error","timestamp":1590784908040,"user_tz":-330,"elapsed":62367,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"df9696c9-04ac-4cce-9ccc-ac1a6e1edcd6"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0001,0.0002,0.0006]:\n","    \n","        for hidden_nodes in [1024,1600,1800]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adamax(model,lr=learning_rate,device='cuda:0',epoch= args.epochs)\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'word2vec_cross_adamax_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00010000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.733254 \tValidation Loss: -0.772418\n","Validation loss decreased (inf --> -0.772418).  Saving model ...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-6908c786784a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mtrain_setup_Adamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0meval_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-9a1245ca6623>\u001b[0m in \u001b[0;36mtrain_setup_Adamax\u001b[0;34m(net, lr, batch_size, momentum, device, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec_cross_epoch.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_n_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mtrain_loss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0;31m#print(\"train_loss_MSE\",train_loss_arr[i+1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-1e315ca1a2c5>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, trainload, opt, batch_size, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0m_sample_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0minput1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0minput2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-2e90c73ce472>\u001b[0m in \u001b[0;36m_sample_pairs\u001b[0;34m(data, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatacopy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdatacopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"YS8GKXNzbwsL","colab_type":"text"},"source":["## optim.RMSprop"]},{"cell_type":"code","metadata":{"id":"HjjWJzmYeHW8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590482527748,"user_tz":-330,"elapsed":3131102,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"5f3f0d6c-9b52-4afa-e065-aac0c361467b"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.01,0.02,0.001]:\n","    for momemtum in [0.09,0.087]:\n","        for hidden_nodes in [1024,1600,1800]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Momentum = %.5f, Hidden nodes = %d\\n' % (learning_rate, momemtum, hidden_nodes))\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adadleta(model,lr=learning_rate,momentum= momemtum ,device='cuda:0')\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'word2vec_cross_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.01000000, Momentum = 0.09000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.600980 \tValidation Loss: -0.605686\n","Validation loss decreased (inf --> -0.605686).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.646431 \tValidation Loss: -0.639014\n","Validation loss decreased (-0.605686 --> -0.639014).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.655960 \tValidation Loss: -0.624927\n","Epoch: 3 \tTraining Loss: -0.658725 \tValidation Loss: -0.624825\n","pred_shape (1379,)\n","result 0.324\n","best_model_score increased (-inf --> 0.324000).  Saving model ...\n","\n","LR = 0.01000000, Momentum = 0.09000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.611263 \tValidation Loss: -0.622550\n","Validation loss decreased (inf --> -0.622550).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.656972 \tValidation Loss: -0.624875\n","Validation loss decreased (-0.622550 --> -0.624875).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.666565 \tValidation Loss: -0.613075\n","Epoch: 3 \tTraining Loss: -0.663706 \tValidation Loss: -0.638375\n","Validation loss decreased (-0.624875 --> -0.638375).  Saving model ...\n","pred_shape (1379,)\n","result 0.5523\n","best_model_score increased (0.324000 --> 0.552300).  Saving model ...\n","\n","LR = 0.01000000, Momentum = 0.09000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.607415 \tValidation Loss: -0.617653\n","Validation loss decreased (inf --> -0.617653).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.647162 \tValidation Loss: -0.631916\n","Validation loss decreased (-0.617653 --> -0.631916).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.651971 \tValidation Loss: -0.637518\n","Validation loss decreased (-0.631916 --> -0.637518).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.679719 \tValidation Loss: -0.665755\n","Validation loss decreased (-0.637518 --> -0.665755).  Saving model ...\n","pred_shape (1379,)\n","result 0.6178\n","best_model_score increased (0.552300 --> 0.617800).  Saving model ...\n","\n","LR = 0.01000000, Momentum = 0.08700, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.614772 \tValidation Loss: -0.647425\n","Validation loss decreased (inf --> -0.647425).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.651159 \tValidation Loss: -0.600722\n","Epoch: 2 \tTraining Loss: -0.649418 \tValidation Loss: -0.640925\n","Epoch: 3 \tTraining Loss: -0.654844 \tValidation Loss: -0.618496\n","pred_shape (1379,)\n","result 0.3966\n","\n","LR = 0.01000000, Momentum = 0.08700, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.611672 \tValidation Loss: -0.630623\n","Validation loss decreased (inf --> -0.630623).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.654429 \tValidation Loss: -0.624425\n","Epoch: 2 \tTraining Loss: -0.653030 \tValidation Loss: -0.637961\n","Validation loss decreased (-0.630623 --> -0.637961).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.655367 \tValidation Loss: -0.651592\n","Validation loss decreased (-0.637961 --> -0.651592).  Saving model ...\n","pred_shape (1379,)\n","result 0.5427\n","\n","LR = 0.01000000, Momentum = 0.08700, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.606984 \tValidation Loss: -0.631100\n","Validation loss decreased (inf --> -0.631100).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.642544 \tValidation Loss: -0.616884\n","Epoch: 2 \tTraining Loss: -0.650394 \tValidation Loss: -0.621809\n","Epoch: 3 \tTraining Loss: -0.654026 \tValidation Loss: -0.622901\n","pred_shape (1379,)\n","result 0.3403\n","\n","LR = 0.02000000, Momentum = 0.09000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.628713 \tValidation Loss: -0.633487\n","Validation loss decreased (inf --> -0.633487).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.656802 \tValidation Loss: -0.626431\n","Epoch: 2 \tTraining Loss: -0.666395 \tValidation Loss: -0.618105\n","Epoch: 3 \tTraining Loss: -0.660991 \tValidation Loss: -0.634018\n","Validation loss decreased (-0.633487 --> -0.634018).  Saving model ...\n","pred_shape (1379,)\n","result 0.5082\n","\n","LR = 0.02000000, Momentum = 0.09000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.621208 \tValidation Loss: -0.634387\n","Validation loss decreased (inf --> -0.634387).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.668351 \tValidation Loss: -0.651112\n","Validation loss decreased (-0.634387 --> -0.651112).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.691746 \tValidation Loss: -0.700877\n","Validation loss decreased (-0.651112 --> -0.700877).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.726272 \tValidation Loss: -0.716951\n","Validation loss decreased (-0.700877 --> -0.716951).  Saving model ...\n","pred_shape (1379,)\n","result 0.671\n","best_model_score increased (0.617800 --> 0.671000).  Saving model ...\n","\n","LR = 0.02000000, Momentum = 0.09000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.632773 \tValidation Loss: -0.627619\n","Validation loss decreased (inf --> -0.627619).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.664379 \tValidation Loss: -0.687821\n","Validation loss decreased (-0.627619 --> -0.687821).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.715564 \tValidation Loss: -0.699890\n","Validation loss decreased (-0.687821 --> -0.699890).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.715966 \tValidation Loss: -0.717848\n","Validation loss decreased (-0.699890 --> -0.717848).  Saving model ...\n","pred_shape (1379,)\n","result 0.6587\n","\n","LR = 0.02000000, Momentum = 0.08700, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.624876 \tValidation Loss: -0.611606\n","Validation loss decreased (inf --> -0.611606).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.676443 \tValidation Loss: -0.655647\n","Validation loss decreased (-0.611606 --> -0.655647).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.686899 \tValidation Loss: -0.678474\n","Validation loss decreased (-0.655647 --> -0.678474).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.719443 \tValidation Loss: -0.679832\n","Validation loss decreased (-0.678474 --> -0.679832).  Saving model ...\n","pred_shape (1379,)\n","result 0.6593\n","\n","LR = 0.02000000, Momentum = 0.08700, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.637971 \tValidation Loss: -0.618593\n","Validation loss decreased (inf --> -0.618593).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.678056 \tValidation Loss: -0.692937\n","Validation loss decreased (-0.618593 --> -0.692937).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.713200 \tValidation Loss: -0.693931\n","Validation loss decreased (-0.692937 --> -0.693931).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.715949 \tValidation Loss: -0.708572\n","Validation loss decreased (-0.693931 --> -0.708572).  Saving model ...\n","pred_shape (1379,)\n","result 0.6575\n","\n","LR = 0.02000000, Momentum = 0.08700, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.630595 \tValidation Loss: -0.611557\n","Validation loss decreased (inf --> -0.611557).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.683781 \tValidation Loss: -0.690757\n","Validation loss decreased (-0.611557 --> -0.690757).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.712841 \tValidation Loss: -0.713249\n","Validation loss decreased (-0.690757 --> -0.713249).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.729493 \tValidation Loss: -0.715622\n","Validation loss decreased (-0.713249 --> -0.715622).  Saving model ...\n","pred_shape (1379,)\n","result 0.6517\n","\n","LR = 0.00100000, Momentum = 0.09000, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.577070 \tValidation Loss: -0.584615\n","Validation loss decreased (inf --> -0.584615).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.592403 \tValidation Loss: -0.587111\n","Validation loss decreased (-0.584615 --> -0.587111).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.594938 \tValidation Loss: -0.604350\n","Validation loss decreased (-0.587111 --> -0.604350).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.607521 \tValidation Loss: -0.605891\n","Validation loss decreased (-0.604350 --> -0.605891).  Saving model ...\n","pred_shape (1379,)\n","result 0.3905\n","\n","LR = 0.00100000, Momentum = 0.09000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.586436 \tValidation Loss: -0.587577\n","Validation loss decreased (inf --> -0.587577).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.593379 \tValidation Loss: -0.588123\n","Validation loss decreased (-0.587577 --> -0.588123).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.603718 \tValidation Loss: -0.618259\n","Validation loss decreased (-0.588123 --> -0.618259).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.609509 \tValidation Loss: -0.603572\n","pred_shape (1379,)\n","result 0.3292\n","\n","LR = 0.00100000, Momentum = 0.09000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.586962 \tValidation Loss: -0.601214\n","Validation loss decreased (inf --> -0.601214).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.592995 \tValidation Loss: -0.602483\n","Validation loss decreased (-0.601214 --> -0.602483).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.608155 \tValidation Loss: -0.622946\n","Validation loss decreased (-0.602483 --> -0.622946).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.610707 \tValidation Loss: -0.621573\n","pred_shape (1379,)\n","result 0.3441\n","\n","LR = 0.00100000, Momentum = 0.08700, Hidden nodes = 1024\n","\n","Epoch: 0 \tTraining Loss: -0.590369 \tValidation Loss: -0.597177\n","Validation loss decreased (inf --> -0.597177).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.595422 \tValidation Loss: -0.595591\n","Epoch: 2 \tTraining Loss: -0.593215 \tValidation Loss: -0.604065\n","Validation loss decreased (-0.597177 --> -0.604065).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.606864 \tValidation Loss: -0.603309\n","pred_shape (1379,)\n","result 0.2697\n","\n","LR = 0.00100000, Momentum = 0.08700, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.574864 \tValidation Loss: -0.589800\n","Validation loss decreased (inf --> -0.589800).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.585125 \tValidation Loss: -0.590569\n","Validation loss decreased (-0.589800 --> -0.590569).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.587899 \tValidation Loss: -0.610646\n","Validation loss decreased (-0.590569 --> -0.610646).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.594506 \tValidation Loss: -0.605070\n","pred_shape (1379,)\n","result 0.1523\n","\n","LR = 0.00100000, Momentum = 0.08700, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.579692 \tValidation Loss: -0.587399\n","Validation loss decreased (inf --> -0.587399).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.594112 \tValidation Loss: -0.594661\n","Validation loss decreased (-0.587399 --> -0.594661).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.600105 \tValidation Loss: -0.602231\n","Validation loss decreased (-0.594661 --> -0.602231).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.602057 \tValidation Loss: -0.612289\n","Validation loss decreased (-0.602231 --> -0.612289).  Saving model ...\n","pred_shape (1379,)\n","result 0.1103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pISYepuieC_P","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Js120I3bTMaB","colab_type":"text"},"source":["# Practice"]},{"cell_type":"code","metadata":{"id":"99F0SRW5dyY9","colab_type":"code","colab":{}},"source":["trainload= _load_data('sts-train.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNi4lsSTdkGL","colab_type":"code","colab":{}},"source":["data=_sample_pairs(trainload,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhA8win0gR0V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589382413225,"user_tz":-330,"elapsed":1485,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"15ee7d0c-693b-4bd4-f857-d14e5358ec66"},"source":["data_len= []\n","for i in data['s0']:\n","  data_len.append(len(i))\n","max_len_sent=max(data_len)\n","\n","rep= torch.zeros(max_len_sent, 2 ,300)\n","rep.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([11, 2, 300])"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"u2UgwP2Zk23J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1589383031128,"user_tz":-330,"elapsed":1647,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"83d2fa18-b2ce-4912-8f4d-0953eedf9be6"},"source":["(data['s0'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['brown',\n","  'and',\n","  'white',\n","  'cow',\n","  'standing',\n","  'in',\n","  'grass',\n","  'at',\n","  'side',\n","  'of',\n","  'road'],\n"," ['boy', 'scouts', 'delay', 'decision', 'on', 'admitting', 'gays']]"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"1aknSKgzjzY1","colab_type":"code","colab":{}},"source":["temp=[]\n","rep[0][0]=torch.tensor(indextovector[wordtoindex['brown']])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63gsjzqaoYLv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589383373257,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"ec8900d0-ef3d-46a2-e169-ac80a390c947"},"source":["rep[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3741, -0.0763,  0.1093,  0.1866,  0.0299,  0.1827, -0.6320,  0.1331,\n","         -0.1290,  0.6034, -0.6804, -0.1422, -0.1336, -0.6594,  0.0524,  0.1674,\n","          0.6392,  1.7680,  0.3462, -0.6248, -0.1287, -0.1970, -0.3745,  0.3306,\n","          0.0468, -0.6535, -0.5614,  0.2274,  0.2292, -0.4158, -0.1677,  0.3354,\n","          0.0972, -0.4670, -0.0269, -0.0677, -0.1921, -0.1337,  0.0163, -0.2083,\n","          0.6486, -0.1102, -0.0510,  0.0722,  0.1877,  0.2711, -0.3142,  0.1832,\n","          0.3915, -0.2255, -0.3819,  0.3306, -0.0899, -0.3763,  0.0480, -0.2050,\n","         -0.5489,  0.3044, -0.1887, -0.3034, -0.1157, -0.3487,  0.2800,  0.0501,\n","         -0.2814, -0.2335, -0.3683, -0.1204, -0.2833,  0.1857,  0.1036,  0.2531,\n","         -0.0340,  0.1051,  0.1214, -0.1630, -0.3318,  0.1731,  0.1076, -0.9936,\n","         -0.1171,  0.4223,  0.1512,  0.3106,  0.2674, -0.4927,  1.8049,  1.0738,\n","          0.3442,  0.1128, -0.1049,  0.3694,  0.4082, -0.4037,  0.3233, -0.0939,\n","         -0.0290,  0.3825, -0.3389, -0.6132,  0.8434,  0.1593, -0.1174,  0.0806,\n","         -0.2899, -0.4439, -0.1183,  0.1658,  0.1525,  0.2386, -0.3295, -0.3199,\n","         -0.3118, -0.1919,  0.2847,  0.2568,  0.4379, -0.0233,  0.1891, -0.0850,\n","         -0.1164, -0.1102, -0.0595,  0.1155,  0.2070,  0.5587,  0.8177, -0.2563,\n","         -0.0181, -0.0410, -0.2660, -0.4568, -0.0374,  0.3325,  0.1414, -0.0630,\n","         -0.0866, -0.3327, -0.0092, -0.0355, -2.8871,  0.2453,  0.2974,  0.6599,\n","         -0.0134, -0.1089,  0.1155,  0.0526, -0.0430,  0.2285,  0.4021, -0.4891,\n","          0.0441, -0.1368, -0.7181,  0.2526, -0.5788, -0.4807, -0.2409,  0.0427,\n","         -0.0946, -0.3034, -0.3197,  0.3554,  0.0629, -0.2043, -0.2978, -0.1545,\n","          0.2443,  0.0489, -0.0773,  0.3643, -0.1513, -0.4539, -0.3431,  0.1069,\n","          0.4292, -0.0260,  0.4825,  0.3361, -0.5032,  0.2241, -0.2737, -0.4904,\n","         -0.1173,  1.0537, -0.2023,  0.0490, -0.1223,  0.1100,  0.4155, -0.1183,\n","          0.1148, -0.2663,  0.2908,  0.2541,  0.3535,  0.3172, -0.1517, -0.5050,\n","         -0.2202,  0.1163, -0.2513,  0.2280,  0.2628,  0.2107,  0.0236,  0.0769,\n","         -0.1486,  0.0720,  0.3767,  0.3536, -0.3933, -0.1338,  0.5593,  0.0337,\n","         -0.4850, -0.3276,  0.2587,  0.4876, -0.2649,  0.0329, -0.0838, -0.0638,\n","          0.1076, -0.1855, -0.0523,  0.0767, -0.2148,  0.9646, -0.2479, -0.1211,\n","          0.0394,  0.4471, -0.1380, -0.0278, -0.4937, -0.5163,  0.3386,  0.5921,\n","         -0.2013, -0.0832, -0.3758, -0.2127, -0.3856,  0.2259, -0.3722, -0.1872,\n","         -0.6052, -0.1279,  0.2344, -0.4222, -0.2354,  0.2968,  0.0678,  0.0780,\n","          0.3195, -0.0348,  0.2981,  0.4400,  0.1174,  0.0550,  0.2368,  0.8982,\n","         -0.4097,  0.0752, -0.1103, -0.4099, -0.9572,  0.5275, -0.0427,  0.2662,\n","          0.3053, -0.5190, -0.4604, -0.0938,  0.1301,  0.0193,  0.0102,  0.0076,\n","          0.2955,  0.2316, -0.0349, -0.1169, -0.3273,  0.2049,  0.4750,  0.5131,\n","         -0.1458, -0.1851, -0.0154,  0.3929, -0.0348, -0.7203, -0.3653,  0.7405,\n","          0.1084, -0.3658, -0.2882,  0.1146],\n","        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000]])"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"A2XUoGKXm6bu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"ok","timestamp":1589383146976,"user_tz":-330,"elapsed":1264,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"492d4acd-34f3-4ba7-e431-75db36c221ee"},"source":["data['m0'][0][11]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"VB2STaT2SzyW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589370183806,"user_tz":-330,"elapsed":1311,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"b337bbc4-9adc-4234-c976-8006afce7033"},"source":["m = nn.MaxPool1d(1)\n","input = torch.randn(6, 5)\n","input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 5])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"xTHe3bx83kR6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1589370748582,"user_tz":-330,"elapsed":1446,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"035245a9-3273-4e41-ead4-fde0c6edb090"},"source":["input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7378,  1.7368,  0.0198,  0.8431,  0.9046],\n","        [-1.5884, -1.1110,  0.8694,  0.3053,  0.3550],\n","        [ 0.1539, -0.4941, -0.0704,  1.3168,  0.9116],\n","        [ 1.2474,  0.6942,  0.1928, -0.5697, -0.8765],\n","        [-0.5326, -0.9174,  0.2422, -0.1825,  0.2426],\n","        [-1.5224, -1.7681, -1.8564, -1.0241, -1.3065]])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"YytbQVTy2LTs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1589371055905,"user_tz":-330,"elapsed":1936,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"d23b8943-a917-4490-8178-78e3b4bfa8f8"},"source":["input.to(torch.float32)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7378,  1.7368,  0.0198,  0.8431,  0.9046],\n","        [-1.5884, -1.1110,  0.8694,  0.3053,  0.3550],\n","        [ 0.1539, -0.4941, -0.0704,  1.3168,  0.9116],\n","        [ 1.2474,  0.6942,  0.1928, -0.5697, -0.8765],\n","        [-0.5326, -0.9174,  0.2422, -0.1825,  0.2426],\n","        [-1.5224, -1.7681, -1.8564, -1.0241, -1.3065]])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"c4ifcUQ-rE-z","colab_type":"code","colab":{}},"source":["output = m(input)\n","output.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtNIYGWArTMW","colab_type":"code","colab":{}},"source":["out= torch.flatten(output, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KNDFi6QhK3V","colab_type":"code","colab":{}},"source":["out.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa8AVUN1TFka","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vo28Dj7EhNUl","colab_type":"code","colab":{}},"source":["a=torch.tensor(np.array([1,2,3]))\n","b=torch.tensor(np.array([4,5,6]))\n","a*b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec595DaW2i6W","colab_type":"code","colab":{}},"source":["c=abs(a-b)\n","\n","c"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcJ9pxdi3tIc","colab_type":"code","colab":{}},"source":["import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-r14qRP595v","colab_type":"code","colab":{}},"source":["torch.cat((a,b),1).shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-F3HFrZ_ASV5","colab_type":"code","colab":{}},"source":["c= torch.randn(2, 5)\n","d= torch.randn(2,5)\n","e= torch.cat((c,d),1)\n","e.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sk0E5F22DpCX","colab_type":"code","colab":{}},"source":["(c-d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwGrQJ4TENvS","colab_type":"code","colab":{}},"source":["-1.5705-1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9NMh84DEcqd","colab_type":"code","colab":{}},"source":["(c*d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-V2_tVDEsj4","colab_type":"code","colab":{}},"source":["-1.5705*1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSrDjaRbEw58","colab_type":"code","colab":{}},"source":["-0.6561*-0.2841"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3FunLaWZdOb","colab_type":"code","colab":{}},"source":["'''blocksize=2\n","k= ((li[block:block+blocksize], block) for block in range(0,len(li),blocksize))\n","for i,j in k:\n","    print(i,j)'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKmW1OrSE5Fi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIw11E00ZdOp","colab_type":"code","colab":{}},"source":["'''def worker(args):\n","        print(args[0])\n","        print(args[1])'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFRV8fpxq6_H","colab_type":"code","colab":{}},"source":["p= np.random.randn(1,5)\n","p"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIxJzwg4rFr7","colab_type":"code","colab":{}},"source":["plt.plot(p,'-*')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uA4LFKOErSjU","colab_type":"code","colab":{}},"source":["p[1:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2pIVqMUrnEk","colab_type":"code","colab":{}},"source":["d={'a':[1],'b':[2],'c':[3]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utzQBcocDKgw","colab_type":"code","colab":{}},"source":["d1={}\n","d1= d.keys\n","d1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StnIcTfHDNOr","colab_type":"code","colab":{}},"source":["d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ILOBRLaDUoR","colab_type":"code","colab":{}},"source":["d2={}\n","d3=d2.fromkeys(d.keys(),[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYqLiw7OFti_","colab_type":"code","colab":{}},"source":["d3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDD4QynwF1mT","colab_type":"code","colab":{}},"source":["d3['b'].append(909)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gW5xs9TOF2gQ","colab_type":"code","colab":{}},"source":["d4 = copy.deepcopy(d3)\n","d4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzfN1pbYF3t4","colab_type":"code","colab":{}},"source":["d4['a'].append(78)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f8gYRILJJVMk","colab_type":"code","colab":{}},"source":["d4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATDR9bO1JZYi","colab_type":"code","colab":{}},"source":["d['a'].append(909)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6_Vlp8KJmtO","colab_type":"code","colab":{}},"source":["d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2ZuH1ZyJt7W","colab_type":"code","colab":{}},"source":["d5={}\n","for i in d.keys():\n","  d5[i]=[]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ownN6bJmJ2-e","colab_type":"code","colab":{}},"source":["d5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUD2KxkvJ8Ap","colab_type":"code","colab":{}},"source":["\n","d5['a'].append(78)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vCw3STpKA01","colab_type":"code","colab":{}},"source":["d5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-IFwXmcLL4A","colab_type":"code","colab":{}},"source":["from numpy import linalg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdtczaL6KBuo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"error","timestamp":1589962938659,"user_tz":-330,"elapsed":1187,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"ab6da03f-0bb3-417e-db02-fa44cfc5e31f"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-867cd236419a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'linalg'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"YkK96xS3LKDu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}