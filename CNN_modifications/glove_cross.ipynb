{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"glove_cross.ipynb","provenance":[{"file_id":"1qszfjxZPa7uU4fp9Uo2zt2KP2MFGHYtZ","timestamp":1590410121337},{"file_id":"11gC0heODGZF5gzeO1JHAwvNQbl71HYGQ","timestamp":1589450062635},{"file_id":"1yqdy1wAa1K44GBjjCnjhVdfHdzv0FhOd","timestamp":1588956399944}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SH2wpCTYZdMh","colab_type":"code","colab":{}},"source":["import numpy as np\n","import multiprocessing as mp\n","import random,copy,string\n","from nltk.tokenize import word_tokenize\n","from scipy.stats import pearsonr\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.layers import Input, Convolution1D, MaxPooling1D, Flatten\n","from tensorflow.python.keras.layers import Lambda, multiply, concatenate, Dense\n","from tensorflow.python.keras.regularizers import l2\n","from tensorflow.python.keras.callbacks import Callback\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Q_ABwOwnYl1","colab_type":"code","colab":{}},"source":["import os, string, random, time, math\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQcOsPfMJL1-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1591622588275,"user_tz":-330,"elapsed":7935,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"ee9894e2-a09f-448f-daba-fd85f256a4e4"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"uLz42OGuar31","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1591622613588,"user_tz":-330,"elapsed":33220,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"ebbf53ac-4dca-4e94-885c-69e5cf3f92dc"},"source":["'''from google.colab import drive\n","drive.mount('/content/drive/')'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ae7JCVPfnj-p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591622613593,"user_tz":-330,"elapsed":33199,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"f3e3a5f0-302b-434b-d559-eb8753c0d9f4"},"source":["#cd 'drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UVdNymZ4Iuqt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":465},"executionInfo":{"status":"ok","timestamp":1591622616975,"user_tz":-330,"elapsed":36556,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"83b32013-1d02-434f-b20c-8be7a6a1dc0d"},"source":["#ls\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34m2017_takelab\u001b[0m/                        model_cifar.pt\n"," \u001b[01;34m2017_takelab+cnn\u001b[0m/                    msr_vid_SVR.ipynb\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/                    name2lang.txt\n"," data.zip                             processed_takelab_glove.txt\n"," deep_fasttext_epoch.pt               processed_takelab_jc.txt\n"," fasttext_cross0                      processed_takelab_lin.txt\n"," fasttext_cross1                      processed_takelab_output_MSRpar.txt\n"," fasttext_cross2                      processed_wv_wwv.txt\n"," fasttext_cross_epoch.pt              pytorch_cnn_code.ipynb\n"," fasttext_cross_model.pt              sts-dev.csv\n"," fasttext_cross.pt                    STS_survey.odt\n"," fasttext_kl_adamax_model.pt          sts-test.csv\n"," fasttext_kl_adam_model.pt            sts-train.csv\n"," fasttext_kl_epoch.pt                 substitute_vec.txt\n"," glove.840B.300d.txt                  takelab_glove.txt\n"," glove_ce_epoch.pt                    takelab_jc.txt\n"," glove_ce_model.pt                    takelab_lin.txt\n"," glove_cross_2FNN_epoch.pt            takelab_output_MSRpar.txt\n"," glove_cross_adam2FNN__model.pt       \u001b[01;34mtargets_subvecs\u001b[0m/\n"," glove_kl_adam_model.pt               try.csv\n"," glove_kl_epoch.pt                    try_test.csv\n"," GoogleNews-vectors-negative300.bin   try_validation.csv\n"," \u001b[01;34minput_model\u001b[0m/                         Understanding_cnn_code.ipynb\n"," \u001b[01;34mmlflow_server\u001b[0m/                       \u001b[01;34muoh_thesis\u001b[0m/\n"," \u001b[01;34mmlruns\u001b[0m/                              wv_wwv.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aN1UtOJrZdM5","colab_type":"code","colab":{}},"source":["c = dict()\n","c['num_runs']   = 3\n","c['num_epochs'] = 2\n","c['num_batchs'] = 4\n","c['batch_size'] = 3\n","c['wordvectdim']  = 300\n","c['sentencepad']  = 60\n","c['num_classes']  = 6\n","c['cnnfilters']     = {1: 1800}\n","c['cnninitial']     = 'he_uniform'\n","c['cnnactivate']    = 'relu'\n","c['densedimension'] = list([1800])\n","c['denseinitial']   = 'he_uniform'\n","c['denseactivate']  = 'tanh'\n","c['optimizer']  = 'adam'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGZC-I84ZdNN","colab_type":"code","colab":{}},"source":["wordvectdim=300\n","wordtoindex= dict()\n","indextovector= []\n","indextovector.append(np.zeros(wordvectdim))    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI95iihPfWFV","colab_type":"text"},"source":["# Loading word vectors"]},{"cell_type":"code","metadata":{"id":"aS9rXS5pZdNb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591622616989,"user_tz":-330,"elapsed":36541,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"644ea847-baab-4d5e-c8a3-26ea8ff31baf"},"source":["'''dictname= 'substitute_vec.txt'\n","lines = open('drive/My Drive/'dictname,'r',encoding='latin1').readlines()'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"dictname= 'substitute_vec.txt'\\nlines = open('drive/My Drive/'dictname,'r',encoding='latin1').readlines()\""]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"T3AhRwagicnh","colab_type":"code","colab":{}},"source":["lines= (open('../glove.840B.300d.txt','r').readlines())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b36H3elsZdN3","colab_type":"code","colab":{}},"source":["def _worker(args):\n","        print(args[1])\n","        wordtoindex   = dict()\n","        indextovector = []\n","        for line in args[0]:\n","            elements = line.split(' ')\n","            wordtoindex[elements[0]] = len(indextovector)+args[1]+1    # index of first word starts with 1\n","            indextovector.append(np.array(elements[1:]).astype(float))\n","        return (wordtoindex,indextovector)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQZw36Y2ZdOD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591622740291,"user_tz":-330,"elapsed":159814,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"534f4962-a75d-497e-ca70-bf6588fd6e22"},"source":["print(\"Number of cpu : \", mp.cpu_count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of cpu :  4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"jZorpPaoZdO1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591623505682,"user_tz":-330,"elapsed":4244,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"86742fcf-0ef9-4d82-99ee-e432f9a47e13"},"source":["blocksize=500\n","r_list = mp.Pool(4).map(_worker, ((lines[block:block+blocksize], block) for block in range(0,len(lines),blocksize)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","500\n","1000\n","1500\n","2000\n","2500\n","3000\n","3500\n","4000\n","4500\n","137500\n","5000\n","138000\n","5500\n","138500\n","6000\n","139000\n","6500\n","7000\n","139500\n","7500\n","140000\n","275000\n","8000\n","275500\n","140500\n","8500\n","276000\n","141000\n","9000\n","276500\n","141500\n","9500\n","277000\n","142000\n","10000\n","277500\n","142500\n","278000\n","10500\n","143000\n","278500\n","11000\n","143500\n","279000\n","412500\n","11500\n","144000\n","279500\n","413000\n","12000\n","144500\n","413500\n","280000\n","12500\n","414000\n","145000\n","280500\n","13000\n","414500\n","145500\n","281000\n","13500\n","415000\n","146000\n","281500\n","14000\n","415500\n","146500\n","282000\n","14500\n","416000\n","282500\n","147000\n","15000\n","416500\n","283000\n","147500\n","15500\n","417000\n","283500\n","148000\n","16000\n","417500\n","284000\n","148500\n","418000\n","16500\n","284500\n","149000\n","418500\n","17000\n","285000\n","149500\n","419000\n","17500\n","285500\n","150000\n","419500\n","18000\n","286000\n","150500\n","420000\n","18500\n","151000\n","286500\n","420500\n","19000\n","151500\n","287000\n","421000\n","19500\n","287500\n","152000\n","421500\n","20000\n","288000\n","152500\n","422000\n","20500\n","153000\n","288500\n","422500\n","21000\n","289000\n","153500\n","423000\n","21500\n","289500\n","154000\n","423500\n","22000\n","290000\n","154500\n","424000\n","22500\n","290500\n","155000\n","424500\n","23000\n","291000\n","155500\n","425000\n","23500\n","291500\n","156000\n","425500\n","24000\n","292000\n","156500\n","426000\n","24500\n","292500\n","157000\n","426500\n","25000\n","293000\n","157500\n","427000\n","25500\n","293500\n","158000\n","427500\n","26000\n","294000\n","158500\n","428000\n","26500\n","294500\n","159000\n","428500\n","27000\n","295000\n","159500\n","429000\n","27500\n","295500\n","160000\n","429500\n","28000\n","296000\n","160500\n","430000\n","28500\n","296500\n","161000\n","430500\n","29000\n","297000\n","161500\n","431000\n","29500\n","297500\n","162000\n","431500\n","30000\n","298000\n","162500\n","432000\n","30500\n","298500\n","432500\n","163000\n","31000\n","299000\n","433000\n","163500\n","31500\n","299500\n","433500\n","164000\n","32000\n","300000\n","434000\n","164500\n","32500\n","300500\n","434500\n","165000\n","33000\n","301000\n","435000\n","165500\n","33500\n","301500\n","435500\n","166000\n","34000\n","302000\n","436000\n","166500\n","34500\n","302500\n","436500\n","167000\n","35000\n","303000\n","437000\n","167500\n","35500\n","437500\n","303500\n","168000\n","36000\n","438000\n","304000\n","168500\n","36500\n","438500\n","169000\n","304500\n","37000\n","439000\n","169500\n","305000\n","37500\n","439500\n","170000\n","305500\n","38000\n","440000\n","170500\n","306000\n","38500\n","440500\n","171000\n","306500\n","39000\n","441000\n","171500\n","39500\n","307000\n","441500\n","172000\n","307500\n","40000\n","442000\n","172500\n","308000\n","40500\n","173000\n","442500\n","308500\n","41000\n","173500\n","443000\n","41500\n","309000\n","174000\n","443500\n","42000\n","309500\n","174500\n","444000\n","42500\n","310000\n","175000\n","444500\n","43000\n","310500\n","175500\n","445000\n","43500\n","311000\n","176000\n","445500\n","311500\n","44000\n","176500\n","446000\n","312000\n","44500\n","177000\n","446500\n","312500\n","45000\n","177500\n","313000\n","447000\n","45500\n","178000\n","313500\n","447500\n","46000\n","178500\n","314000\n","448000\n","46500\n","179000\n","314500\n","448500\n","47000\n","179500\n","315000\n","449000\n","47500\n","180000\n","315500\n","449500\n","48000\n","180500\n","316000\n","450000\n","48500\n","181000\n","316500\n","450500\n","49000\n","181500\n","317000\n","451000\n","182000\n","49500\n","317500\n","451500\n","182500\n","50000\n","318000\n","452000\n","183000\n","50500\n","318500\n","452500\n","183500\n","51000\n","319000\n","453000\n","184000\n","51500\n","319500\n","453500\n","184500\n","320000\n","52000\n","454000\n","185000\n","320500\n","52500\n","454500\n","185500\n","321000\n","53000\n","455000\n","321500\n","186000\n","53500\n","455500\n","322000\n","186500\n","54000\n","456000\n","187000\n","322500\n","456500\n","54500\n","187500\n","323000\n","457000\n","55000\n","188000\n","323500\n","457500\n","55500\n","188500\n","324000\n","458000\n","56000\n","189000\n","324500\n","458500\n","56500\n","189500\n","325000\n","459000\n","57000\n","190000\n","325500\n","459500\n","57500\n","190500\n","326000\n","460000\n","58000\n","191000\n","326500\n","460500\n","58500\n","191500\n","327000\n","461000\n","59000\n","192000\n","461500\n","327500\n","59500\n","192500\n","462000\n","328000\n","60000\n","193000\n","462500\n","328500\n","60500\n","193500\n","463000\n","329000\n","61000\n","194000\n","463500\n","329500\n","61500\n","194500\n","464000\n","330000\n","62000\n","195000\n","464500\n","330500\n","62500\n","195500\n","465000\n","331000\n","63000\n","196000\n","465500\n","331500\n","63500\n","196500\n","466000\n","332000\n","197000\n","64000\n","466500\n","332500\n","197500\n","64500\n","467000\n","333000\n","198000\n","65000\n","467500\n","333500\n","198500\n","65500\n","468000\n","334000\n","199000\n","66000\n","468500\n","334500\n","199500\n","66500\n","469000\n","335000\n","200000\n","67000\n","469500\n","335500\n","200500\n","67500\n","336000\n","470000\n","201000\n","68000\n","336500\n","470500\n","201500\n","68500\n","337000\n","471000\n","202000\n","69000\n","337500\n","471500\n","202500\n","69500\n","338000\n","472000\n","203000\n","70000\n","338500\n","472500\n","203500\n","70500\n","339000\n","473000\n","204000\n","71000\n","339500\n","473500\n","204500\n","340000\n","71500\n","474000\n","205000\n","72000\n","340500\n","474500\n","205500\n","72500\n","475000\n","341000\n","206000\n","73000\n","475500\n","341500\n","206500\n","73500\n","476000\n","342000\n","207000\n","74000\n","476500\n","342500\n","207500\n","74500\n","477000\n","343000\n","208000\n","75000\n","343500\n","477500\n","208500\n","75500\n","344000\n","478000\n","209000\n","76000\n","344500\n","478500\n","209500\n","76500\n","345000\n","479000\n","210000\n","77000\n","345500\n","479500\n","210500\n","77500\n","480000\n","346000\n","211000\n","78000\n","480500\n","346500\n","211500\n","78500\n","481000\n","347000\n","212000\n","79000\n","481500\n","347500\n","212500\n","79500\n","482000\n","348000\n","213000\n","80000\n","482500\n","348500\n","213500\n","80500\n","483000\n","349000\n","81000\n","214000\n","483500\n","349500\n","81500\n","214500\n","484000\n","350000\n","82000\n","215000\n","484500\n","350500\n","82500\n","215500\n","485000\n","351000\n","83000\n","216000\n","485500\n","351500\n","83500\n","216500\n","352000\n","486000\n","84000\n","217000\n","352500\n","486500\n","84500\n","217500\n","353000\n","487000\n","85000\n","218000\n","353500\n","487500\n","85500\n","218500\n","354000\n","488000\n","86000\n","219000\n","354500\n","488500\n","86500\n","219500\n","355000\n","489000\n","87000\n","220000\n","355500\n","489500\n","87500\n","220500\n","356000\n","490000\n","88000\n","221000\n","356500\n","490500\n","88500\n","221500\n","357000\n","491000\n","89000\n","357500\n","222000\n","491500\n","89500\n","358000\n","222500\n","492000\n","90000\n","358500\n","492500\n","223000\n","90500\n","359000\n","493000\n","223500\n","91000\n","359500\n","493500\n","224000\n","91500\n","360000\n","494000\n","224500\n","92000\n","360500\n","494500\n","225000\n","92500\n","361000\n","495000\n","225500\n","93000\n","361500\n","495500\n","226000\n","93500\n","362000\n","496000\n","226500\n","94000\n","362500\n","496500\n","227000\n","94500\n","363000\n","497000\n","227500\n","95000\n","363500\n","497500\n","228000\n","95500\n","364000\n","498000\n","228500\n","96000\n","364500\n","498500\n","229000\n","96500\n","365000\n","499000\n","229500\n","97000\n","365500\n","499500\n","230000\n","97500\n","366000\n","500000\n","230500\n","98000\n","366500\n","500500\n","231000\n","98500\n","367000\n","501000\n","99000\n","231500\n","367500\n","501500\n","99500\n","232000\n","368000\n","502000\n","100000\n","232500\n","368500\n","502500\n","100500\n","233000\n","369000\n","503000\n","101000\n","233500\n","369500\n","503500\n","234000\n","101500\n","370000\n","504000\n","234500\n","102000\n","370500\n","504500\n","235000\n","102500\n","371000\n","505000\n","235500\n","103000\n","371500\n","505500\n","236000\n","103500\n","372000\n","506000\n","236500\n","104000\n","372500\n","506500\n","237000\n","104500\n","373000\n","507000\n","237500\n","105000\n","373500\n","507500\n","238000\n","105500\n","374000\n","508000\n","238500\n","106000\n","374500\n","508500\n","239000\n","106500\n","375000\n","509000\n","239500\n","107000\n","375500\n","509500\n","240000\n","107500\n","376000\n","510000\n","240500\n","108000\n","376500\n","510500\n","241000\n","108500\n","377000\n","511000\n","241500\n","109000\n","377500\n","242000\n","109500\n","511500\n","378000\n","242500\n","110000\n","512000\n","378500\n","243000\n","110500\n","512500\n","379000\n","243500\n","111000\n","513000\n","379500\n","244000\n","111500\n","513500\n","380000\n","244500\n","112000\n","514000\n","380500\n","245000\n","112500\n","514500\n","381000\n","245500\n","113000\n","515000\n","381500\n","246000\n","113500\n","515500\n","382000\n","246500\n","114000\n","516000\n","382500\n","247000\n","114500\n","516500\n","383000\n","247500\n","115000\n","517000\n","383500\n","248000\n","517500\n","115500\n","384000\n","248500\n","518000\n","116000\n","384500\n","249000\n","518500\n","116500\n","385000\n","249500\n","519000\n","117000\n","385500\n","250000\n","519500\n","117500\n","386000\n","250500\n","520000\n","386500\n","118000\n","251000\n","520500\n","387000\n","118500\n","251500\n","521000\n","387500\n","119000\n","252000\n","521500\n","388000\n","119500\n","252500\n","522000\n","388500\n","120000\n","253000\n","522500\n","389000\n","120500\n","253500\n","523000\n","389500\n","121000\n","254000\n","523500\n","390000\n","121500\n","254500\n","524000\n","390500\n","122000\n","255000\n","524500\n","391000\n","122500\n","255500\n","525000\n","391500\n","123000\n","256000\n","525500\n","392000\n","123500\n","256500\n","526000\n","392500\n","124000\n","257000\n","526500\n","393000\n","124500\n","257500\n","527000\n","393500\n","125000\n","258000\n","527500\n","394000\n","125500\n","258500\n","528000\n","394500\n","126000\n","259000\n","528500\n","395000\n","126500\n","259500\n","529000\n","395500\n","127000\n","260000\n","529500\n","396000\n","127500\n","260500\n","530000\n","396500\n","128000\n","261000\n","530500\n","397000\n","128500\n","531000\n","261500\n","397500\n","129000\n","531500\n","262000\n","398000\n","129500\n","532000\n","262500\n","398500\n","130000\n","532500\n","263000\n","399000\n","130500\n","533000\n","263500\n","399500\n","131000\n","533500\n","264000\n","400000\n","534000\n","131500\n","264500\n","400500\n","534500\n","132000\n","265000\n","401000\n","535000\n","132500\n","265500\n","401500\n","535500\n","133000\n","266000\n","536000\n","402000\n","133500\n","266500\n","536500\n","402500\n","134000\n","267000\n","537000\n","403000\n","134500\n","267500\n","537500\n","135000\n","403500\n","268000\n","538000\n","135500\n","404000\n","268500\n","538500\n","136000\n","404500\n","269000\n","539000\n","136500\n","405000\n","269500\n","539500\n","137000\n","405500\n","270000\n","540000\n","406000\n","270500\n","406500\n","540500\n","271000\n","407000\n","541000\n","407500\n","271500\n","541500\n","408000\n","272000\n","542000\n","408500\n","272500\n","542500\n","409000\n","273000\n","543000\n","409500\n","273500\n","410000\n","543500\n","274000\n","544000\n","410500\n","274500\n","544500\n","411000\n","545000\n","411500\n","545500\n","412000\n","546000\n","546500\n","547000\n","547500\n","548000\n","548500\n","549000\n","549500\n","550000\n","550500\n","551000\n","551500\n","552000\n","552500\n","553000\n","553500\n","554000\n","554500\n","555000\n","555500\n","556000\n","556500\n","557000\n","687500\n","557500\n","688000\n","558000\n","688500\n","558500\n","559000\n","689000\n","559500\n","689500\n","560000\n","690000\n","690500\n","560500\n","691000\n","561000\n","825000\n","691500\n","561500\n","825500\n","692000\n","562000\n","826000\n","692500\n","562500\n","826500\n","693000\n","563000\n","827000\n","693500\n","563500\n","827500\n","694000\n","564000\n","694500\n","828000\n","564500\n","695000\n","828500\n","565000\n","695500\n","829000\n","565500\n","696000\n","829500\n","566000\n","696500\n","830000\n","697000\n","566500\n","830500\n","697500\n","567000\n","831000\n","567500\n","962500\n","831500\n","698000\n","568000\n","963000\n","832000\n","698500\n","568500\n","832500\n","963500\n","699000\n","569000\n","833000\n","964000\n","699500\n","569500\n","833500\n","964500\n","700000\n","570000\n","834000\n","965000\n","700500\n","570500\n","834500\n","965500\n","701000\n","571000\n","835000\n","966000\n","701500\n","571500\n","835500\n","966500\n","702000\n","572000\n","836000\n","967000\n","702500\n","572500\n","836500\n","967500\n","703000\n","573000\n","837000\n","968000\n","703500\n","573500\n","837500\n","704000\n","968500\n","574000\n","838000\n","704500\n","969000\n","574500\n","838500\n","705000\n","969500\n","575000\n","839000\n","705500\n","970000\n","575500\n","839500\n","706000\n","970500\n","576000\n","840000\n","706500\n","971000\n","576500\n","840500\n","707000\n","971500\n","577000\n","841000\n","707500\n","972000\n","577500\n","841500\n","972500\n","708000\n","578000\n","842000\n","973000\n","708500\n","578500\n","842500\n","973500\n","709000\n","579000\n","974000\n","843000\n","709500\n","579500\n","843500\n","974500\n","710000\n","580000\n","844000\n","975000\n","580500\n","710500\n","844500\n","975500\n","581000\n","711000\n","845000\n","976000\n","581500\n","711500\n","845500\n","976500\n","582000\n","712000\n","846000\n","977000\n","582500\n","712500\n","846500\n","977500\n","583000\n","713000\n","847000\n","978000\n","583500\n","713500\n","847500\n","978500\n","584000\n","714000\n","848000\n","979000\n","584500\n","714500\n","848500\n","979500\n","585000\n","715000\n","849000\n","980000\n","585500\n","715500\n","849500\n","980500\n","586000\n","716000\n","850000\n","981000\n","586500\n","716500\n","850500\n","981500\n","587000\n","717000\n","851000\n","982000\n","587500\n","717500\n","851500\n","982500\n","588000\n","718000\n","983000\n","852000\n","588500\n","718500\n","983500\n","852500\n","589000\n","719000\n","984000\n","853000\n","719500\n","589500\n","984500\n","853500\n","720000\n","590000\n","985000\n","854000\n","720500\n","590500\n","985500\n","854500\n","721000\n","591000\n","986000\n","855000\n","721500\n","591500\n","986500\n","855500\n","722000\n","592000\n","987000\n","856000\n","722500\n","592500\n","987500\n","856500\n","723000\n","593000\n","988000\n","857000\n","593500\n","723500\n","988500\n","857500\n","724000\n","594000\n","989000\n","858000\n","724500\n","989500\n","594500\n","858500\n","725000\n","990000\n","595000\n","859000\n","595500\n","725500\n","990500\n","859500\n","596000\n","726000\n","991000\n","860000\n","726500\n","991500\n","596500\n","860500\n","727000\n","992000\n","597000\n","861000\n","727500\n","992500\n","597500\n","861500\n","728000\n","993000\n","598000\n","862000\n","728500\n","993500\n","598500\n","862500\n","729000\n","994000\n","599000\n","863000\n","729500\n","994500\n","599500\n","863500\n","730000\n","995000\n","864000\n","600000\n","730500\n","995500\n","864500\n","600500\n","731000\n","996000\n","865000\n","601000\n","731500\n","996500\n","865500\n","601500\n","732000\n","997000\n","866000\n","602000\n","732500\n","997500\n","866500\n","602500\n","733000\n","998000\n","867000\n","603000\n","733500\n","998500\n","867500\n","603500\n","734000\n","999000\n","868000\n","734500\n","604000\n","999500\n","868500\n","735000\n","604500\n","1000000\n","869000\n","735500\n","605000\n","1000500\n","869500\n","736000\n","605500\n","1001000\n","870000\n","736500\n","1001500\n","606000\n","870500\n","737000\n","1002000\n","606500\n","871000\n","737500\n","1002500\n","607000\n","871500\n","738000\n","1003000\n","607500\n","872000\n","738500\n","1003500\n","608000\n","872500\n","739000\n","1004000\n","608500\n","873000\n","739500\n","1004500\n","609000\n","873500\n","740000\n","1005000\n","609500\n","874000\n","740500\n","1005500\n","610000\n","741000\n","874500\n","1006000\n","610500\n","741500\n","875000\n","611000\n","1006500\n","742000\n","875500\n","1007000\n","611500\n","742500\n","876000\n","1007500\n","612000\n","743000\n","876500\n","1008000\n","612500\n","743500\n","877000\n","1008500\n","613000\n","744000\n","877500\n","1009000\n","613500\n","744500\n","878000\n","1009500\n","614000\n","745000\n","878500\n","1010000\n","614500\n","745500\n","879000\n","1010500\n","615000\n","746000\n","879500\n","1011000\n","615500\n","746500\n","880000\n","1011500\n","616000\n","747000\n","880500\n","1012000\n","616500\n","747500\n","881000\n","1012500\n","617000\n","748000\n","881500\n","1013000\n","617500\n","748500\n","882000\n","1013500\n","618000\n","749000\n","882500\n","1014000\n","618500\n","749500\n","883000\n","1014500\n","619000\n","750000\n","883500\n","1015000\n","619500\n","750500\n","884000\n","1015500\n","620000\n","751000\n","884500\n","1016000\n","620500\n","751500\n","885000\n","1016500\n","621000\n","885500\n","752000\n","1017000\n","621500\n","752500\n","886000\n","1017500\n","622000\n","753000\n","886500\n","1018000\n","622500\n","753500\n","887000\n","1018500\n","623000\n","754000\n","887500\n","1019000\n","623500\n","888000\n","754500\n","1019500\n","624000\n","888500\n","755000\n","1020000\n","624500\n","889000\n","755500\n","1020500\n","625000\n","889500\n","756000\n","1021000\n","625500\n","890000\n","756500\n","1021500\n","626000\n","890500\n","757000\n","1022000\n","626500\n","891000\n","757500\n","1022500\n","627000\n","891500\n","758000\n","1023000\n","627500\n","892000\n","758500\n","1023500\n","628000\n","759000\n","892500\n","1024000\n","628500\n","759500\n","893000\n","1024500\n","629000\n","760000\n","893500\n","1025000\n","629500\n","760500\n","894000\n","1025500\n","630000\n","761000\n","894500\n","1026000\n","630500\n","761500\n","895000\n","1026500\n","631000\n","762000\n","895500\n","631500\n","1027000\n","762500\n","896000\n","632000\n","1027500\n","763000\n","896500\n","632500\n","1028000\n","763500\n","897000\n","633000\n","1028500\n","764000\n","897500\n","633500\n","1029000\n","898000\n","764500\n","634000\n","1029500\n","898500\n","765000\n","634500\n","1030000\n","899000\n","765500\n","635000\n","1030500\n","899500\n","766000\n","635500\n","1031000\n","900000\n","766500\n","1031500\n","636000\n","900500\n","767000\n","1032000\n","636500\n","901000\n","767500\n","1032500\n","637000\n","901500\n","768000\n","1033000\n","637500\n","902000\n","768500\n","1033500\n","638000\n","902500\n","769000\n","638500\n","1034000\n","903000\n","769500\n","639000\n","1034500\n","903500\n","770000\n","639500\n","1035000\n","904000\n","770500\n","640000\n","1035500\n","904500\n","771000\n","640500\n","1036000\n","905000\n","771500\n","641000\n","905500\n","1036500\n","772000\n","641500\n","906000\n","1037000\n","772500\n","642000\n","906500\n","1037500\n","773000\n","642500\n","907000\n","1038000\n","773500\n","643000\n","907500\n","1038500\n","774000\n","643500\n","908000\n","1039000\n","774500\n","644000\n","908500\n","1039500\n","775000\n","644500\n","909000\n","1040000\n","775500\n","909500\n","645000\n","1040500\n","776000\n","910000\n","645500\n","1041000\n","776500\n","910500\n","646000\n","1041500\n","777000\n","911000\n","646500\n","1042000\n","777500\n","911500\n","1042500\n","647000\n","778000\n","912000\n","1043000\n","647500\n","778500\n","912500\n","1043500\n","648000\n","779000\n","913000\n","1044000\n","648500\n","779500\n","913500\n","1044500\n","649000\n","780000\n","914000\n","1045000\n","649500\n","780500\n","914500\n","1045500\n","650000\n","781000\n","915000\n","1046000\n","650500\n","781500\n","915500\n","1046500\n","651000\n","782000\n","916000\n","1047000\n","651500\n","782500\n","916500\n","1047500\n","652000\n","783000\n","917000\n","1048000\n","783500\n","652500\n","917500\n","1048500\n","784000\n","653000\n","918000\n","1049000\n","784500\n","918500\n","653500\n","1049500\n","785000\n","919000\n","654000\n","1050000\n","785500\n","919500\n","654500\n","1050500\n","786000\n","920000\n","655000\n","1051000\n","786500\n","920500\n","655500\n","1051500\n","787000\n","656000\n","921000\n","1052000\n","787500\n","656500\n","921500\n","1052500\n","788000\n","657000\n","1053000\n","922000\n","788500\n","657500\n","1053500\n","922500\n","789000\n","658000\n","1054000\n","923000\n","789500\n","658500\n","1054500\n","923500\n","790000\n","659000\n","1055000\n","924000\n","790500\n","659500\n","1055500\n","924500\n","791000\n","660000\n","1056000\n","791500\n","925000\n","660500\n","1056500\n","792000\n","925500\n","661000\n","1057000\n","792500\n","926000\n","661500\n","1057500\n","793000\n","926500\n","662000\n","1058000\n","793500\n","927000\n","662500\n","1058500\n","794000\n","663000\n","927500\n","1059000\n","794500\n","663500\n","1059500\n","928000\n","795000\n","664000\n","1060000\n","928500\n","795500\n","664500\n","1060500\n","929000\n","796000\n","665000\n","1061000\n","929500\n","796500\n","665500\n","1061500\n","930000\n","797000\n","666000\n","1062000\n","930500\n","797500\n","666500\n","1062500\n","931000\n","798000\n","667000\n","1063000\n","931500\n","798500\n","667500\n","1063500\n","932000\n","799000\n","668000\n","1064000\n","932500\n","799500\n","668500\n","1064500\n","933000\n","800000\n","669000\n","1065000\n","933500\n","800500\n","669500\n","1065500\n","934000\n","801000\n","670000\n","1066000\n","934500\n","670500\n","801500\n","1066500\n","935000\n","671000\n","802000\n","1067000\n","935500\n","671500\n","802500\n","1067500\n","936000\n","672000\n","803000\n","1068000\n","936500\n","672500\n","803500\n","1068500\n","937000\n","673000\n","804000\n","1069000\n","937500\n","673500\n","1069500\n","804500\n","938000\n","674000\n","1070000\n","938500\n","805000\n","674500\n","1070500\n","805500\n","939000\n","675000\n","1071000\n","806000\n","939500\n","675500\n","1071500\n","806500\n","940000\n","676000\n","1072000\n","940500\n","807000\n","676500\n","1072500\n","941000\n","807500\n","677000\n","1073000\n","941500\n","808000\n","677500\n","1073500\n","942000\n","808500\n","678000\n","1074000\n","942500\n","809000\n","678500\n","1074500\n","943000\n","679000\n","809500\n","1075000\n","943500\n","679500\n","810000\n","1075500\n","944000\n","680000\n","1076000\n","810500\n","944500\n","680500\n","1076500\n","811000\n","945000\n","681000\n","1077000\n","811500\n","945500\n","681500\n","1077500\n","812000\n","946000\n","682000\n","1078000\n","812500\n","946500\n","1078500\n","682500\n","813000\n","947000\n","1079000\n","683000\n","813500\n","947500\n","1079500\n","683500\n","814000\n","948000\n","1080000\n","684000\n","814500\n","948500\n","1080500\n","684500\n","815000\n","949000\n","1081000\n","685000\n","815500\n","1081500\n","949500\n","685500\n","816000\n","950000\n","1082000\n","686000\n","816500\n","950500\n","1082500\n","686500\n","817000\n","951000\n","1083000\n","687000\n","817500\n","1083500\n","951500\n","818000\n","952000\n","1084000\n","818500\n","952500\n","1084500\n","819000\n","1085000\n","953000\n","819500\n","953500\n","1085500\n","820000\n","954000\n","1086000\n","820500\n","954500\n","1086500\n","821000\n","955000\n","1087000\n","821500\n","955500\n","1087500\n","822000\n","956000\n","822500\n","1088000\n","956500\n","823000\n","1088500\n","957000\n","823500\n","1089000\n","957500\n","824000\n","1089500\n","958000\n","824500\n","1090000\n","958500\n","1090500\n","959000\n","1091000\n","1091500\n","959500\n","1092000\n","960000\n","1092500\n","960500\n","1093000\n","961000\n","1093500\n","961500\n","1094000\n","962000\n","1094500\n","1100000\n","1095000\n","1095500\n","1100500\n","1096000\n","1096500\n","1101000\n","1097000\n","1101500\n","1097500\n","1102000\n","1098000\n","1102500\n","1098500\n","1103000\n","1099000\n","1103500\n","1099500\n","1104000\n","1104500\n","1105000\n","1105500\n","1237500\n","1106000\n","1238000\n","1106500\n","1238500\n","1107000\n","1239000\n","1107500\n","1239500\n","1108000\n","1240000\n","1240500\n","1108500\n","1241000\n","1109000\n","1241500\n","1109500\n","1242000\n","1110000\n","1242500\n","1110500\n","1243000\n","1375000\n","1111000\n","1243500\n","1375500\n","1244000\n","1111500\n","1376000\n","1244500\n","1112000\n","1376500\n","1245000\n","1112500\n","1377000\n","1113000\n","1245500\n","1377500\n","1113500\n","1246000\n","1378000\n","1114000\n","1246500\n","1378500\n","1114500\n","1247000\n","1379000\n","1247500\n","1379500\n","1115000\n","1248000\n","1115500\n","1380000\n","1248500\n","1380500\n","1116000\n","1249000\n","1381000\n","1249500\n","1381500\n","1116500\n","1512500\n","1382000\n","1250000\n","1513000\n","1117000\n","1382500\n","1513500\n","1250500\n","1117500\n","1383000\n","1251000\n","1514000\n","1118000\n","1383500\n","1251500\n","1514500\n","1118500\n","1384000\n","1252000\n","1515000\n","1119000\n","1384500\n","1252500\n","1119500\n","1515500\n","1385000\n","1253000\n","1516000\n","1120000\n","1385500\n","1253500\n","1516500\n","1120500\n","1386000\n","1254000\n","1517000\n","1121000\n","1386500\n","1254500\n","1517500\n","1121500\n","1387000\n","1255000\n","1518000\n","1122000\n","1387500\n","1255500\n","1518500\n","1122500\n","1388000\n","1256000\n","1519000\n","1123000\n","1388500\n","1256500\n","1519500\n","1123500\n","1389000\n","1257000\n","1124000\n","1520000\n","1389500\n","1124500\n","1257500\n","1390000\n","1520500\n","1125000\n","1521000\n","1258000\n","1390500\n","1125500\n","1521500\n","1258500\n","1391000\n","1126000\n","1522000\n","1259000\n","1391500\n","1126500\n","1522500\n","1259500\n","1392000\n","1127000\n","1523000\n","1260000\n","1392500\n","1127500\n","1523500\n","1260500\n","1393000\n","1128000\n","1261000\n","1524000\n","1393500\n","1128500\n","1261500\n","1524500\n","1394000\n","1129000\n","1262000\n","1525000\n","1394500\n","1129500\n","1262500\n","1525500\n","1395000\n","1130000\n","1263000\n","1526000\n","1395500\n","1130500\n","1263500\n","1526500\n","1396000\n","1131000\n","1264000\n","1527000\n","1396500\n","1131500\n","1264500\n","1527500\n","1397000\n","1132000\n","1265000\n","1528000\n","1397500\n","1132500\n","1265500\n","1528500\n","1398000\n","1133000\n","1266000\n","1529000\n","1398500\n","1133500\n","1266500\n","1529500\n","1399000\n","1134000\n","1267000\n","1530000\n","1399500\n","1134500\n","1267500\n","1530500\n","1400000\n","1135000\n","1268000\n","1531000\n","1400500\n","1135500\n","1268500\n","1531500\n","1401000\n","1136000\n","1269000\n","1532000\n","1401500\n","1136500\n","1269500\n","1532500\n","1402000\n","1137000\n","1533000\n","1270000\n","1402500\n","1137500\n","1533500\n","1270500\n","1403000\n","1138000\n","1534000\n","1271000\n","1403500\n","1138500\n","1534500\n","1271500\n","1404000\n","1139000\n","1535000\n","1272000\n","1404500\n","1139500\n","1535500\n","1272500\n","1405000\n","1140000\n","1536000\n","1273000\n","1405500\n","1140500\n","1536500\n","1273500\n","1406000\n","1141000\n","1537000\n","1274000\n","1406500\n","1141500\n","1537500\n","1274500\n","1407000\n","1142000\n","1538000\n","1275000\n","1407500\n","1142500\n","1538500\n","1408000\n","1275500\n","1143000\n","1539000\n","1408500\n","1276000\n","1143500\n","1539500\n","1409000\n","1276500\n","1144000\n","1540000\n","1409500\n","1277000\n","1144500\n","1540500\n","1410000\n","1277500\n","1145000\n","1410500\n","1541000\n","1145500\n","1278000\n","1411000\n","1541500\n","1146000\n","1278500\n","1411500\n","1542000\n","1146500\n","1279000\n","1412000\n","1542500\n","1147000\n","1279500\n","1412500\n","1543000\n","1147500\n","1280000\n","1413000\n","1543500\n","1148000\n","1280500\n","1413500\n","1544000\n","1148500\n","1281000\n","1414000\n","1544500\n","1149000\n","1281500\n","1414500\n","1545000\n","1149500\n","1282000\n","1415000\n","1545500\n","1150000\n","1282500\n","1415500\n","1546000\n","1150500\n","1283000\n","1546500\n","1416000\n","1151000\n","1283500\n","1547000\n","1416500\n","1151500\n","1284000\n","1547500\n","1417000\n","1152000\n","1284500\n","1548000\n","1417500\n","1152500\n","1285000\n","1548500\n","1418000\n","1153000\n","1285500\n","1549000\n","1418500\n","1153500\n","1286000\n","1549500\n","1419000\n","1154000\n","1286500\n","1550000\n","1419500\n","1154500\n","1287000\n","1550500\n","1420000\n","1155000\n","1287500\n","1551000\n","1420500\n","1155500\n","1288000\n","1551500\n","1421000\n","1156000\n","1288500\n","1552000\n","1421500\n","1156500\n","1289000\n","1552500\n","1422000\n","1289500\n","1157000\n","1553000\n","1422500\n","1290000\n","1157500\n","1553500\n","1423000\n","1290500\n","1158000\n","1423500\n","1554000\n","1291000\n","1158500\n","1424000\n","1554500\n","1291500\n","1159000\n","1424500\n","1555000\n","1292000\n","1159500\n","1425000\n","1555500\n","1292500\n","1160000\n","1425500\n","1293000\n","1556000\n","1160500\n","1426000\n","1293500\n","1556500\n","1161000\n","1426500\n","1294000\n","1557000\n","1161500\n","1427000\n","1294500\n","1162000\n","1557500\n","1427500\n","1295000\n","1162500\n","1558000\n","1428000\n","1295500\n","1163000\n","1558500\n","1428500\n","1296000\n","1163500\n","1559000\n","1429000\n","1296500\n","1164000\n","1559500\n","1429500\n","1297000\n","1164500\n","1560000\n","1430000\n","1297500\n","1165000\n","1560500\n","1430500\n","1165500\n","1298000\n","1561000\n","1431000\n","1166000\n","1298500\n","1561500\n","1431500\n","1166500\n","1299000\n","1562000\n","1432000\n","1299500\n","1167000\n","1562500\n","1432500\n","1300000\n","1167500\n","1563000\n","1433000\n","1300500\n","1168000\n","1563500\n","1433500\n","1301000\n","1168500\n","1564000\n","1434000\n","1301500\n","1169000\n","1564500\n","1434500\n","1169500\n","1565000\n","1302000\n","1435000\n","1170000\n","1565500\n","1435500\n","1302500\n","1566000\n","1170500\n","1436000\n","1303000\n","1566500\n","1171000\n","1436500\n","1303500\n","1567000\n","1171500\n","1437000\n","1304000\n","1567500\n","1437500\n","1172000\n","1304500\n","1568000\n","1438000\n","1172500\n","1568500\n","1305000\n","1438500\n","1173000\n","1305500\n","1569000\n","1439000\n","1173500\n","1569500\n","1306000\n","1439500\n","1174000\n","1570000\n","1306500\n","1440000\n","1174500\n","1570500\n","1307000\n","1440500\n","1175000\n","1307500\n","1571000\n","1441000\n","1175500\n","1308000\n","1571500\n","1441500\n","1176000\n","1308500\n","1572000\n","1442000\n","1176500\n","1309000\n","1572500\n","1442500\n","1177000\n","1309500\n","1573000\n","1443000\n","1177500\n","1310000\n","1573500\n","1443500\n","1178000\n","1310500\n","1574000\n","1444000\n","1178500\n","1311000\n","1444500\n","1574500\n","1179000\n","1311500\n","1445000\n","1575000\n","1179500\n","1312000\n","1445500\n","1575500\n","1180000\n","1312500\n","1446000\n","1576000\n","1180500\n","1313000\n","1446500\n","1576500\n","1181000\n","1313500\n","1447000\n","1577000\n","1181500\n","1314000\n","1577500\n","1447500\n","1182000\n","1314500\n","1578000\n","1448000\n","1182500\n","1315000\n","1578500\n","1448500\n","1183000\n","1315500\n","1449000\n","1579000\n","1183500\n","1316000\n","1449500\n","1579500\n","1184000\n","1316500\n","1450000\n","1184500\n","1580000\n","1317000\n","1450500\n","1185000\n","1580500\n","1317500\n","1451000\n","1185500\n","1581000\n","1318000\n","1451500\n","1581500\n","1186000\n","1318500\n","1452000\n","1582000\n","1186500\n","1319000\n","1452500\n","1582500\n","1187000\n","1319500\n","1453000\n","1583000\n","1187500\n","1320000\n","1583500\n","1453500\n","1188000\n","1320500\n","1584000\n","1454000\n","1188500\n","1321000\n","1584500\n","1454500\n","1189000\n","1321500\n","1585000\n","1455000\n","1189500\n","1322000\n","1585500\n","1455500\n","1190000\n","1322500\n","1586000\n","1456000\n","1190500\n","1323000\n","1586500\n","1456500\n","1191000\n","1323500\n","1587000\n","1457000\n","1191500\n","1324000\n","1587500\n","1457500\n","1192000\n","1324500\n","1588000\n","1458000\n","1192500\n","1325000\n","1588500\n","1458500\n","1193000\n","1325500\n","1589000\n","1459000\n","1193500\n","1326000\n","1589500\n","1459500\n","1194000\n","1590000\n","1326500\n","1460000\n","1194500\n","1590500\n","1327000\n","1460500\n","1195000\n","1591000\n","1327500\n","1461000\n","1195500\n","1591500\n","1328000\n","1461500\n","1196000\n","1592000\n","1328500\n","1462000\n","1196500\n","1592500\n","1329000\n","1462500\n","1197000\n","1593000\n","1329500\n","1463000\n","1197500\n","1593500\n","1330000\n","1463500\n","1198000\n","1594000\n","1330500\n","1464000\n","1198500\n","1594500\n","1331000\n","1199000\n","1464500\n","1595000\n","1331500\n","1465000\n","1199500\n","1595500\n","1332000\n","1465500\n","1200000\n","1596000\n","1332500\n","1466000\n","1200500\n","1596500\n","1333000\n","1466500\n","1201000\n","1597000\n","1333500\n","1467000\n","1201500\n","1597500\n","1334000\n","1467500\n","1202000\n","1598000\n","1334500\n","1468000\n","1202500\n","1598500\n","1335000\n","1468500\n","1203000\n","1599000\n","1335500\n","1469000\n","1203500\n","1599500\n","1336000\n","1469500\n","1204000\n","1600000\n","1336500\n","1470000\n","1204500\n","1600500\n","1337000\n","1470500\n","1205000\n","1337500\n","1601000\n","1471000\n","1205500\n","1338000\n","1601500\n","1471500\n","1206000\n","1338500\n","1602000\n","1472000\n","1206500\n","1339000\n","1472500\n","1602500\n","1207000\n","1339500\n","1473000\n","1603000\n","1207500\n","1340000\n","1473500\n","1603500\n","1208000\n","1340500\n","1604000\n","1474000\n","1208500\n","1341000\n","1604500\n","1474500\n","1209000\n","1341500\n","1605000\n","1475000\n","1209500\n","1342000\n","1605500\n","1475500\n","1210000\n","1342500\n","1606000\n","1476000\n","1210500\n","1343000\n","1606500\n","1476500\n","1211000\n","1343500\n","1607000\n","1477000\n","1211500\n","1344000\n","1607500\n","1477500\n","1212000\n","1344500\n","1608000\n","1478000\n","1212500\n","1345000\n","1608500\n","1478500\n","1213000\n","1345500\n","1609000\n","1479000\n","1213500\n","1346000\n","1609500\n","1479500\n","1214000\n","1346500\n","1610000\n","1480000\n","1214500\n","1347000\n","1610500\n","1480500\n","1215000\n","1611000\n","1347500\n","1481000\n","1215500\n","1611500\n","1348000\n","1481500\n","1216000\n","1348500\n","1612000\n","1482000\n","1216500\n","1349000\n","1612500\n","1482500\n","1217000\n","1349500\n","1613000\n","1483000\n","1217500\n","1350000\n","1613500\n","1483500\n","1218000\n","1350500\n","1614000\n","1484000\n","1218500\n","1351000\n","1614500\n","1484500\n","1219000\n","1351500\n","1615000\n","1485000\n","1219500\n","1352000\n","1615500\n","1485500\n","1220000\n","1352500\n","1616000\n","1486000\n","1220500\n","1353000\n","1616500\n","1486500\n","1353500\n","1221000\n","1617000\n","1487000\n","1354000\n","1221500\n","1617500\n","1487500\n","1354500\n","1222000\n","1618000\n","1488000\n","1355000\n","1222500\n","1618500\n","1488500\n","1355500\n","1223000\n","1619000\n","1489000\n","1356000\n","1223500\n","1619500\n","1489500\n","1356500\n","1620000\n","1224000\n","1490000\n","1357000\n","1620500\n","1224500\n","1490500\n","1357500\n","1621000\n","1225000\n","1491000\n","1358000\n","1621500\n","1225500\n","1491500\n","1358500\n","1622000\n","1226000\n","1492000\n","1359000\n","1622500\n","1226500\n","1492500\n","1359500\n","1623000\n","1227000\n","1493000\n","1360000\n","1623500\n","1227500\n","1493500\n","1360500\n","1624000\n","1228000\n","1494000\n","1624500\n","1361000\n","1228500\n","1494500\n","1361500\n","1625000\n","1229000\n","1495000\n","1362000\n","1625500\n","1229500\n","1495500\n","1362500\n","1626000\n","1230000\n","1496000\n","1363000\n","1626500\n","1230500\n","1496500\n","1363500\n","1627000\n","1231000\n","1497000\n","1627500\n","1364000\n","1231500\n","1497500\n","1628000\n","1364500\n","1232000\n","1498000\n","1628500\n","1365000\n","1498500\n","1232500\n","1629000\n","1365500\n","1499000\n","1233000\n","1629500\n","1366000\n","1499500\n","1233500\n","1630000\n","1366500\n","1500000\n","1234000\n","1630500\n","1367000\n","1500500\n","1234500\n","1631000\n","1367500\n","1501000\n","1235000\n","1631500\n","1368000\n","1501500\n","1632000\n","1235500\n","1368500\n","1502000\n","1632500\n","1236000\n","1369000\n","1502500\n","1633000\n","1236500\n","1369500\n","1503000\n","1633500\n","1237000\n","1370000\n","1503500\n","1634000\n","1370500\n","1504000\n","1634500\n","1371000\n","1504500\n","1635000\n","1371500\n","1505000\n","1635500\n","1372000\n","1505500\n","1636000\n","1372500\n","1506000\n","1636500\n","1373000\n","1506500\n","1637000\n","1373500\n","1507000\n","1637500\n","1374000\n","1507500\n","1638000\n","1374500\n","1508000\n","1638500\n","1508500\n","1639000\n","1509000\n","1639500\n","1640000\n","1509500\n","1640500\n","1510000\n","1641000\n","1510500\n","1641500\n","1511000\n","1642000\n","1511500\n","1642500\n","1512000\n","1643000\n","1643500\n","1644000\n","1644500\n","1645000\n","1645500\n","1646000\n","1646500\n","1647000\n","1650000\n","1647500\n","1648000\n","1650500\n","1651000\n","1648500\n","1649000\n","1651500\n","1652000\n","1649500\n","1652500\n","1653000\n","1653500\n","1654000\n","1654500\n","1655000\n","1655500\n","1656000\n","1656500\n","1657000\n","1657500\n","1660000\n","1658000\n","1658500\n","1659000\n","1659500\n","1660500\n","1661000\n","1661500\n","1787500\n","1662000\n","1788000\n","1788500\n","1662500\n","1789000\n","1663000\n","1789500\n","1790000\n","1663500\n","1790500\n","1664000\n","1791000\n","1664500\n","1791500\n","1665000\n","1665500\n","1792000\n","1925000\n","1666000\n","1792500\n","1925500\n","1793000\n","1666500\n","1793500\n","1926000\n","1667000\n","1794000\n","1926500\n","1667500\n","1794500\n","1668000\n","1927000\n","1795000\n","1668500\n","1927500\n","1795500\n","1669000\n","1928000\n","1669500\n","1796000\n","1928500\n","1796500\n","1670000\n","1929000\n","1797000\n","1929500\n","1670500\n","1797500\n","1930000\n","1671000\n","1798000\n","1930500\n","1671500\n","1798500\n","1672000\n","1931000\n","2062500\n","1799000\n","1672500\n","2063000\n","1931500\n","1799500\n","1673000\n","2063500\n","1932000\n","1800000\n","1673500\n","2064000\n","1800500\n","1932500\n","1674000\n","2064500\n","1801000\n","1933000\n","1674500\n","2065000\n","1933500\n","1801500\n","1675000\n","2065500\n","1934000\n","1802000\n","1675500\n","2066000\n","1934500\n","1802500\n","1676000\n","2066500\n","1935000\n","1803000\n","1676500\n","2067000\n","1935500\n","1803500\n","1677000\n","2067500\n","1936000\n","1804000\n","1677500\n","2068000\n","1936500\n","1804500\n","1678000\n","1937000\n","2068500\n","1805000\n","1678500\n","1937500\n","2069000\n","1805500\n","1679000\n","1938000\n","2069500\n","1806000\n","1679500\n","1938500\n","2070000\n","1806500\n","1680000\n","2070500\n","1939000\n","1680500\n","1807000\n","2071000\n","1939500\n","1681000\n","1807500\n","2071500\n","1940000\n","1681500\n","1808000\n","2072000\n","1940500\n","1808500\n","1682000\n","2072500\n","1809000\n","1941000\n","1682500\n","2073000\n","1809500\n","1941500\n","1683000\n","2073500\n","1942000\n","1810000\n","1683500\n","2074000\n","1942500\n","1684000\n","1810500\n","2074500\n","1943000\n","1684500\n","1811000\n","2075000\n","1943500\n","1685000\n","1811500\n","2075500\n","1944000\n","1685500\n","1812000\n","2076000\n","1944500\n","1686000\n","1812500\n","2076500\n","1945000\n","1686500\n","1813000\n","2077000\n","1945500\n","1687000\n","1813500\n","2077500\n","1946000\n","1687500\n","1814000\n","2078000\n","1946500\n","1688000\n","1814500\n","2078500\n","1947000\n","1688500\n","1815000\n","2079000\n","1947500\n","1689000\n","1815500\n","2079500\n","1948000\n","1689500\n","1816000\n","2080000\n","1948500\n","1690000\n","1816500\n","2080500\n","1949000\n","1690500\n","1817000\n","2081000\n","1949500\n","1691000\n","1817500\n","2081500\n","1950000\n","1691500\n","1818000\n","2082000\n","1950500\n","1692000\n","1818500\n","2082500\n","1951000\n","1692500\n","2083000\n","1819000\n","1951500\n","2083500\n","1693000\n","1819500\n","1952000\n","2084000\n","1693500\n","1820000\n","1952500\n","2084500\n","1694000\n","1953000\n","1820500\n","2085000\n","1694500\n","1953500\n","1821000\n","2085500\n","1695000\n","1954000\n","1821500\n","2086000\n","1695500\n","1954500\n","1822000\n","2086500\n","1696000\n","1955000\n","1822500\n","2087000\n","1696500\n","1955500\n","1823000\n","2087500\n","1697000\n","1956000\n","1823500\n","2088000\n","1697500\n","1956500\n","2088500\n","1824000\n","1698000\n","1957000\n","2089000\n","1824500\n","1698500\n","1957500\n","2089500\n","1825000\n","1699000\n","1958000\n","2090000\n","1825500\n","1699500\n","1958500\n","2090500\n","1826000\n","1700000\n","1959000\n","2091000\n","1959500\n","1700500\n","1826500\n","2091500\n","1960000\n","1701000\n","1827000\n","2092000\n","1960500\n","1701500\n","1827500\n","2092500\n","1961000\n","1702000\n","1828000\n","2093000\n","1961500\n","1702500\n","1828500\n","2093500\n","1962000\n","1703000\n","1829000\n","2094000\n","1962500\n","1703500\n","1829500\n","2094500\n","1963000\n","1704000\n","1830000\n","2095000\n","1963500\n","1704500\n","1830500\n","2095500\n","1964000\n","1705000\n","1831000\n","2096000\n","1964500\n","1705500\n","1831500\n","2096500\n","1965000\n","1706000\n","1832000\n","2097000\n","1965500\n","1706500\n","1832500\n","2097500\n","1966000\n","1707000\n","1833000\n","2098000\n","1966500\n","1707500\n","1833500\n","2098500\n","1967000\n","1708000\n","1834000\n","2099000\n","1967500\n","1708500\n","1834500\n","2099500\n","1968000\n","1709000\n","1835000\n","2100000\n","1968500\n","1709500\n","1835500\n","2100500\n","1969000\n","1710000\n","1836000\n","2101000\n","1969500\n","1710500\n","1836500\n","2101500\n","1970000\n","1711000\n","1837000\n","2102000\n","1970500\n","1711500\n","1837500\n","2102500\n","1971000\n","1712000\n","1838000\n","2103000\n","1971500\n","1712500\n","1838500\n","2103500\n","1972000\n","1839000\n","2104000\n","1713000\n","1972500\n","2104500\n","1839500\n","1713500\n","1973000\n","2105000\n","1840000\n","1973500\n","1714000\n","2105500\n","1840500\n","1974000\n","1714500\n","2106000\n","1841000\n","1974500\n","1715000\n","2106500\n","1841500\n","1975000\n","1715500\n","2107000\n","1842000\n","1975500\n","1716000\n","2107500\n","1842500\n","1976000\n","1716500\n","2108000\n","1843000\n","1976500\n","1717000\n","2108500\n","1843500\n","1977000\n","1717500\n","2109000\n","1844000\n","1977500\n","1718000\n","2109500\n","1844500\n","1978000\n","2110000\n","1718500\n","1845000\n","1978500\n","2110500\n","1719000\n","1845500\n","1979000\n","2111000\n","1719500\n","1846000\n","1979500\n","2111500\n","1720000\n","1980000\n","1846500\n","2112000\n","1720500\n","1980500\n","1847000\n","2112500\n","1721000\n","1981000\n","1847500\n","2113000\n","1721500\n","1981500\n","1848000\n","2113500\n","1722000\n","1982000\n","1848500\n","2114000\n","1722500\n","1982500\n","1849000\n","2114500\n","1723000\n","1983000\n","1849500\n","2115000\n","1723500\n","1983500\n","1850000\n","2115500\n","1724000\n","1984000\n","1850500\n","1724500\n","2116000\n","1984500\n","1851000\n","1725000\n","1985000\n","2116500\n","1851500\n","1725500\n","1985500\n","2117000\n","1852000\n","1726000\n","1986000\n","2117500\n","1852500\n","1726500\n","1986500\n","2118000\n","1853000\n","1727000\n","1987000\n","2118500\n","1853500\n","1727500\n","1987500\n","2119000\n","1854000\n","1728000\n","1988000\n","2119500\n","1854500\n","1728500\n","1988500\n","2120000\n","1855000\n","1729000\n","1989000\n","2120500\n","1729500\n","1989500\n","1855500\n","2121000\n","1730000\n","1990000\n","2121500\n","1856000\n","1730500\n","1990500\n","2122000\n","1856500\n","1731000\n","1991000\n","2122500\n","1857000\n","1731500\n","1991500\n","2123000\n","1857500\n","1732000\n","1992000\n","2123500\n","1858000\n","1732500\n","1992500\n","2124000\n","1858500\n","1733000\n","2124500\n","1993000\n","1859000\n","1733500\n","2125000\n","1993500\n","1859500\n","1734000\n","1994000\n","2125500\n","1860000\n","1734500\n","1994500\n","2126000\n","1860500\n","1735000\n","1995000\n","1861000\n","2126500\n","1735500\n","1995500\n","2127000\n","1861500\n","1736000\n","1996000\n","2127500\n","1862000\n","1736500\n","1996500\n","2128000\n","1862500\n","1737000\n","1997000\n","2128500\n","1737500\n","1863000\n","1997500\n","2129000\n","1738000\n","1863500\n","2129500\n","1998000\n","1738500\n","1864000\n","2130000\n","1998500\n","1739000\n","1864500\n","2130500\n","1999000\n","1739500\n","1865000\n","2131000\n","1999500\n","1740000\n","1865500\n","2131500\n","1740500\n","2000000\n","1866000\n","2132000\n","1741000\n","1866500\n","2000500\n","2132500\n","1741500\n","1867000\n","2001000\n","2133000\n","1742000\n","2001500\n","1867500\n","2133500\n","1742500\n","1868000\n","2002000\n","2134000\n","1743000\n","1868500\n","2002500\n","2134500\n","1743500\n","1869000\n","2003000\n","2135000\n","1744000\n","1869500\n","2003500\n","2135500\n","1744500\n","1870000\n","2004000\n","2136000\n","1745000\n","1870500\n","2004500\n","2136500\n","1745500\n","1871000\n","2005000\n","2137000\n","1746000\n","1871500\n","2005500\n","2137500\n","1746500\n","1872000\n","2006000\n","2138000\n","1747000\n","1872500\n","2138500\n","2006500\n","1747500\n","1873000\n","2139000\n","2007000\n","1748000\n","1873500\n","2139500\n","2007500\n","1748500\n","1874000\n","2140000\n","2008000\n","1749000\n","1874500\n","2008500\n","2140500\n","1749500\n","1875000\n","2009000\n","2141000\n","1750000\n","1875500\n","2009500\n","1750500\n","2141500\n","1876000\n","2010000\n","1751000\n","2142000\n","1876500\n","2010500\n","1751500\n","2142500\n","1877000\n","2011000\n","1752000\n","2143000\n","1877500\n","2011500\n","1752500\n","2143500\n","1878000\n","2012000\n","1753000\n","2144000\n","1878500\n","2012500\n","2144500\n","1753500\n","1879000\n","2013000\n","2145000\n","1754000\n","1879500\n","2013500\n","2145500\n","1754500\n","1880000\n","2014000\n","2146000\n","1880500\n","1755000\n","2014500\n","2146500\n","1881000\n","1755500\n","2015000\n","2147000\n","1881500\n","1756000\n","2015500\n","2147500\n","1882000\n","1756500\n","2016000\n","2148000\n","1882500\n","1757000\n","2016500\n","2148500\n","1883000\n","1757500\n","2017000\n","1883500\n","2149000\n","1758000\n","2017500\n","1884000\n","2149500\n","1758500\n","2018000\n","1884500\n","2150000\n","1759000\n","2018500\n","1885000\n","2150500\n","1759500\n","2019000\n","1885500\n","2151000\n","1760000\n","2019500\n","1886000\n","2151500\n","1760500\n","2020000\n","1886500\n","2152000\n","1761000\n","1887000\n","2020500\n","2152500\n","1761500\n","1887500\n","2021000\n","2153000\n","1762000\n","1888000\n","2021500\n","2153500\n","1762500\n","1888500\n","2154000\n","2022000\n","1763000\n","1889000\n","2154500\n","2022500\n","1763500\n","1889500\n","2155000\n","2023000\n","1764000\n","1890000\n","2155500\n","2023500\n","1764500\n","1890500\n","2156000\n","2024000\n","1765000\n","1891000\n","2156500\n","2024500\n","1765500\n","1891500\n","2157000\n","2025000\n","1766000\n","1892000\n","2157500\n","2025500\n","1766500\n","1892500\n","2158000\n","2026000\n","1767000\n","1893000\n","2158500\n","2026500\n","1767500\n","1893500\n","2159000\n","2027000\n","1768000\n","1894000\n","2159500\n","2027500\n","1768500\n","1894500\n","2160000\n","2028000\n","1769000\n","1895000\n","2160500\n","2028500\n","1769500\n","2161000\n","1895500\n","2029000\n","1770000\n","2161500\n","1896000\n","2029500\n","1770500\n","2162000\n","1896500\n","2030000\n","1771000\n","2162500\n","1897000\n","2030500\n","1771500\n","2163000\n","1897500\n","2031000\n","2163500\n","1772000\n","1898000\n","2031500\n","2164000\n","1772500\n","1898500\n","2032000\n","2164500\n","1773000\n","1899000\n","2032500\n","2165000\n","1773500\n","1899500\n","2033000\n","2165500\n","1774000\n","1900000\n","2033500\n","2166000\n","1774500\n","1900500\n","2034000\n","2166500\n","1775000\n","1901000\n","2034500\n","2167000\n","1775500\n","1901500\n","2035000\n","2167500\n","1776000\n","1902000\n","2035500\n","2168000\n","1776500\n","1902500\n","2036000\n","2168500\n","1903000\n","1777000\n","2036500\n","2169000\n","1903500\n","1777500\n","2037000\n","2169500\n","1904000\n","1778000\n","2037500\n","2170000\n","1904500\n","1778500\n","2038000\n","2170500\n","1905000\n","1779000\n","2038500\n","2171000\n","1905500\n","1779500\n","2039000\n","2171500\n","1906000\n","1780000\n","2039500\n","2172000\n","1906500\n","1780500\n","2040000\n","2172500\n","1907000\n","1781000\n","2040500\n","2173000\n","1907500\n","1781500\n","2041000\n","2173500\n","1782000\n","1908000\n","2041500\n","2174000\n","1782500\n","1908500\n","2042000\n","2174500\n","1783000\n","1909000\n","2042500\n","2175000\n","1783500\n","1909500\n","2043000\n","2175500\n","1784000\n","1910000\n","2043500\n","2176000\n","1784500\n","1910500\n","2044000\n","2176500\n","1785000\n","1911000\n","2044500\n","2177000\n","1785500\n","2045000\n","1911500\n","2177500\n","1786000\n","2045500\n","1912000\n","2178000\n","1786500\n","2046000\n","1912500\n","2178500\n","1787000\n","2046500\n","1913000\n","2179000\n","2047000\n","1913500\n","2179500\n","2047500\n","2180000\n","1914000\n","2048000\n","2180500\n","1914500\n","2048500\n","2181000\n","1915000\n","2181500\n","2049000\n","1915500\n","2182000\n","2049500\n","1916000\n","2182500\n","2050000\n","1916500\n","2183000\n","2050500\n","1917000\n","2183500\n","2051000\n","1917500\n","2184000\n","2051500\n","2184500\n","1918000\n","2052000\n","2185000\n","1918500\n","2052500\n","2185500\n","1919000\n","2053000\n","2186000\n","1919500\n","2053500\n","2186500\n","1920000\n","2054000\n","2187000\n","1920500\n","2054500\n","2187500\n","1921000\n","2055000\n","2188000\n","1921500\n","2055500\n","2188500\n","1922000\n","2056000\n","2189000\n","1922500\n","2189500\n","2056500\n","1923000\n","2057000\n","2190000\n","1923500\n","2057500\n","2190500\n","1924000\n","2058000\n","2191000\n","1924500\n","2058500\n","2191500\n","2059000\n","2192000\n","2059500\n","2192500\n","2060000\n","2060500\n","2193000\n","2061000\n","2193500\n","2061500\n","2194000\n","2062000\n","2194500\n","2195000\n","2195500\n","2196000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hyek5XjnZdPM","colab_type":"code","colab":{}},"source":["for r in r_list:\n","          wordtoindex.update(r[0])\n","          indextovector.extend(r[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLtusxzzZdP8","colab_type":"code","colab":{}},"source":["indextovector = np.array(indextovector, dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH6BShILZdQF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505692,"user_tz":-330,"elapsed":415,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"2f4f04a9-7813-407f-852a-9372c9e7ac5e"},"source":["indextovector.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2196018, 300)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"vr-1hkKAlgRi","colab_type":"text"},"source":["# Params"]},{"cell_type":"code","metadata":{"id":"F1YZLUtAldcF","colab_type":"code","colab":{}},"source":["class Params(object):\n","  def __init__(self, batch_size, epochs, seed, log_interval):\n","    self.batch_size = batch_size\n","    self.epochs = epochs\n","    self.seed = seed\n","    self.log_interval = log_interval\n","\n","args= Params(16,8,0,8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1oW_df2ZdRk","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"sMGSUK8PZdRl","colab_type":"code","colab":{}},"source":["def matrixize(sentencelist, sentencepad):\n","        indexlist = []\n","        for sentence in sentencelist:\n","            indexes = []\n","            for word in sentence:\n","                word = word.lower()\n","                if word not in wordtoindex: indexes.append(1)\n","                else: indexes.append(wordtoindex[word])\n","            indexlist.append(indexes)\n","        return indextovector[(pad_sequences(indexlist, maxlen=sentencepad, truncating='post', padding='post'))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdRruMEiZdRt","colab_type":"code","colab":{}},"source":["def _load_data(filename):\n","        s0,s1,labels = [],[],[]\n","        lines=open(filename,'r').read().splitlines()\n","        for line in lines:\n","            _,_,_,_, label, s0x, s1x = line.rstrip().split('\\t')[:7]\n","            labels.append(float(label))\n","            s0.append([word.lower() for word in word_tokenize(s0x) if word not in string.punctuation])\n","            s1.append([word.lower() for word in word_tokenize(s1x) if word not in string.punctuation])\n","        m0 = matrixize(s0, c['sentencepad'])\n","        m1 = matrixize(s1, c['sentencepad'])\n","        classes = np.zeros((len(labels),c['num_classes']))\n","        for i, label in enumerate(labels): # making probability distribution of classes\n","            if np.floor(label) + 1 < c['num_classes']:\n","                classes[i, int(np.floor(label)) + 1] = label - np.floor(label)\n","            classes[i, int(np.floor(label))] = np.floor(label) - label + 1\n","        return {'labels': labels, 's0': s0, 's1': s1, 'classes': classes, 'm0': m0, 'm1': m1}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTpfVvSiRAiV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTyswzfCRc63","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505706,"user_tz":-330,"elapsed":353,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"c7078112-f5e3-4601-952a-e8dfc07e6b12"},"source":["'''trainload= _load_data('sts-train.csv')\n","validation= _load_data('sts-dev.csv')\n","len(trainload['s0'])'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"trainload= _load_data('sts-train.csv')\\nvalidation= _load_data('sts-dev.csv')\\nlen(trainload['s0'])\""]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"J4dIGn7FRZ2B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505709,"user_tz":-330,"elapsed":339,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"f35b9fa6-8abd-4d45-d101-7f0ce7b25d01"},"source":["'''data_len= []\n","for i in trainload['s0']:\n","  data_len.append(len(i))\n","traiload_maxsent=max(data_len)\n","traiload_maxsent'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"data_len= []\\nfor i in trainload['s0']:\\n  data_len.append(len(i))\\ntraiload_maxsent=max(data_len)\\ntraiload_maxsent\""]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"U-eyweC0R0gf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1591623505712,"user_tz":-330,"elapsed":327,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"8f13be37-f0fa-4852-d37d-8e7087f74dd6"},"source":["'''data_len= []\n","for i in  validation['s0']:\n","  data_len.append(len(i))\n","validation_maxsent=max(data_len)\n","validation_maxsent'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"data_len= []\\nfor i in  validation['s0']:\\n  data_len.append(len(i))\\nvalidation_maxsent=max(data_len)\\nvalidation_maxsent\""]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"vMYnoNCrdNYu","colab_type":"text"},"source":["# Sampling Batch"]},{"cell_type":"code","metadata":{"id":"grGwK-j0-ctQ","colab_type":"code","colab":{}},"source":["def _sample_pairs(data,batch_size):\n","  datacopy={}\n","  for i in data.keys():\n","    datacopy[i]= []\n","  for i in range(batch_size):\n","    index = np.random.randint(len(data['labels']))\n","    #print(index)\n","    for key,value in data.items():\n","      datacopy[key].append(value[index])\n","  datacopy['classes']= torch.tensor(datacopy['classes'])\n","  datacopy['m0']= torch.tensor(datacopy['m0'])\n","  datacopy['m1']= torch.tensor(datacopy['m1'])\n","  return datacopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT33frFDlodS","colab_type":"text"},"source":["# Defining CNN Model"]},{"cell_type":"code","metadata":{"id":"GnxSiUWpl-qn","colab_type":"code","colab":{}},"source":["import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSip9cpbZdTt","colab_type":"code","colab":{}},"source":["class CNN_Model(nn.Module):\n","  def __init__(self,nh=1800):\n","    super(CNN_Model, self).__init__()\n","    self.cnn= nn.Sequential(nn.Conv1d(300,1800,1),              #(bs,300,60) -> (bs, 1800, 60)\n","                            #nn.BatchNorm1d(1800),\n","                            nn.ReLU(),\n","                            #torch.nn.Dropout(0.2),\n","                            nn.MaxPool1d(kernel_size=60))       #(bs,1800,60)-> (bs, 1800, 1)\n","\n","    self.Linear= nn.Sequential(nn.Linear(3600,nh),            #(bs, 3600)  -> (bs, 1800 )\n","                               nn.Tanh(),\n","                               nn.Linear(nh,6),               #(bs,1800)   -> (bs,6)\n","                               nn.Softmax(dim=1))\n","                            \n","    \n","\n","  def forward(self,input1, input2):\n","    input1= self.cnn(input1)\n","    input2= self.cnn(input2)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    input1= torch.flatten(input1,1)\n","    input2= torch.flatten(input2,1)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    absdiff= abs(input1 - input2)\n","    mulDifference= input1 * input2\n","    concatenate = torch.cat((absdiff,mulDifference),1)\n","    #print(concatenate.shape)\n","    output= self.Linear(concatenate)\n","    #print(output.shape)\n","    return (output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoRWbzsiS1VX","colab_type":"code","colab":{}},"source":["def weights_init(m):\n","    if isinstance(m, nn.Conv1d) or isinstance(m, torch.nn.Linear):\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        torch.nn.init.zeros_(m.bias)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRUv6bDcmYpE","colab_type":"text"},"source":["# Defining Loss"]},{"cell_type":"code","metadata":{"id":"yCG3Om6zxj-g","colab_type":"code","colab":{}},"source":["def _lossfunction(y_true,y_pred):\n","    \n","    #print(\"y_true.shape\",y_true.shape)\n","    #print(\"y_pred.shape\",y_pred.shape)\n","    ny_true = y_true[:,1] + 2*y_true[:,2] + 3*y_true[:,3] + 4*y_true[:,4] + 5*y_true[:,5]\n","    #print(ny_true)\n","    ny_pred = y_pred[:,1] + 2*y_pred[:,2] + 3*y_pred[:,3] + 4*y_pred[:,4] + 5*y_pred[:,5]\n","    #print(ny_pred)\n","    my_true = (ny_true.mean())\n","    #print(my_true)\n","    my_pred = (ny_pred.mean())\n","    #print(my_pred)\n","    var_true = (ny_true - my_true)**2\n","    var_pred = (ny_pred - my_pred)**2\n","    eps= 1e-14\n","    return -torch.sum((ny_true-my_true)*(ny_pred-my_pred),axis=-1) / (torch.sqrt(torch.sum(var_true,axis=-1)* torch.sum(var_pred,axis=-1)+eps))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6g9dYuH9x1Dx","colab_type":"text"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"QxQ4r7AzyWA-","colab_type":"text"},"source":["## Train setup"]},{"cell_type":"code","metadata":{"id":"QCWkAB75yili","colab_type":"code","colab":{}},"source":["def train_batch(net,trainload, opt,batch_size, device= 'cpu'):\n","  \n","  net.train().to(device)\n","  opt.zero_grad()\n","  \n","  \n","\n","  data= _sample_pairs(trainload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device)\n","  true_output= (data['classes']).to(device, dtype=torch.float32)\n","  pred_output= net(input1,input2).to(torch.float32)\n","  loss= _lossfunction(true_output,pred_output)\n","\n","  #loss= criterion(pred_output,true_output)\n","  loss.backward()\n","  opt.step()\n","  #print(\"lossgf\",loss.item())\n","  #return loss.item()\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUuqHGuH45FT","colab_type":"text"},"source":["## Validation Setup"]},{"cell_type":"code","metadata":{"id":"M6VfkAYo3RN5","colab_type":"code","colab":{}},"source":["def valid_batch(net,validation, opt,batch_size, device= 'cpu'):\n","  net.eval().to(device)\n","  \n","  data = _sample_pairs(validation,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device)\n","  true_output= (data['classes']).to(device, dtype=torch.float32)\n","  pred_output= net(input1,input2).to(torch.float32)\n","  loss= _lossfunction(true_output,pred_output)\n","  #loss= criterion(pred_output,true_output)\n","  #return loss.item()\n","  return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QWJNMId9pJIH","colab_type":"text"},"source":["# Full Training Setup"]},{"cell_type":"code","metadata":{"id":"Y5WzVLt2pPkA","colab_type":"code","colab":{}},"source":["def train_setup_Adam(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  net.apply(weights_init)\n","  valid_loss_min = np.Inf\n","  opt = optim.Adam(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('glove_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    #mlflow.log_metric('train_loss_KLDIV', train_loss_arr[i+1])\n","    #mlflow.log_metric('valid_loss_KLDIV', valid_loss_arr[i+1])\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'glove_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnpZLXaaJMF7","colab_type":"code","colab":{}},"source":["def train_setup_Adamax(net,lr = 0.01,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adamax(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('glove_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    #mlflow.log_metric('train_loss_KLDIV', train_loss_arr[i+1])\n","    #mlflow.log_metric('valid_loss_KLDIV', valid_loss_arr[i+1])\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'glove_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3lxuhFAopUC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505730,"user_tz":-330,"elapsed":219,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"84a90bd4-d6bb-4891-d1f9-1415fae99504"},"source":["'''net= CNN_Model()\n","train_setup(net,lr = 0.05, momentum = 0.95, device='cpu')'''\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"net= CNN_Model()\\ntrain_setup(net,lr = 0.05, momentum = 0.95, device='cpu')\""]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"-dkld6lIWW8b","colab_type":"text"},"source":["# Evaluate"]},{"cell_type":"code","metadata":{"id":"Es5Q3yGuWU9T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505731,"user_tz":-330,"elapsed":208,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"f6e1b9e8-a59b-4c60-cb7f-9a90e962e4c3"},"source":["'''net.load_state_dict(torch.load('model_cifar.pt'))'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"net.load_state_dict(torch.load('model_cifar.pt'))\""]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"2GQzXlEi-XHH","colab_type":"text"},"source":["## Evaluation Setup"]},{"cell_type":"code","metadata":{"id":"SkXPty0k-h9O","colab_type":"code","colab":{}},"source":["def eval_setup(net,batch_size = 1379, device = 'cpu'):\n","  \n","  \n","  net.load_state_dict(torch.load('glove_cross_epoch.pt'))\n","  net.eval().to(device)\n","  testload= _load_data('sts-test.csv')\n","  test_n_batch= int(len(testload['labels'])/batch_size)\n","  #print(len(testload['labels']))\n","  test_loss_arr = np.zeros(test_n_batch+ 1)\n","\n","\n","  data= _sample_pairs(testload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device)\n","  pred_output= (net(input1,input2)).to('cpu')\n","  pred= pred_output.detach().numpy()\n","  prediction = np.dot(np.array(pred),np.arange(c['num_classes']))\n","  print('pred_shape',prediction.shape)\n","  goldlabels = data['labels']\n","  result=round((pearsonr(prediction, goldlabels)[0]),4)\n","  print(\"result\",result)\n","\n","  return result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDkaR6L8Sc6s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1591623505734,"user_tz":-330,"elapsed":188,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"0857254b-a0a9-472c-b34b-ee585f9a06a2"},"source":["'''net=CNN_Model(48)\n","eval_setup(net,device = 'cuda:0')'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"net=CNN_Model(48)\\neval_setup(net,device = 'cuda:0')\""]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"uACzDtuiU-_k","colab_type":"text"},"source":["# Hyper-parameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"XmcvNaEgV0Dz","colab_type":"text"},"source":["## optim.SGD()"]},{"cell_type":"code","metadata":{"id":"36tKwylaViep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"error","timestamp":1591623505734,"user_tz":-330,"elapsed":178,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"4367c1b2-46b5-41c2-d4a6-a88f8937c431"},"source":["\n","'''for lrng in [0.01,0.001]:\n","    for mntm in [0.09,0.1,0.2]:\n","        for hidden_nodes in [1800]:\n","        \n","          expt_id = '%d_%d_%d' % (int(lrng*100), int(mntm*100), hidden_nodes)\n","          print('\\nLR = %.5f, Momentum = %.5f, Hidden nodes = %d\\n' % (lrng, mntm, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","\n","          '''with mlflow.start_run(nested=True) as run:\n","\n","            for key, value in vars(args).items():\n","              mlflow.log_param(key, value)\n","            mlflow.log_param('lr', lrng)\n","            mlflow.log_param('momentum', mntm)\n","            mlflow.log_param('hidden_nodes', hidden_nodes)'''\n","\n","          train_setup(model,lr=lrng,momentum= mntm,device='cuda:0')\n","\n","          eval_setup(model,device = 'cuda:0')'''\n","  \n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-a1dea7297fb6>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    '''with mlflow.start_run(nested=True) as run:\u001b[0m\n\u001b[0m                                                 \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"9G1MlwqpV_Tl","colab_type":"text"},"source":["## optim.adam"]},{"cell_type":"code","metadata":{"id":"ZDX421f0VWRP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591627478608,"user_tz":-330,"elapsed":3944170,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"b1daef41-f928-4aa0-e9f8-e16b4820e941"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0001,0.0005,0.0006]:\n","    \n","        for hidden_nodes in [1600,1800,2400]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adam(model,lr=learning_rate,device='cuda:0')\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score > best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'glove_cross_adam_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00010000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.724155 \tValidation Loss: -0.759911\n","Validation loss decreased (inf --> -0.759911).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.839455 \tValidation Loss: -0.768247\n","Validation loss decreased (-0.759911 --> -0.768247).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.893974 \tValidation Loss: -0.811878\n","Validation loss decreased (-0.768247 --> -0.811878).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.922450 \tValidation Loss: -0.797742\n","Epoch: 4 \tTraining Loss: -0.922223 \tValidation Loss: -0.795153\n","Epoch: 5 \tTraining Loss: -0.920373 \tValidation Loss: -0.790881\n","Epoch: 6 \tTraining Loss: -0.917072 \tValidation Loss: -0.804178\n","Epoch: 7 \tTraining Loss: -0.917823 \tValidation Loss: -0.802283\n","pred_shape (1379,)\n","result 0.7613\n","best_model_score increased (-inf --> 0.761300).  Saving model ...\n","\n","LR = 0.00010000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.751870 \tValidation Loss: -0.778110\n","Validation loss decreased (inf --> -0.778110).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.842197 \tValidation Loss: -0.778365\n","Validation loss decreased (-0.778110 --> -0.778365).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.884829 \tValidation Loss: -0.800186\n","Validation loss decreased (-0.778365 --> -0.800186).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.919923 \tValidation Loss: -0.785808\n","Epoch: 4 \tTraining Loss: -0.920475 \tValidation Loss: -0.795535\n","Epoch: 5 \tTraining Loss: -0.909527 \tValidation Loss: -0.809281\n","Validation loss decreased (-0.800186 --> -0.809281).  Saving model ...\n","Epoch: 6 \tTraining Loss: -0.939649 \tValidation Loss: -0.819586\n","Validation loss decreased (-0.809281 --> -0.819586).  Saving model ...\n","Epoch: 7 \tTraining Loss: -0.955697 \tValidation Loss: -0.820636\n","Validation loss decreased (-0.819586 --> -0.820636).  Saving model ...\n","pred_shape (1379,)\n","result 0.7548\n","\n","LR = 0.00010000, Hidden nodes = 2400\n","\n","Epoch: 0 \tTraining Loss: -0.734269 \tValidation Loss: -0.787589\n","Validation loss decreased (inf --> -0.787589).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.837819 \tValidation Loss: -0.791770\n","Validation loss decreased (-0.787589 --> -0.791770).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.884528 \tValidation Loss: -0.798481\n","Validation loss decreased (-0.791770 --> -0.798481).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.923965 \tValidation Loss: -0.822553\n","Validation loss decreased (-0.798481 --> -0.822553).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.939285 \tValidation Loss: -0.820232\n","Epoch: 5 \tTraining Loss: -0.928461 \tValidation Loss: -0.813285\n","Epoch: 6 \tTraining Loss: -0.931974 \tValidation Loss: -0.807133\n","Epoch: 7 \tTraining Loss: -0.932820 \tValidation Loss: -0.798429\n","pred_shape (1379,)\n","result 0.7581\n","\n","LR = 0.00050000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.663459 \tValidation Loss: -0.820520\n","Validation loss decreased (inf --> -0.820520).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.837526 \tValidation Loss: -0.797295\n","Epoch: 2 \tTraining Loss: -0.842405 \tValidation Loss: -0.790069\n","Epoch: 3 \tTraining Loss: -0.833588 \tValidation Loss: -0.820230\n","Epoch: 4 \tTraining Loss: -0.826589 \tValidation Loss: -0.785375\n","Epoch: 5 \tTraining Loss: -0.834796 \tValidation Loss: -0.802392\n","Epoch: 6 \tTraining Loss: -0.845184 \tValidation Loss: -0.798813\n","Epoch: 7 \tTraining Loss: -0.847151 \tValidation Loss: -0.798975\n","pred_shape (1379,)\n","result 0.7445\n","\n","LR = 0.00050000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.711836 \tValidation Loss: -0.786030\n","Validation loss decreased (inf --> -0.786030).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.858293 \tValidation Loss: -0.821916\n","Validation loss decreased (-0.786030 --> -0.821916).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.905149 \tValidation Loss: -0.816851\n","Epoch: 3 \tTraining Loss: -0.900629 \tValidation Loss: -0.815655\n","Epoch: 4 \tTraining Loss: -0.899775 \tValidation Loss: -0.799755\n","Epoch: 5 \tTraining Loss: -0.901588 \tValidation Loss: -0.809983\n","Epoch: 6 \tTraining Loss: -0.908113 \tValidation Loss: -0.815106\n","Epoch: 7 \tTraining Loss: -0.903975 \tValidation Loss: -0.822146\n","Validation loss decreased (-0.821916 --> -0.822146).  Saving model ...\n","pred_shape (1379,)\n","result 0.779\n","best_model_score increased (0.761300 --> 0.779000).  Saving model ...\n","\n","LR = 0.00050000, Hidden nodes = 2400\n","\n","Epoch: 0 \tTraining Loss: -0.568630 \tValidation Loss: -0.688206\n","Validation loss decreased (inf --> -0.688206).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.650019 \tValidation Loss: -0.697667\n","Validation loss decreased (-0.688206 --> -0.697667).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.652365 \tValidation Loss: -0.722437\n","Validation loss decreased (-0.697667 --> -0.722437).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.743462 \tValidation Loss: -0.732349\n","Validation loss decreased (-0.722437 --> -0.732349).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.760563 \tValidation Loss: -0.746019\n","Validation loss decreased (-0.732349 --> -0.746019).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.767894 \tValidation Loss: -0.722600\n","Epoch: 6 \tTraining Loss: -0.767608 \tValidation Loss: -0.765568\n","Validation loss decreased (-0.746019 --> -0.765568).  Saving model ...\n","Epoch: 7 \tTraining Loss: -0.760216 \tValidation Loss: -0.739765\n","pred_shape (1379,)\n","result 0.7177\n","\n","LR = 0.00060000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.682803 \tValidation Loss: -0.796870\n","Validation loss decreased (inf --> -0.796870).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.838533 \tValidation Loss: -0.782801\n","Epoch: 2 \tTraining Loss: -0.843857 \tValidation Loss: -0.803831\n","Validation loss decreased (-0.796870 --> -0.803831).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.894468 \tValidation Loss: -0.802348\n","Epoch: 4 \tTraining Loss: -0.896047 \tValidation Loss: -0.828240\n","Validation loss decreased (-0.803831 --> -0.828240).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.910184 \tValidation Loss: -0.792681\n","Epoch: 6 \tTraining Loss: -0.919568 \tValidation Loss: -0.807789\n","Epoch: 7 \tTraining Loss: -0.922861 \tValidation Loss: -0.801794\n","pred_shape (1379,)\n","result 0.793\n","best_model_score increased (0.779000 --> 0.793000).  Saving model ...\n","\n","LR = 0.00060000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.724136 \tValidation Loss: -0.751972\n","Validation loss decreased (inf --> -0.751972).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.853602 \tValidation Loss: -0.824246\n","Validation loss decreased (-0.751972 --> -0.824246).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.898443 \tValidation Loss: -0.807822\n","Epoch: 3 \tTraining Loss: -0.902968 \tValidation Loss: -0.806289\n","Epoch: 4 \tTraining Loss: -0.899983 \tValidation Loss: -0.817476\n","Epoch: 5 \tTraining Loss: -0.898237 \tValidation Loss: -0.797263\n","Epoch: 6 \tTraining Loss: -0.898613 \tValidation Loss: -0.800102\n","Epoch: 7 \tTraining Loss: -0.900711 \tValidation Loss: -0.803290\n","pred_shape (1379,)\n","result 0.7599\n","\n","LR = 0.00060000, Hidden nodes = 2400\n","\n","Epoch: 0 \tTraining Loss: -0.620214 \tValidation Loss: -0.623688\n","Validation loss decreased (inf --> -0.623688).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.688028 \tValidation Loss: -0.634632\n","Validation loss decreased (-0.623688 --> -0.634632).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.735953 \tValidation Loss: -0.767212\n","Validation loss decreased (-0.634632 --> -0.767212).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.768173 \tValidation Loss: -0.733001\n","Epoch: 4 \tTraining Loss: -0.743182 \tValidation Loss: -0.740418\n","Epoch: 5 \tTraining Loss: -0.741426 \tValidation Loss: -0.743529\n","Epoch: 6 \tTraining Loss: -0.755846 \tValidation Loss: -0.734045\n","Epoch: 7 \tTraining Loss: -0.817480 \tValidation Loss: -0.799894\n","Validation loss decreased (-0.767212 --> -0.799894).  Saving model ...\n","pred_shape (1379,)\n","result 0.7599\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"buyF_UyTJoE_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590769080202,"user_tz":-330,"elapsed":3987460,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"ad725d34-d420-4ec3-8a36-032c566f844c"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0001,0.0005,0.0006]:\n","    \n","        for hidden_nodes in [1600,1800,1700]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adamax(model,lr=learning_rate,device='cuda:0')\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'glove_cross_adamax_model.pt')\n","            best_model_score= eval_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00010000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.737807 \tValidation Loss: -0.781203\n","Validation loss decreased (inf --> -0.781203).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.826764 \tValidation Loss: -0.809836\n","Validation loss decreased (-0.781203 --> -0.809836).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.869590 \tValidation Loss: -0.806272\n","Epoch: 3 \tTraining Loss: -0.873411 \tValidation Loss: -0.795774\n","Epoch: 4 \tTraining Loss: -0.870513 \tValidation Loss: -0.794509\n","Epoch: 5 \tTraining Loss: -0.864493 \tValidation Loss: -0.789623\n","Epoch: 6 \tTraining Loss: -0.869042 \tValidation Loss: -0.791963\n","Epoch: 7 \tTraining Loss: -0.861585 \tValidation Loss: -0.792882\n","pred_shape (1379,)\n","result 0.7537\n","best_model_score increased (-inf --> 0.753700).  Saving model ...\n","\n","LR = 0.00010000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.735946 \tValidation Loss: -0.772099\n","Validation loss decreased (inf --> -0.772099).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.824905 \tValidation Loss: -0.767948\n","Epoch: 2 \tTraining Loss: -0.819717 \tValidation Loss: -0.786135\n","Validation loss decreased (-0.772099 --> -0.786135).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.862003 \tValidation Loss: -0.796291\n","Validation loss decreased (-0.786135 --> -0.796291).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.897587 \tValidation Loss: -0.765247\n","Epoch: 5 \tTraining Loss: -0.892929 \tValidation Loss: -0.774706\n","Epoch: 6 \tTraining Loss: -0.886495 \tValidation Loss: -0.771957\n","Epoch: 7 \tTraining Loss: -0.888807 \tValidation Loss: -0.782837\n","pred_shape (1379,)\n","result 0.7487\n","\n","LR = 0.00010000, Hidden nodes = 1700\n","\n","Epoch: 0 \tTraining Loss: -0.749019 \tValidation Loss: -0.802763\n","Validation loss decreased (inf --> -0.802763).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.834214 \tValidation Loss: -0.783076\n","Epoch: 2 \tTraining Loss: -0.831001 \tValidation Loss: -0.808294\n","Validation loss decreased (-0.802763 --> -0.808294).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.866000 \tValidation Loss: -0.809227\n","Validation loss decreased (-0.808294 --> -0.809227).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.892975 \tValidation Loss: -0.805852\n","Epoch: 5 \tTraining Loss: -0.897677 \tValidation Loss: -0.791681\n","Epoch: 6 \tTraining Loss: -0.892064 \tValidation Loss: -0.813057\n","Validation loss decreased (-0.809227 --> -0.813057).  Saving model ...\n","Epoch: 7 \tTraining Loss: -0.921704 \tValidation Loss: -0.796373\n","pred_shape (1379,)\n","result 0.769\n","best_model_score increased (0.753700 --> 0.769000).  Saving model ...\n","\n","LR = 0.00050000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.694980 \tValidation Loss: -0.784248\n","Validation loss decreased (inf --> -0.784248).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.812515 \tValidation Loss: -0.754057\n","Epoch: 2 \tTraining Loss: -0.820835 \tValidation Loss: -0.804092\n","Validation loss decreased (-0.784248 --> -0.804092).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.874936 \tValidation Loss: -0.819498\n","Validation loss decreased (-0.804092 --> -0.819498).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.907571 \tValidation Loss: -0.802898\n","Epoch: 5 \tTraining Loss: -0.914322 \tValidation Loss: -0.795591\n","Epoch: 6 \tTraining Loss: -0.916557 \tValidation Loss: -0.812969\n","Epoch: 7 \tTraining Loss: -0.917798 \tValidation Loss: -0.818528\n","pred_shape (1379,)\n","result 0.7446\n","\n","LR = 0.00050000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.728460 \tValidation Loss: -0.755709\n","Validation loss decreased (inf --> -0.755709).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.812199 \tValidation Loss: -0.790695\n","Validation loss decreased (-0.755709 --> -0.790695).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.886494 \tValidation Loss: -0.814161\n","Validation loss decreased (-0.790695 --> -0.814161).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.908910 \tValidation Loss: -0.801911\n","Epoch: 4 \tTraining Loss: -0.909127 \tValidation Loss: -0.816017\n","Validation loss decreased (-0.814161 --> -0.816017).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.934264 \tValidation Loss: -0.820139\n","Validation loss decreased (-0.816017 --> -0.820139).  Saving model ...\n","Epoch: 6 \tTraining Loss: -0.947429 \tValidation Loss: -0.795839\n","Epoch: 7 \tTraining Loss: -0.951234 \tValidation Loss: -0.780796\n","pred_shape (1379,)\n","result 0.7684\n","\n","LR = 0.00050000, Hidden nodes = 1700\n","\n","Epoch: 0 \tTraining Loss: -0.699967 \tValidation Loss: -0.702240\n","Validation loss decreased (inf --> -0.702240).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.817312 \tValidation Loss: -0.803540\n","Validation loss decreased (-0.702240 --> -0.803540).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.883492 \tValidation Loss: -0.812429\n","Validation loss decreased (-0.803540 --> -0.812429).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.916323 \tValidation Loss: -0.809756\n","Epoch: 4 \tTraining Loss: -0.915341 \tValidation Loss: -0.796768\n","Epoch: 5 \tTraining Loss: -0.917578 \tValidation Loss: -0.809333\n","Epoch: 6 \tTraining Loss: -0.911129 \tValidation Loss: -0.806388\n","Epoch: 7 \tTraining Loss: -0.906160 \tValidation Loss: -0.808395\n","pred_shape (1379,)\n","result 0.7731\n","best_model_score increased (0.769000 --> 0.773100).  Saving model ...\n","\n","LR = 0.00060000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.695323 \tValidation Loss: -0.742880\n","Validation loss decreased (inf --> -0.742880).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.783615 \tValidation Loss: -0.766563\n","Validation loss decreased (-0.742880 --> -0.766563).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.872119 \tValidation Loss: -0.785774\n","Validation loss decreased (-0.766563 --> -0.785774).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.899915 \tValidation Loss: -0.810402\n","Validation loss decreased (-0.785774 --> -0.810402).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.933681 \tValidation Loss: -0.807277\n","Epoch: 5 \tTraining Loss: -0.932408 \tValidation Loss: -0.784441\n","Epoch: 6 \tTraining Loss: -0.928222 \tValidation Loss: -0.807837\n","Epoch: 7 \tTraining Loss: -0.933368 \tValidation Loss: -0.817994\n","Validation loss decreased (-0.810402 --> -0.817994).  Saving model ...\n","pred_shape (1379,)\n","result 0.7739\n","best_model_score increased (0.773100 --> 0.773900).  Saving model ...\n","\n","LR = 0.00060000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.669385 \tValidation Loss: -0.778280\n","Validation loss decreased (inf --> -0.778280).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.788163 \tValidation Loss: -0.795020\n","Validation loss decreased (-0.778280 --> -0.795020).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.867826 \tValidation Loss: -0.814606\n","Validation loss decreased (-0.795020 --> -0.814606).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.900896 \tValidation Loss: -0.820105\n","Validation loss decreased (-0.814606 --> -0.820105).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.928388 \tValidation Loss: -0.791974\n","Epoch: 5 \tTraining Loss: -0.930337 \tValidation Loss: -0.810400\n","Epoch: 6 \tTraining Loss: -0.931056 \tValidation Loss: -0.811239\n","Epoch: 7 \tTraining Loss: -0.928209 \tValidation Loss: -0.812170\n","pred_shape (1379,)\n","result 0.7779\n","best_model_score increased (0.773900 --> 0.777900).  Saving model ...\n","\n","LR = 0.00060000, Hidden nodes = 1700\n","\n","Epoch: 0 \tTraining Loss: -0.698487 \tValidation Loss: -0.769932\n","Validation loss decreased (inf --> -0.769932).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.814371 \tValidation Loss: -0.814169\n","Validation loss decreased (-0.769932 --> -0.814169).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.876522 \tValidation Loss: -0.786875\n","Epoch: 3 \tTraining Loss: -0.879650 \tValidation Loss: -0.798631\n","Epoch: 4 \tTraining Loss: -0.869057 \tValidation Loss: -0.804892\n","Epoch: 5 \tTraining Loss: -0.872655 \tValidation Loss: -0.796407\n","Epoch: 6 \tTraining Loss: -0.881427 \tValidation Loss: -0.814853\n","Validation loss decreased (-0.814169 --> -0.814853).  Saving model ...\n","Epoch: 7 \tTraining Loss: -0.913335 \tValidation Loss: -0.793477\n","pred_shape (1379,)\n","result 0.7471\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Js120I3bTMaB","colab_type":"text"},"source":["# Practice"]},{"cell_type":"code","metadata":{"id":"99F0SRW5dyY9","colab_type":"code","colab":{}},"source":["trainload= _load_data('sts-train.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNi4lsSTdkGL","colab_type":"code","colab":{}},"source":["data=_sample_pairs(trainload,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhA8win0gR0V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589453511924,"user_tz":-330,"elapsed":1316189,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"5a47cfc1-6ac8-422d-c7ff-46ec3a8be4a6"},"source":["data_len= []\n","for i in data['s0']:\n","  data_len.append(len(i))\n","max_len_sent=max(data_len)\n","\n","rep= torch.zeros(max_len_sent, 2 ,300)\n","rep.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([9, 2, 300])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"u2UgwP2Zk23J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"status":"ok","timestamp":1589453511927,"user_tz":-330,"elapsed":1316178,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"8953d57d-b07b-4ff7-9358-6068b374650d"},"source":["(data['s0'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['blast', 'kills', '10', 'young', 'girls', 'in', 'eastern', 'afghanistan'],\n"," ['four',\n","  'blue',\n","  'and',\n","  'yellow',\n","  'planes',\n","  'flying',\n","  'over',\n","  'four',\n","  'boats']]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"1aknSKgzjzY1","colab_type":"code","colab":{}},"source":["temp=[]\n","rep[0][0]=torch.tensor(indextovector[wordtoindex['brown']])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63gsjzqaoYLv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589453511933,"user_tz":-330,"elapsed":1316161,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"68d57e61-ce4a-4f0b-c8d7-d322d11d07d4"},"source":["rep[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3741, -0.0763,  0.1093,  0.1866,  0.0299,  0.1827, -0.6320,  0.1331,\n","         -0.1290,  0.6034, -0.6804, -0.1422, -0.1336, -0.6594,  0.0524,  0.1674,\n","          0.6392,  1.7680,  0.3462, -0.6248, -0.1287, -0.1970, -0.3745,  0.3306,\n","          0.0468, -0.6535, -0.5614,  0.2274,  0.2292, -0.4158, -0.1677,  0.3354,\n","          0.0972, -0.4670, -0.0269, -0.0677, -0.1921, -0.1337,  0.0163, -0.2083,\n","          0.6486, -0.1102, -0.0510,  0.0722,  0.1877,  0.2711, -0.3142,  0.1832,\n","          0.3915, -0.2255, -0.3819,  0.3306, -0.0899, -0.3763,  0.0480, -0.2050,\n","         -0.5489,  0.3044, -0.1887, -0.3034, -0.1157, -0.3487,  0.2800,  0.0501,\n","         -0.2814, -0.2335, -0.3683, -0.1204, -0.2833,  0.1857,  0.1036,  0.2531,\n","         -0.0340,  0.1051,  0.1214, -0.1630, -0.3318,  0.1731,  0.1076, -0.9936,\n","         -0.1171,  0.4223,  0.1512,  0.3106,  0.2674, -0.4927,  1.8049,  1.0738,\n","          0.3442,  0.1128, -0.1049,  0.3694,  0.4082, -0.4037,  0.3233, -0.0939,\n","         -0.0290,  0.3825, -0.3389, -0.6132,  0.8434,  0.1593, -0.1174,  0.0806,\n","         -0.2899, -0.4439, -0.1183,  0.1658,  0.1525,  0.2386, -0.3295, -0.3199,\n","         -0.3118, -0.1919,  0.2847,  0.2568,  0.4379, -0.0233,  0.1891, -0.0850,\n","         -0.1164, -0.1102, -0.0595,  0.1155,  0.2070,  0.5587,  0.8177, -0.2563,\n","         -0.0181, -0.0410, -0.2660, -0.4568, -0.0374,  0.3325,  0.1414, -0.0630,\n","         -0.0866, -0.3327, -0.0092, -0.0355, -2.8871,  0.2453,  0.2974,  0.6599,\n","         -0.0134, -0.1089,  0.1155,  0.0526, -0.0430,  0.2285,  0.4021, -0.4891,\n","          0.0441, -0.1368, -0.7181,  0.2526, -0.5788, -0.4807, -0.2409,  0.0427,\n","         -0.0946, -0.3034, -0.3197,  0.3554,  0.0629, -0.2043, -0.2978, -0.1545,\n","          0.2443,  0.0489, -0.0773,  0.3643, -0.1513, -0.4539, -0.3431,  0.1069,\n","          0.4292, -0.0260,  0.4825,  0.3361, -0.5032,  0.2241, -0.2737, -0.4904,\n","         -0.1173,  1.0537, -0.2023,  0.0490, -0.1223,  0.1100,  0.4155, -0.1183,\n","          0.1148, -0.2663,  0.2908,  0.2541,  0.3535,  0.3172, -0.1517, -0.5050,\n","         -0.2202,  0.1163, -0.2513,  0.2280,  0.2628,  0.2107,  0.0236,  0.0769,\n","         -0.1486,  0.0720,  0.3767,  0.3536, -0.3933, -0.1338,  0.5593,  0.0337,\n","         -0.4850, -0.3276,  0.2587,  0.4876, -0.2649,  0.0329, -0.0838, -0.0638,\n","          0.1076, -0.1855, -0.0523,  0.0767, -0.2148,  0.9646, -0.2479, -0.1211,\n","          0.0394,  0.4471, -0.1380, -0.0278, -0.4937, -0.5163,  0.3386,  0.5921,\n","         -0.2013, -0.0832, -0.3758, -0.2127, -0.3856,  0.2259, -0.3722, -0.1872,\n","         -0.6052, -0.1279,  0.2344, -0.4222, -0.2354,  0.2968,  0.0678,  0.0780,\n","          0.3195, -0.0348,  0.2981,  0.4400,  0.1174,  0.0550,  0.2368,  0.8982,\n","         -0.4097,  0.0752, -0.1103, -0.4099, -0.9572,  0.5275, -0.0427,  0.2662,\n","          0.3053, -0.5190, -0.4604, -0.0938,  0.1301,  0.0193,  0.0102,  0.0076,\n","          0.2955,  0.2316, -0.0349, -0.1169, -0.3273,  0.2049,  0.4750,  0.5131,\n","         -0.1458, -0.1851, -0.0154,  0.3929, -0.0348, -0.7203, -0.3653,  0.7405,\n","          0.1084, -0.3658, -0.2882,  0.1146],\n","        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000]])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"A2XUoGKXm6bu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"ok","timestamp":1589453511935,"user_tz":-330,"elapsed":1316148,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"8bec8c76-10f6-4a78-b851-20f46a0a2943"},"source":["data['m0'][0][11]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"VB2STaT2SzyW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589453511937,"user_tz":-330,"elapsed":1316135,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"c0a150f2-e099-42fa-97b0-25f6f495f7bc"},"source":["m = nn.MaxPool1d(1)\n","input = torch.randn(6, 5)\n","input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 5])"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"xTHe3bx83kR6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1589453511939,"user_tz":-330,"elapsed":1316123,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"1ffa645f-8c60-4550-99d2-7ad8a7ebb263"},"source":["input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8696,  0.9236, -1.2735, -0.4908,  0.0378],\n","        [-0.2711, -1.3810,  0.3729, -1.0544,  0.3804],\n","        [ 0.2439,  0.7127, -0.5271,  0.8484, -1.5219],\n","        [-1.2225,  0.3181, -1.3479,  0.4878,  0.7140],\n","        [-1.1902, -0.4306, -0.3603, -1.2621,  0.3393],\n","        [-1.0988,  0.1381, -1.8079,  1.2449,  0.9523]])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"YytbQVTy2LTs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1589453511940,"user_tz":-330,"elapsed":1316107,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"b3b80f2e-4ff1-4122-c5b0-2b2100ff9849"},"source":["input.to(torch.float32)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.8696,  0.9236, -1.2735, -0.4908,  0.0378],\n","        [-0.2711, -1.3810,  0.3729, -1.0544,  0.3804],\n","        [ 0.2439,  0.7127, -0.5271,  0.8484, -1.5219],\n","        [-1.2225,  0.3181, -1.3479,  0.4878,  0.7140],\n","        [-1.1902, -0.4306, -0.3603, -1.2621,  0.3393],\n","        [-1.0988,  0.1381, -1.8079,  1.2449,  0.9523]])"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"c4ifcUQ-rE-z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"error","timestamp":1589453513791,"user_tz":-330,"elapsed":1317954,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"269e3224-c200-464f-e3f5-257fe70b9066"},"source":["output = m(input)\n","output.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-75c7badcbd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[1;32m     75\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     return torch.max_pool1d(\n\u001b[0;32m--> 496\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m max_pool1d = boolean_dispatch(\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'self' (while checking arguments for max_pool1d)"]}]},{"cell_type":"code","metadata":{"id":"AtNIYGWArTMW","colab_type":"code","colab":{}},"source":["out= torch.flatten(output, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KNDFi6QhK3V","colab_type":"code","colab":{}},"source":["out.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa8AVUN1TFka","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vo28Dj7EhNUl","colab_type":"code","colab":{}},"source":["a=torch.tensor(np.array([1,2,3]))\n","b=torch.tensor(np.array([4,5,6]))\n","a*b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec595DaW2i6W","colab_type":"code","colab":{}},"source":["c=abs(a-b)\n","\n","c"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcJ9pxdi3tIc","colab_type":"code","colab":{}},"source":["import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-r14qRP595v","colab_type":"code","colab":{}},"source":["torch.cat((a,b),1).shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-F3HFrZ_ASV5","colab_type":"code","colab":{}},"source":["c= torch.randn(2, 5)\n","d= torch.randn(2,5)\n","e= torch.cat((c,d),1)\n","e.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sk0E5F22DpCX","colab_type":"code","colab":{}},"source":["(c-d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwGrQJ4TENvS","colab_type":"code","colab":{}},"source":["-1.5705-1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9NMh84DEcqd","colab_type":"code","colab":{}},"source":["(c*d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-V2_tVDEsj4","colab_type":"code","colab":{}},"source":["-1.5705*1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSrDjaRbEw58","colab_type":"code","colab":{}},"source":["-0.6561*-0.2841"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3FunLaWZdOb","colab_type":"code","colab":{}},"source":["'''blocksize=2\n","k= ((li[block:block+blocksize], block) for block in range(0,len(li),blocksize))\n","for i,j in k:\n","    print(i,j)'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKmW1OrSE5Fi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIw11E00ZdOp","colab_type":"code","colab":{}},"source":["'''def worker(args):\n","        print(args[0])\n","        print(args[1])'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFRV8fpxq6_H","colab_type":"code","colab":{}},"source":["p= np.random.randn(1,5)\n","p"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zoIsaS3SLTFy","colab_type":"text"},"source":["# comparing different losses"]},{"cell_type":"code","metadata":{"id":"GZHCtr3MIZRR","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdtczaL6KBuo","colab_type":"code","colab":{}},"source":["loss = nn.NLLLoss()\n","klloss= nn.KLDivLoss(reduction='batchmean')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZnrMpP_g69B","colab_type":"code","colab":{}},"source":["pred = torch.tensor(([0.21, 0.79], [0.68, 0.32]), dtype = torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n-4ENROQg-pF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1589861566981,"user_tz":-330,"elapsed":1120,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"4f5ada14-8f83-41ba-cd78-71c9041508c8"},"source":["pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2100, 0.7900],\n","        [0.6800, 0.3200]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"40KyJ78Nky5o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1589861682562,"user_tz":-330,"elapsed":925,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"3c072806-aed9-4786-8127-b44a4a059849"},"source":["target1 = torch.tensor(([0.2,0.8],[0.7,0.3]),dtype = torch.float)\n","target=torch.max(target1,1)[1]\n","print(target1)\n","print(target)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.2000, 0.8000],\n","        [0.7000, 0.3000]])\n","tensor([1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tkjDj664iChg","colab_type":"code","colab":{}},"source":["def cross_entropy(pred,target):\n","  output = loss(torch.log(pred), target)\n","  print(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07NJSXCSL1_C","colab_type":"code","colab":{}},"source":["def crosse_wo_onehot(pred,target1):\n","  print((-(target1[0,0]*pred[0,0 ]) - (target1[0,1]*pred[0,1 ]) - (target1[1,0]*pred[1,0 ]) - (target1[1,1]*pred[1,1 ])) / 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9JI9__zJgmk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589861823506,"user_tz":-330,"elapsed":1170,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"f78f808d-d264-4d92-bf80-80cd601b1549"},"source":["crosse_wo_onehot(pred,target1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.5563)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"52zsVz05LMBt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"69defKeBLL9x","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJDHRWXZJkiU","colab_type":"code","colab":{}},"source":["pred = torch.tensor(([0.25, 0.75], [0.65, 0.35]), dtype = torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKUX8aXYJx5E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1589863358822,"user_tz":-330,"elapsed":1233,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"9eba6f14-d05d-41fc-8925-ddb280921e02"},"source":["cross_entropy(pred,target)\n","pred_log= torch.log(pred)\n","crosse_wo_onehot(pred_log,target1)\n","print(klloss(pred_log,target1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.3592)\n","tensor(0.5619)\n","tensor(0.0063)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Wnp7Q-3iItU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1589878429703,"user_tz":-330,"elapsed":5875,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"4cdb7274-025e-4396-ded6-9ff09c65f8f7"},"source":["!pip3 install fasttext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.4)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4u3_5NmmzZe6","colab_type":"code","colab":{}},"source":["import fasttext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob4S8PPhSRAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1589797017995,"user_tz":-330,"elapsed":6265,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"b05d09e6-ca55-46d3-93e9-a333d495734f"},"source":["!pip3 install sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/9c/796934ee6d990d504c600056aa435e31bd49dbfba37e81d2045d37c8bdaf/sh-1.13.1-py2.py3-none-any.whl (40kB)\n","\r\u001b[K     |████████▏                       | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: sh\n","Successfully installed sh-1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B8halLzUSCrO","colab_type":"code","colab":{}},"source":["from sh import gunzip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nG77mvsYSd9a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1589797346675,"user_tz":-330,"elapsed":271147,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"dcf5149e-4506-41f9-b0cd-15a3751e67ae"},"source":["gunzip('cc.en.300.bin.gz')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"wRGuDp0Sz0E_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"error","timestamp":1589878455965,"user_tz":-330,"elapsed":1232,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"cfd4bdbd-0a4b-410e-8f2f-0efc4145e962"},"source":["ft = fasttext.load_model('cc.en.300.bin')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-db24633ede55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cc.en.300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;34m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, args)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cc.en.300.bin cannot be opened for loading!"]}]},{"cell_type":"code","metadata":{"id":"tqOL3ooG0KZC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589798269505,"user_tz":-330,"elapsed":1385,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"0fe8f2c1-7b03-4ad8-a883-b33215feacde"},"source":["ft.get_word_vector('hello')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.57576188e-01,  4.37820926e-02, -4.51271934e-03,  6.65931404e-02,\n","        7.70346820e-02,  4.85855248e-03,  8.19822028e-03,  6.52402919e-03,\n","        9.25899856e-03,  3.53899002e-02, -2.31395271e-02, -4.91807126e-02,\n","       -8.32642540e-02,  1.56014524e-02,  2.54856616e-01,  3.45423706e-02,\n","       -1.07451361e-02, -7.80188590e-02, -7.08099529e-02,  7.62385577e-02,\n","       -6.09613657e-02,  4.48625796e-02, -7.29744136e-02,  1.30583309e-02,\n","        3.14881057e-02, -3.10055036e-02,  1.66004002e-02,  1.74405202e-02,\n","       -7.35838860e-02,  1.18252613e-01, -1.21330231e-01, -4.09253240e-02,\n","        2.93969568e-02,  4.84445989e-02, -1.33816330e-02, -1.74765270e-02,\n","        7.51308873e-02,  9.97046307e-02, -4.00476977e-02,  4.05735290e-03,\n","       -7.21896589e-02, -4.43356819e-02, -1.22628408e-03,  7.56693557e-02,\n","        3.98401320e-02,  3.22643593e-02,  1.95914153e-02,  4.68016043e-02,\n","       -1.46228177e-02,  1.12967767e-01,  3.15065160e-02, -1.02312110e-01,\n","        1.58124104e-01, -2.76147053e-02, -3.39851156e-02, -1.77006852e-02,\n","       -5.73529862e-04,  1.10789239e-01, -1.64533369e-02, -3.14955460e-03,\n","       -4.22914140e-02,  1.11429848e-01, -5.31049855e-02,  4.91117276e-02,\n","        9.10004079e-02,  6.57141507e-02, -3.71061601e-02,  3.81702930e-02,\n","        7.25173131e-02, -5.31874336e-02,  3.06243524e-02, -5.77391349e-02,\n","       -8.07492957e-02, -9.05582383e-02, -8.05390999e-02, -6.03040010e-02,\n","       -9.73476470e-02,  4.83466834e-02,  6.79628998e-02, -2.63391621e-03,\n","       -8.63242708e-03, -5.09856315e-03,  3.15496624e-02,  6.66525513e-02,\n","        3.12875141e-04, -8.35073516e-02,  4.45498899e-02,  3.60494666e-02,\n","       -2.06746310e-02, -6.20845817e-02, -9.07698199e-02, -4.88502011e-02,\n","        1.32845968e-01,  1.26201622e-02,  4.61448133e-02, -5.53582981e-02,\n","        2.26286706e-03,  4.92154472e-02,  3.35916355e-02,  6.64286166e-02,\n","       -8.92760456e-02, -5.37227653e-02,  1.32202283e-01, -9.05150920e-03,\n","        3.26110516e-03, -4.37462777e-02,  7.51723945e-02, -4.36847992e-02,\n","       -3.93423960e-02,  4.89794314e-02,  8.05674866e-02, -3.93629894e-02,\n","       -7.60222226e-02,  7.16625601e-02, -1.88665651e-02, -4.20744009e-02,\n","        3.32255103e-03, -2.13907361e-02, -1.30127341e-01,  1.37401130e-02,\n","       -5.14834598e-02,  3.86724435e-02,  4.92810011e-02, -6.17840439e-02,\n","       -3.39861885e-02,  3.51758078e-02,  2.59123407e-02, -1.02832042e-01,\n","        6.01336509e-02, -7.14224055e-02, -2.23655030e-02, -1.03390224e-01,\n","       -6.34965971e-02,  1.22897769e-03, -8.42045806e-03, -7.10138381e-02,\n","       -1.38788186e-02,  9.29828510e-02, -7.62190223e-02, -1.79991737e-01,\n","        4.98081669e-02,  5.59808277e-02,  4.36702892e-02,  1.68789774e-02,\n","       -3.51566449e-02,  5.45868883e-03, -1.51729390e-01,  8.31367448e-03,\n","        1.33901536e-01,  1.18388735e-01, -2.54749060e-02, -5.89675866e-02,\n","       -1.15508147e-01, -9.11533982e-02, -3.26217338e-02,  9.58938058e-03,\n","        7.08419904e-02, -1.19613513e-01, -2.44825650e-02,  4.67297807e-02,\n","       -1.05831511e-01,  8.39347020e-03, -3.59367356e-02, -7.11603984e-02,\n","        1.49144500e-01, -9.40826610e-02,  3.87760401e-02,  4.80452590e-02,\n","        2.00118758e-02,  5.70331514e-02, -5.09383976e-02, -1.54985264e-02,\n","       -3.21162455e-02,  6.39992654e-02,  4.45546657e-02, -5.41638955e-02,\n","        2.38869134e-02,  3.99200059e-02,  4.95060384e-02, -8.13021213e-02,\n","        8.67957771e-02,  2.78793890e-02,  2.23497916e-02,  6.88121617e-02,\n","        5.80286458e-02,  1.24275330e-02,  9.18484554e-02,  1.70225650e-02,\n","       -2.20671259e-02, -5.54737449e-02,  3.15260515e-03, -8.95306170e-02,\n","       -5.89935109e-04, -4.80783619e-02, -4.11259457e-02, -3.47180255e-02,\n","       -4.23192009e-02,  1.01052016e-01,  4.34643961e-02,  6.75219819e-02,\n","       -7.32917935e-02,  2.32507251e-02,  3.76763381e-02,  9.02093761e-03,\n","       -8.25045630e-02, -9.67509300e-02,  5.91404364e-03,  2.62256898e-02,\n","       -2.22521871e-02,  7.38612264e-02, -1.88500714e-03, -9.77522582e-02,\n","       -5.37980236e-02, -4.76639681e-02, -1.30426334e-02,  8.38671811e-04,\n","        2.90181581e-02, -3.12499143e-03, -9.28533375e-02,  6.73858598e-02,\n","       -1.85458809e-01,  4.01153788e-02, -5.62882163e-02,  6.18898645e-02,\n","        8.93600285e-02, -6.91142231e-02, -3.22221480e-02, -1.35385573e-01,\n","       -7.45606720e-02,  1.01488158e-01, -2.72288243e-03,  6.07009046e-02,\n","        2.42582299e-02, -1.51890054e-01, -2.93815900e-02, -4.21775132e-03,\n","        5.16449586e-02,  1.85986951e-01, -2.56413780e-02,  8.12229067e-02,\n","        3.16283293e-03, -3.35572846e-02,  3.90090160e-02, -7.37856179e-02,\n","        1.14605539e-01, -7.38329254e-05, -3.69094908e-02,  9.31020677e-02,\n","       -2.92852186e-02,  5.21238521e-02,  7.99705926e-03, -2.93293986e-02,\n","        1.31182939e-01, -8.32130760e-02, -3.40401530e-02,  1.21310152e-01,\n","        3.51337232e-02,  4.17837035e-03,  5.03289811e-02,  2.06086487e-02,\n","        7.90461749e-02, -4.95089963e-02,  2.54211240e-02, -2.95754354e-02,\n","       -2.65460461e-02,  5.42523079e-02, -5.52508160e-02,  1.06864944e-02,\n","       -3.00089158e-02, -6.05286062e-02,  8.54329094e-02, -6.65596053e-02,\n","       -6.78129196e-02,  3.51911336e-02,  6.19770139e-02,  4.80552204e-02,\n","       -3.45021002e-02, -2.87248623e-02, -5.90536669e-02, -5.05724642e-03,\n","       -9.74042267e-02,  1.88945048e-03, -9.06497836e-02,  1.47764226e-02,\n","       -9.77678970e-02,  3.95894758e-02,  2.82567330e-02, -9.28364843e-02,\n","       -8.16594157e-03, -4.56805378e-02,  1.12314738e-01,  8.59746262e-02,\n","       -1.47517517e-01,  8.33301097e-02,  9.94666740e-02, -3.67202386e-02,\n","        6.84743300e-02,  8.06697235e-02, -4.50269580e-02, -3.11294980e-02],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"_HBgEsYKW8jP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589798255468,"user_tz":-330,"elapsed":1230,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"f5e5e63a-3bfb-4890-da10-048e91f4ec04"},"source":["ft"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<fasttext.FastText._FastText at 0x7f4bcf7e0c18>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"kLVC2dX5XDU7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}