{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"fasttext_cross.ipynb","provenance":[{"file_id":"1uQ45aKC1kvpKNW_91iy6tqsoixHScEm8","timestamp":1589912225093},{"file_id":"1yqdy1wAa1K44GBjjCnjhVdfHdzv0FhOd","timestamp":1588956399944}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SH2wpCTYZdMh","colab_type":"code","colab":{}},"source":["import numpy as np\n","import multiprocessing as mp\n","import random,copy,string\n","from nltk.tokenize import word_tokenize\n","from scipy.stats import pearsonr\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.layers import Input, Convolution1D, MaxPooling1D, Flatten\n","from tensorflow.python.keras.layers import Lambda, multiply, concatenate, Dense\n","from tensorflow.python.keras.regularizers import l2\n","from tensorflow.python.keras.callbacks import Callback\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Q_ABwOwnYl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590785066196,"user_tz":-330,"elapsed":6890,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"8c444189-f31a-43e1-91f2-d7a40e976064"},"source":["import os, string, random, time, math\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import torch\n","'''import mlflow\n","import mlflow.pytorch'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import mlflow\\nimport mlflow.pytorch'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"JQcOsPfMJL1-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1590785066673,"user_tz":-330,"elapsed":7346,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"8f00dd11-29f1-4724-a48f-fcd27edbb234"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"OGmtx8I_6Ci6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1590785088925,"user_tz":-330,"elapsed":29579,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"36d62c14-2ba5-40d2-859f-c850c1b4df8b"},"source":["'''from google.colab import drive\n","drive.mount('/content/drive')'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ae7JCVPfnj-p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590785088928,"user_tz":-330,"elapsed":29564,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"f6f157eb-f3ca-4e1d-c324-3fb398c71e86"},"source":["#cd 'drive/My Drive'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dAPg3_LAoKHs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"ok","timestamp":1590785091660,"user_tz":-330,"elapsed":32276,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"b7c53f24-760f-4707-b055-dc3cb5240607"},"source":["#ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34m2017_takelab+cnn\u001b[0m/                     sts-dev.csv\n"," \u001b[01;34m2017_takelab_MLP\u001b[0m/                     sts-test.csv\n"," \u001b[01;34m2017_takelab_SVR\u001b[0m/                     sts-train.csv\n"," cc.en.300.bin                         takelab_jc.txt\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/                     takelab_lin.txt\n"," fasttext_cross_cnn_code.ipynb         takelab_output_MSRpar.txt\n"," full.txt                              temp.ipynb\n","'Getting started.pdf'                  temp_word2vec_kl.ipynb\n"," GoogleNews-vectors-negative300.bin    \u001b[01;34mthesis\u001b[0m/\n"," jc_lin.txt                            word2vec_cross_adam_model.pt\n"," model_cifar.pt                        word2vec_cross_cnn_code.ipynb\n"," processed_full.txt                    word2vec_cross_epoch.pt\n"," processed_jc_lin.txt                  word2vec_kl_cnn_code.ipynb\n"," processed_takelab_jc.txt              word2vec_kl_epoch.pt\n"," processed_takelab_lin.txt             word2vec_kl_model.pt\n"," processed_takelab_output_MSRpar.txt   wv_wlsa.txt\n"," processed_wv_wlsa.txt                 wv_wwv.txt\n"," processed_wv_wwv.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aN1UtOJrZdM5","colab_type":"code","colab":{}},"source":["c = dict()\n","c['num_runs']   = 3\n","c['num_epochs'] = 2\n","c['num_batchs'] = 4\n","c['batch_size'] = 3\n","c['wordvectdim']  = 300\n","c['sentencepad']  = 60\n","c['num_classes']  = 6\n","c['cnnfilters']     = {1: 1800}\n","c['cnninitial']     = 'he_uniform'\n","c['cnnactivate']    = 'relu'\n","c['densedimension'] = list([1800])\n","c['denseinitial']   = 'he_uniform'\n","c['denseactivate']  = 'tanh'\n","c['optimizer']  = 'adam'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGZC-I84ZdNN","colab_type":"code","colab":{}},"source":["wordvectdim=300\n","wordtoindex= dict()\n","indextovector= []\n","indextovector.append(np.zeros(wordvectdim))    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI95iihPfWFV","colab_type":"text"},"source":["# Loading word vectors"]},{"cell_type":"code","metadata":{"id":"5sOYuK24UniQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"ok","timestamp":1590785140139,"user_tz":-330,"elapsed":80715,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"fa027821-aa64-4a70-a194-7000dad4a8c5"},"source":["!pip3 install fasttext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fasttext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n","\r\u001b[K     |████▊                           | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n","\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.4)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3018054 sha256=3042350d7f540e2b278c7ce0c31c2ef9025b9b956e9fc0164caac1857e7fdf1e\n","  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e_m1YW_vUTF0","colab_type":"code","colab":{}},"source":["import fasttext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xygLK_HgUtAM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1590785315050,"user_tz":-330,"elapsed":255591,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"0528432b-038b-4178-e99b-f7890c5f4434"},"source":["ft = fasttext.load_model('../cc.en.300.bin')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vr-1hkKAlgRi","colab_type":"text"},"source":["# Params"]},{"cell_type":"code","metadata":{"id":"F1YZLUtAldcF","colab_type":"code","colab":{}},"source":["class Params(object):\n","  def __init__(self, batch_size, epochs, seed, log_interval):\n","    self.batch_size = batch_size\n","    self.epochs = epochs\n","    self.seed = seed\n","    self.log_interval = log_interval\n","\n","args= Params(16,6,0,8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1oW_df2ZdRk","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"v87IpbJR9gDG","colab_type":"code","colab":{}},"source":["def matrixize(sentencelist, sentencepad):\n","  padding= np.zeros(300)\n","  matrix= np.zeros((len(sentencelist),sentencepad,300 ))\n","  m=0\n","  s=1\n","\n","  for i in range(len(sentencelist)):\n","    for j in range(len(sentencelist[i])):\n","      try:\n","        matrix[i][j]= ft.get_word_vector(sentencelist[i][j])\n","      except:\n","        print(sentencelist[i][j])\n","        matrix[i][j]= np.random.normal(m,s,300)/norm(np.random.normal(m,s,300) + 1e-8)\n","\n","  return matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdRruMEiZdRt","colab_type":"code","colab":{}},"source":["def _load_data(filename):\n","        s0,s1,labels = [],[],[]\n","        lines=open(filename,'r',encoding='utf-8').read().splitlines()\n","        for line in lines:\n","            _,_,_,_, label, s0x, s1x = line.rstrip().split('\\t')[:7]\n","            labels.append(float(label))\n","            s0.append([word.lower() for word in word_tokenize(s0x) if word not in string.punctuation])\n","            s1.append([word.lower() for word in word_tokenize(s1x) if word not in string.punctuation])\n","\n","        m0 = matrixize(s0, c['sentencepad'])\n","        m1 = matrixize(s1, c['sentencepad'])\n","        classes = np.zeros((len(labels),c['num_classes']))\n","        for i, label in enumerate(labels): # making probability distribution of classes\n","            if np.floor(label) + 1 < c['num_classes']:\n","                classes[i, int(np.floor(label)) + 1] = label - np.floor(label)\n","            classes[i, int(np.floor(label))] = np.floor(label) - label + 1\n","            \n","        return {'labels': labels, 's0': s0, 's1': s1, 'classes': classes, 'm0': m0, 'm1': m1}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vMYnoNCrdNYu","colab_type":"text"},"source":["# Sampling Batch"]},{"cell_type":"code","metadata":{"id":"grGwK-j0-ctQ","colab_type":"code","colab":{}},"source":["def _sample_pairs(data,batch_size):\n","  datacopy={}\n","  for i in data.keys():\n","    datacopy[i]= []\n","  for i in range(batch_size):\n","    index = np.random.randint(len(data['labels']))\n","    #print(index)\n","    for key,value in data.items():\n","      datacopy[key].append(value[index])\n","  datacopy['classes']= torch.tensor(datacopy['classes'])\n","  datacopy['m0']= torch.tensor(datacopy['m0'])\n","  datacopy['m1']= torch.tensor(datacopy['m1'])\n","  return datacopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT33frFDlodS","colab_type":"text"},"source":["# Defining CNN Model"]},{"cell_type":"code","metadata":{"id":"GnxSiUWpl-qn","colab_type":"code","colab":{}},"source":["import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSip9cpbZdTt","colab_type":"code","colab":{}},"source":["class CNN_Model(nn.Module):\n","  def __init__(self,nh):\n","    super(CNN_Model, self).__init__()\n","    self.cnn= nn.Sequential(nn.Conv1d(300,1800,1),              #(bs,300,60) -> (bs, 1800, 60)\n","                          \n","                            nn.LeakyReLU(0.01),\n","                            nn.MaxPool1d(kernel_size=60))       #(bs,1800,60)-> (bs, 1800, 1)\n","\n","    self.Linear= nn.Sequential(nn.Linear(3600,nh),            #(bs, 3600)  -> (bs, 1800 )\n","                               nn.LeakyReLU(0.01),\n","                               nn.Linear(nh,6),               #(bs,1800)   -> (bs,6)\n","                               nn.Softmax(dim=1))\n","                            \n","    \n","\n","  def forward(self,input1, input2):\n","    input1= self.cnn(input1)\n","    input2= self.cnn(input2)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    input1= torch.flatten(input1,1)\n","    input2= torch.flatten(input2,1)\n","    #print(\"input1=\",input1.shape)\n","    #print(\"input2=\",input2.shape)\n","    absdiff= abs(input1 - input2)\n","    mulDifference= input1 * input2\n","    concatenate = torch.cat((absdiff,mulDifference),1)\n","    #print(concatenate.shape)\n","    output= self.Linear(concatenate)\n","    #print(output.shape)\n","    return (output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"41iK7OkW5QjB","colab_type":"code","colab":{}},"source":["def weights_init(m):\n","    if isinstance(m, nn.Conv1d) or isinstance(m, torch.nn.Linear):\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        torch.nn.init.zeros_(m.bias)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"34bjQlMn74Hh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1590785315066,"user_tz":-330,"elapsed":255522,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"38db83f5-429a-4f5b-d0b0-38ee0958855d"},"source":["'''class CNN_Model(nn.Module):\n","  def __init__(self,nh=1800):\n","    super(CNN_Model, self).__init__()\n","    self.bi_cnn= nn.Sequential(nn.Conv1d(300,600,2),                   #(bs,300,60) -> (bs,600, 59)\n","                                nn.ReLU(0.01),\n","                                nn.MaxPool1d(kernel_size=59))           #(bs,600,59) -> (bs,600, 1) \n","\n","\n","    self.tri_cnn= nn.Sequential(nn.Conv1d(300,600,3),                    #(bs,300,60) -> (bs,600, 58)\n","                                nn.ReLU(0.01),\n","                                nn.Dropout(0.4),\n","                                nn.MaxPool1d(kernel_size=58))             #(bs,300,60) -> (bs,600,1)\n","\n","    self.four_cnn= nn.Sequential(nn.Conv1d(300,600,4),                   #(bs,300,60) -> (bs,600, 57)\n","                                nn.ReLU(0.01),\n","                                nn.Dropout(0.4),\n","                                nn.MaxPool1d(kernel_size=57))           #(bs,600,59) -> (bs,600, 1)                                       \n","\n","\n","    self.Linear= nn.Sequential(nn.Linear(3600,nh),            #(bs, 3600)  -> (bs, 1800 )\n","                               nn.ReLU(0.01),\n","                               nn.Linear(nh,6),               #(bs,1800)   -> (bs,6)\n","                               nn.Softmax(dim=1))\n","                            \n","    \n","\n","  def forward(self,input1, input2):\n","    inp1_1= self.bi_cnn(input1)\n","    inp1_2= self.tri_cnn(input1)\n","    inp1_3= self.four_cnn(input1)\n","    concatenate1 = torch.cat((inp1_1,inp1_2,inp1_3),1)\n","\n","    inp2_1= self.bi_cnn(input2)\n","    inp2_2= self.tri_cnn(input2)\n","    inp3_3= self.four_cnn(input2)\n","    concatenate2 = torch.cat((inp1_1,inp1_2,inp1_3),1)\n","\n","    input1= torch.flatten(concatenate1,1)\n","    input2= torch.flatten(concatenate2,1)\n","\n","    absdiff= abs(input1 - input2)\n","    mulDifference= input1 * input2\n","\n","    concatenate = torch.cat((absdiff,mulDifference),1)\n","    output= self.Linear(concatenate)\n","\n","    return (output)'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'class CNN_Model(nn.Module):\\n  def __init__(self,nh=1800):\\n    super(CNN_Model, self).__init__()\\n    self.bi_cnn= nn.Sequential(nn.Conv1d(300,600,2),                   #(bs,300,60) -> (bs,600, 59)\\n                                nn.ReLU(0.01),\\n                                nn.MaxPool1d(kernel_size=59))           #(bs,600,59) -> (bs,600, 1) \\n\\n\\n    self.tri_cnn= nn.Sequential(nn.Conv1d(300,600,3),                    #(bs,300,60) -> (bs,600, 58)\\n                                nn.ReLU(0.01),\\n                                nn.Dropout(0.4),\\n                                nn.MaxPool1d(kernel_size=58))             #(bs,300,60) -> (bs,600,1)\\n\\n    self.four_cnn= nn.Sequential(nn.Conv1d(300,600,4),                   #(bs,300,60) -> (bs,600, 57)\\n                                nn.ReLU(0.01),\\n                                nn.Dropout(0.4),\\n                                nn.MaxPool1d(kernel_size=57))           #(bs,600,59) -> (bs,600, 1)                                       \\n\\n\\n    self.Linear= nn.Sequential(nn.Linear(3600,nh),            #(bs, 3600)  -> (bs, 1800 )\\n                               nn.ReLU(0.01),\\n                               nn.Linear(nh,6),               #(bs,1800)   -> (bs,6)\\n                               nn.Softmax(dim=1))\\n                            \\n    \\n\\n  def forward(self,input1, input2):\\n    inp1_1= self.bi_cnn(input1)\\n    inp1_2= self.tri_cnn(input1)\\n    inp1_3= self.four_cnn(input1)\\n    concatenate1 = torch.cat((inp1_1,inp1_2,inp1_3),1)\\n\\n    inp2_1= self.bi_cnn(input2)\\n    inp2_2= self.tri_cnn(input2)\\n    inp3_3= self.four_cnn(input2)\\n    concatenate2 = torch.cat((inp1_1,inp1_2,inp1_3),1)\\n\\n    input1= torch.flatten(concatenate1,1)\\n    input2= torch.flatten(concatenate2,1)\\n\\n    absdiff= abs(input1 - input2)\\n    mulDifference= input1 * input2\\n\\n    concatenate = torch.cat((absdiff,mulDifference),1)\\n    output= self.Linear(concatenate)\\n\\n    return (output)'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"uRUv6bDcmYpE","colab_type":"text"},"source":["# Defining Loss"]},{"cell_type":"code","metadata":{"id":"yCG3Om6zxj-g","colab_type":"code","colab":{}},"source":["def _lossfunction(y_true,y_pred):\n","    \n","    #print(\"y_true.shape\",y_true.shape)\n","    #print(\"y_pred.shape\",y_pred.shape)\n","    ny_true = y_true[:,1] + 2*y_true[:,2] + 3*y_true[:,3] + 4*y_true[:,4] + 5*y_true[:,5]\n","    #print(ny_true)\n","    ny_pred = y_pred[:,1] + 2*y_pred[:,2] + 3*y_pred[:,3] + 4*y_pred[:,4] + 5*y_pred[:,5]\n","    #print(ny_pred)\n","    my_true = (ny_true.mean())\n","    #print(my_true)\n","    my_pred = (ny_pred.mean())\n","    #print(my_pred)\n","    var_true = (ny_true - my_true)**2\n","    var_pred = (ny_pred - my_pred)**2\n","    eps= 1e-14\n","    return -torch.sum((ny_true-my_true)*(ny_pred-my_pred),axis=-1) / (torch.sqrt(torch.sum(var_true,axis=-1)* torch.sum(var_pred,axis=-1)+eps))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6g9dYuH9x1Dx","colab_type":"text"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"QxQ4r7AzyWA-","colab_type":"text"},"source":["## Train setup"]},{"cell_type":"code","metadata":{"id":"QCWkAB75yili","colab_type":"code","colab":{}},"source":["def train_batch(net,trainload, opt,batch_size, device= 'cpu'):\n","  \n","  net.train().to(device)\n","  opt.zero_grad()\n","  \n","  \n","\n","  data= _sample_pairs(trainload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  true_output= (data['classes']).to(device)\n","  pred_output= net(input1,input2)\n","  loss= _lossfunction(true_output,pred_output)\n","\n","  #loss= criterion(pred_output,true_output)\n","  loss.backward()\n","  opt.step()\n","  #print(\"lossgf\",loss.item())\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUuqHGuH45FT","colab_type":"text"},"source":["## Validation Setup"]},{"cell_type":"code","metadata":{"id":"M6VfkAYo3RN5","colab_type":"code","colab":{}},"source":["def valid_batch(net,validation, opt,batch_size, device= 'cpu'):\n","  net.eval().to(device)\n","  \n","  data = _sample_pairs(validation,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  true_output= (data['classes']).to(device)\n","  pred_output= net(input1,input2)\n","  loss= _lossfunction(true_output,pred_output)\n","  #loss= criterion(pred_output,true_output)\n","  return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QWJNMId9pJIH","colab_type":"text"},"source":["# Full Training Setup"]},{"cell_type":"markdown","metadata":{"id":"b4p4zCidAmxm","colab_type":"text"},"source":["## Adam"]},{"cell_type":"code","metadata":{"id":"Y5WzVLt2pPkA","colab_type":"code","colab":{}},"source":["def train_setup_Adam(net,lr = 0.0001,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adam(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('fasttext_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'fasttext_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Me6XlCSZTmL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"ok","timestamp":1590789437472,"user_tz":-330,"elapsed":1632174,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"b973260a-5050-44ed-e3f2-af148c1888b4"},"source":["net= CNN_Model(2048)\n","train_setup_Adam(net, lr= 0.0005, epoch= 18)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 0 \tTraining Loss: -0.630394 \tValidation Loss: -0.716440\n","Validation loss decreased (inf --> -0.716440).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.817180 \tValidation Loss: -0.733017\n","Validation loss decreased (-0.716440 --> -0.733017).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.886970 \tValidation Loss: -0.776813\n","Validation loss decreased (-0.733017 --> -0.776813).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.910880 \tValidation Loss: -0.766688\n","Epoch: 4 \tTraining Loss: -0.912935 \tValidation Loss: -0.785050\n","Validation loss decreased (-0.776813 --> -0.785050).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.935186 \tValidation Loss: -0.786898\n","Validation loss decreased (-0.785050 --> -0.786898).  Saving model ...\n","Epoch: 6 \tTraining Loss: -0.952041 \tValidation Loss: -0.793033\n","Validation loss decreased (-0.786898 --> -0.793033).  Saving model ...\n","Epoch: 7 \tTraining Loss: -0.963446 \tValidation Loss: -0.796177\n","Validation loss decreased (-0.793033 --> -0.796177).  Saving model ...\n","Epoch: 8 \tTraining Loss: -0.972763 \tValidation Loss: -0.774985\n","Epoch: 9 \tTraining Loss: -0.969539 \tValidation Loss: -0.811008\n","Validation loss decreased (-0.796177 --> -0.811008).  Saving model ...\n","Epoch: 10 \tTraining Loss: -0.968205 \tValidation Loss: -0.798224\n","Epoch: 11 \tTraining Loss: -0.968279 \tValidation Loss: -0.788752\n","Epoch: 12 \tTraining Loss: -0.963446 \tValidation Loss: -0.769344\n","Epoch: 13 \tTraining Loss: -0.966876 \tValidation Loss: -0.793728\n","Epoch: 14 \tTraining Loss: -0.965826 \tValidation Loss: -0.761511\n","Epoch: 15 \tTraining Loss: -0.966724 \tValidation Loss: -0.777488\n","Epoch: 16 \tTraining Loss: -0.967387 \tValidation Loss: -0.776590\n","Epoch: 17 \tTraining Loss: -0.970452 \tValidation Loss: -0.784621\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lkNKMZ1IAsJ-","colab_type":"text"},"source":["## Adamax"]},{"cell_type":"code","metadata":{"id":"qG-HZks0AxQn","colab_type":"code","colab":{}},"source":["def train_setup_Adamax(net,lr = 0.0001,  batch_size = args.batch_size, momentum = 0.9, device = 'cpu',epoch= args.epochs):\n","  torch.autograd.set_detect_anomaly(True)\n","  valid_loss_min = np.Inf\n","  net.apply(weights_init)\n","  opt = optim.Adamax(net.parameters(), lr=lr)\n","  trainload= _load_data('sts-train.csv')\n","  validation= _load_data('sts-dev.csv')\n","  train_n_batch= int(len(trainload['labels'])/batch_size)\n","  train_loss_arr = np.zeros(train_n_batch+ 1)\n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  for epoch in range(epoch):\n","    if epoch != 0:\n","      net.load_state_dict(torch.load('fasttext_cross_epoch.pt'))\n","    for i in range(train_n_batch):\n","      train_loss_arr[i+1] = (train_loss_arr[i]*i + train_batch(net,trainload, opt, batch_size, device))/(i + 1)\n","      #print(\"train_loss_MSE\",train_loss_arr[i+1])\n","\n","     \n","   \n","    \n","      #if i%display_freq == display_freq-1:\n","      '''clear_output(wait=True)\n","      print('Iteration', i, 'Loss', loss_arr[i])\n","      plt.figure()\n","      plt.plot(train_loss_arr,'-*')\n","      plt.xlabel('Iteration')\n","      plt.ylabel('Loss')\n","      plt.show()\n","      print('\\n\\n')'''\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","    valid_n_batch = int(len(validation['labels'])/batch_size)\n","    valid_loss_arr = np.zeros(valid_n_batch + 1)\n","    for i in range(valid_n_batch):\n","      valid_loss_arr[i+1] = (valid_loss_arr[i]*i + valid_batch(net,validation, opt, batch_size, device))/(i + 1)\n","    \n","    '''mlflow.log_metric('train_loss_MSE', train_loss_arr[i+1])\n","    mlflow.log_metric('valid_loss_MSE', valid_loss_arr[i+1])'''\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss_arr[train_n_batch ], valid_loss_arr[valid_n_batch ]))\n","  \n","    if valid_loss_arr[valid_n_batch ] <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min, valid_loss_arr[valid_n_batch ]))\n","          torch.save(net.state_dict(), 'fasttext_cross_epoch.pt')\n","          valid_loss_min = valid_loss_arr[valid_n_batch ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3lxuhFAopUC","colab_type":"code","colab":{}},"source":["'''net= CNN_Model()\n","train_setup(net,device='cuda:0')'''\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dkld6lIWW8b","colab_type":"text"},"source":["# Evaluate"]},{"cell_type":"markdown","metadata":{"id":"2GQzXlEi-XHH","colab_type":"text"},"source":["## Evaluation Setup"]},{"cell_type":"code","metadata":{"id":"SkXPty0k-h9O","colab_type":"code","colab":{}},"source":["def eval_setup(net,batch_size = 1379, device = 'cpu'):\n","  \n","  net.load_state_dict(torch.load('fasttext_cross_epoch.pt'))\n","  net.eval().to(device)\n","  testload= _load_data('sts-test.csv')\n","  test_n_batch= int(len(testload['labels'])/batch_size)\n","  #print(len(testload['labels']))\n","  test_loss_arr = np.zeros(test_n_batch+ 1)\n","\n","\n","  data= _sample_pairs(testload,batch_size)\n","  input1= (torch.transpose(data['m0'],1,2)).to(device,dtype= torch.float32)\n","  input2= (torch.transpose(data['m1'],1,2)).to(device,dtype= torch.float32)\n","  pred_output= (net(input1,input2)).to('cpu')\n","  pred= pred_output.detach().numpy()\n","  prediction = np.dot(np.array(pred),np.arange(c['num_classes']))\n","  print('pred_shape',prediction.shape)\n","  goldlabels = data['labels']\n","  result=round((pearsonr(prediction, goldlabels)[0]),4)\n","  print(\"result\",result)\n","\n","  return result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDkaR6L8Sc6s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1590789548983,"user_tz":-330,"elapsed":6998,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"5f26f302-89e4-4567-bb5a-759e0e82bd37"},"source":["net=CNN_Model(2048)\n","eval_setup(net,device = 'cuda:0')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["pred_shape (1379,)\n","result 0.738\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.738"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"uACzDtuiU-_k","colab_type":"text"},"source":["# Hyper-parameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"PVpDkJCGA1h4","colab_type":"text"},"source":["## optim.Adam"]},{"cell_type":"code","metadata":{"id":"ZDX421f0VWRP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590787311337,"user_tz":-330,"elapsed":1700829,"user":{"displayName":"Rachna Soni","photoUrl":"","userId":"11374143874237782535"}},"outputId":"fe603209-caec-439f-9b01-c6a2c00c5c2a"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0005,0.00055]:\n","    \n","        for hidden_nodes in [1600,1800,1900]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adam(model,lr=learning_rate,device='cuda:0',epoch= args.epochs)\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'fasttext_cross_adam_model.pt')\n","            best_model_score= eval_score\n","\n","            \n","\n","          \n","\n","          \n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00050000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.693432 \tValidation Loss: -0.741591\n","Validation loss decreased (inf --> -0.741591).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.827671 \tValidation Loss: -0.767782\n","Validation loss decreased (-0.741591 --> -0.767782).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.884130 \tValidation Loss: -0.789634\n","Validation loss decreased (-0.767782 --> -0.789634).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.920197 \tValidation Loss: -0.799794\n","Validation loss decreased (-0.789634 --> -0.799794).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.946202 \tValidation Loss: -0.785072\n","Epoch: 5 \tTraining Loss: -0.943323 \tValidation Loss: -0.784964\n","pred_shape (1379,)\n","result 0.7396\n","best_model_score increased (-inf --> 0.739600).  Saving model ...\n","\n","LR = 0.00050000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.667266 \tValidation Loss: -0.715252\n","Validation loss decreased (inf --> -0.715252).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.819648 \tValidation Loss: -0.769886\n","Validation loss decreased (-0.715252 --> -0.769886).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.886855 \tValidation Loss: -0.766555\n","Epoch: 3 \tTraining Loss: -0.869574 \tValidation Loss: -0.762583\n","Epoch: 4 \tTraining Loss: -0.878529 \tValidation Loss: -0.768733\n","Epoch: 5 \tTraining Loss: -0.872820 \tValidation Loss: -0.764756\n","pred_shape (1379,)\n","result 0.6774\n","\n","LR = 0.00050000, Hidden nodes = 1900\n","\n","Epoch: 0 \tTraining Loss: -0.663667 \tValidation Loss: -0.709130\n","Validation loss decreased (inf --> -0.709130).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.819422 \tValidation Loss: -0.709637\n","Validation loss decreased (-0.709130 --> -0.709637).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.884678 \tValidation Loss: -0.756990\n","Validation loss decreased (-0.709637 --> -0.756990).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.917971 \tValidation Loss: -0.753601\n","Epoch: 4 \tTraining Loss: -0.909981 \tValidation Loss: -0.749950\n","Epoch: 5 \tTraining Loss: -0.909171 \tValidation Loss: -0.757721\n","Validation loss decreased (-0.756990 --> -0.757721).  Saving model ...\n","pred_shape (1379,)\n","result 0.731\n","\n","LR = 0.00055000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.662907 \tValidation Loss: -0.734745\n","Validation loss decreased (inf --> -0.734745).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.825405 \tValidation Loss: -0.772279\n","Validation loss decreased (-0.734745 --> -0.772279).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.876490 \tValidation Loss: -0.764898\n","Epoch: 3 \tTraining Loss: -0.878797 \tValidation Loss: -0.774326\n","Validation loss decreased (-0.772279 --> -0.774326).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.917587 \tValidation Loss: -0.779081\n","Validation loss decreased (-0.774326 --> -0.779081).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.940681 \tValidation Loss: -0.796314\n","Validation loss decreased (-0.779081 --> -0.796314).  Saving model ...\n","pred_shape (1379,)\n","result 0.7142\n","\n","LR = 0.00055000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.636419 \tValidation Loss: -0.732189\n","Validation loss decreased (inf --> -0.732189).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.811619 \tValidation Loss: -0.777086\n","Validation loss decreased (-0.732189 --> -0.777086).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.878334 \tValidation Loss: -0.764680\n","Epoch: 3 \tTraining Loss: -0.871698 \tValidation Loss: -0.774886\n","Epoch: 4 \tTraining Loss: -0.866540 \tValidation Loss: -0.767108\n","Epoch: 5 \tTraining Loss: -0.863704 \tValidation Loss: -0.789841\n","Validation loss decreased (-0.777086 --> -0.789841).  Saving model ...\n","pred_shape (1379,)\n","result 0.7319\n","\n","LR = 0.00055000, Hidden nodes = 1900\n","\n","Epoch: 0 \tTraining Loss: -0.666484 \tValidation Loss: -0.660265\n","Validation loss decreased (inf --> -0.660265).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.821404 \tValidation Loss: -0.743460\n","Validation loss decreased (-0.660265 --> -0.743460).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.870609 \tValidation Loss: -0.731801\n","Epoch: 3 \tTraining Loss: -0.875263 \tValidation Loss: -0.741008\n","Epoch: 4 \tTraining Loss: -0.860166 \tValidation Loss: -0.772421\n","Validation loss decreased (-0.743460 --> -0.772421).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.907065 \tValidation Loss: -0.775958\n","Validation loss decreased (-0.772421 --> -0.775958).  Saving model ...\n","pred_shape (1379,)\n","result 0.7089\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mRFsp-4kA7CN","colab_type":"text"},"source":["## optim.Adamax"]},{"cell_type":"code","metadata":{"id":"_GDwmpHvBG_c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590503262066,"user_tz":-330,"elapsed":30119,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"6e0b15a3-9361-4427-fdbf-4c6532088f0b"},"source":["best_model_score = -(np.Inf)\n","for learning_rate in [0.0005,0.00055]:\n","    \n","        for hidden_nodes in [1600,1800,1900]:\n","        \n","          expt_id = '%d_%d' % (int(learning_rate*100),  hidden_nodes)\n","          print('\\nLR = %.8f, Hidden nodes = %d\\n' % (learning_rate, hidden_nodes))\n","\n","          model = CNN_Model(hidden_nodes)\n","          train_setup_Adamax(model,lr=learning_rate,device='cuda:0',epoch= args.epochs)\n","\n","          eval_score=eval_setup(model,device = 'cuda:0')\n","\n","          if eval_score >= best_model_score :\n","            print('best_model_score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","            best_model_score, eval_score))\n","            torch.save(model.state_dict(), 'fasttext_cross_adamax_model.pt')\n","            best_model_score= eval_score\n","\n","            \n","\n","          \n","\n","          \n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","LR = 0.00050000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.669022 \tValidation Loss: -0.697163\n","Validation loss decreased (inf --> -0.697163).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.780866 \tValidation Loss: -0.725529\n","Validation loss decreased (-0.697163 --> -0.725529).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.844695 \tValidation Loss: -0.745111\n","Validation loss decreased (-0.725529 --> -0.745111).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.875266 \tValidation Loss: -0.749840\n","Validation loss decreased (-0.745111 --> -0.749840).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.905009 \tValidation Loss: -0.745165\n","Epoch: 5 \tTraining Loss: -0.904850 \tValidation Loss: -0.745224\n","pred_shape (1379,)\n","result 0.7345\n","best_model_score increased (-inf --> 0.734500).  Saving model ...\n","\n","LR = 0.00050000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.617768 \tValidation Loss: -0.708254\n","Validation loss decreased (inf --> -0.708254).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.792715 \tValidation Loss: -0.733059\n","Validation loss decreased (-0.708254 --> -0.733059).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.844311 \tValidation Loss: -0.758355\n","Validation loss decreased (-0.733059 --> -0.758355).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.871576 \tValidation Loss: -0.763274\n","Validation loss decreased (-0.758355 --> -0.763274).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.893664 \tValidation Loss: -0.782545\n","Validation loss decreased (-0.763274 --> -0.782545).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.921411 \tValidation Loss: -0.754720\n","pred_shape (1379,)\n","result 0.7111\n","\n","LR = 0.00050000, Hidden nodes = 1900\n","\n","Epoch: 0 \tTraining Loss: -0.646229 \tValidation Loss: -0.721028\n","Validation loss decreased (inf --> -0.721028).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.782039 \tValidation Loss: -0.724537\n","Validation loss decreased (-0.721028 --> -0.724537).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.835502 \tValidation Loss: -0.752969\n","Validation loss decreased (-0.724537 --> -0.752969).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.872786 \tValidation Loss: -0.761930\n","Validation loss decreased (-0.752969 --> -0.761930).  Saving model ...\n","Epoch: 4 \tTraining Loss: -0.909233 \tValidation Loss: -0.725603\n","Epoch: 5 \tTraining Loss: -0.901016 \tValidation Loss: -0.769866\n","Validation loss decreased (-0.761930 --> -0.769866).  Saving model ...\n","pred_shape (1379,)\n","result 0.7046\n","\n","LR = 0.00055000, Hidden nodes = 1600\n","\n","Epoch: 0 \tTraining Loss: -0.665489 \tValidation Loss: -0.678322\n","Validation loss decreased (inf --> -0.678322).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.781577 \tValidation Loss: -0.683961\n","Validation loss decreased (-0.678322 --> -0.683961).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.841248 \tValidation Loss: -0.753182\n","Validation loss decreased (-0.683961 --> -0.753182).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.887044 \tValidation Loss: -0.741809\n","Epoch: 4 \tTraining Loss: -0.878759 \tValidation Loss: -0.783185\n","Validation loss decreased (-0.753182 --> -0.783185).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.912173 \tValidation Loss: -0.761036\n","pred_shape (1379,)\n","result 0.6984\n","\n","LR = 0.00055000, Hidden nodes = 1800\n","\n","Epoch: 0 \tTraining Loss: -0.664510 \tValidation Loss: -0.697035\n","Validation loss decreased (inf --> -0.697035).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.796500 \tValidation Loss: -0.711127\n","Validation loss decreased (-0.697035 --> -0.711127).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.854546 \tValidation Loss: -0.747950\n","Validation loss decreased (-0.711127 --> -0.747950).  Saving model ...\n","Epoch: 3 \tTraining Loss: -0.889583 \tValidation Loss: -0.738578\n","Epoch: 4 \tTraining Loss: -0.884748 \tValidation Loss: -0.758232\n","Validation loss decreased (-0.747950 --> -0.758232).  Saving model ...\n","Epoch: 5 \tTraining Loss: -0.911910 \tValidation Loss: -0.750719\n","pred_shape (1379,)\n","result 0.709\n","\n","LR = 0.00055000, Hidden nodes = 1900\n","\n","Epoch: 0 \tTraining Loss: -0.667517 \tValidation Loss: -0.706329\n","Validation loss decreased (inf --> -0.706329).  Saving model ...\n","Epoch: 1 \tTraining Loss: -0.798781 \tValidation Loss: -0.767459\n","Validation loss decreased (-0.706329 --> -0.767459).  Saving model ...\n","Epoch: 2 \tTraining Loss: -0.849106 \tValidation Loss: -0.747292\n","Epoch: 3 \tTraining Loss: -0.834585 \tValidation Loss: -0.764962\n","Epoch: 4 \tTraining Loss: -0.850069 \tValidation Loss: -0.743745\n","Epoch: 5 \tTraining Loss: -0.848329 \tValidation Loss: -0.736808\n","pred_shape (1379,)\n","result 0.6932\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Js120I3bTMaB","colab_type":"text"},"source":["# Practice"]},{"cell_type":"code","metadata":{"id":"99F0SRW5dyY9","colab_type":"code","colab":{}},"source":["trainload= _load_data('sts-train.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNi4lsSTdkGL","colab_type":"code","colab":{}},"source":["data=_sample_pairs(trainload,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhA8win0gR0V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589382413225,"user_tz":-330,"elapsed":1485,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"15ee7d0c-693b-4bd4-f857-d14e5358ec66"},"source":["data_len= []\n","for i in data['s0']:\n","  data_len.append(len(i))\n","max_len_sent=max(data_len)\n","\n","rep= torch.zeros(max_len_sent, 2 ,300)\n","rep.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([11, 2, 300])"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"u2UgwP2Zk23J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1589383031128,"user_tz":-330,"elapsed":1647,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"83d2fa18-b2ce-4912-8f4d-0953eedf9be6"},"source":["(data['s0'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['brown',\n","  'and',\n","  'white',\n","  'cow',\n","  'standing',\n","  'in',\n","  'grass',\n","  'at',\n","  'side',\n","  'of',\n","  'road'],\n"," ['boy', 'scouts', 'delay', 'decision', 'on', 'admitting', 'gays']]"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"1aknSKgzjzY1","colab_type":"code","colab":{}},"source":["temp=[]\n","rep[0][0]=torch.tensor(indextovector[wordtoindex['brown']])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63gsjzqaoYLv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589383373257,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"ec8900d0-ef3d-46a2-e169-ac80a390c947"},"source":["rep[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3741, -0.0763,  0.1093,  0.1866,  0.0299,  0.1827, -0.6320,  0.1331,\n","         -0.1290,  0.6034, -0.6804, -0.1422, -0.1336, -0.6594,  0.0524,  0.1674,\n","          0.6392,  1.7680,  0.3462, -0.6248, -0.1287, -0.1970, -0.3745,  0.3306,\n","          0.0468, -0.6535, -0.5614,  0.2274,  0.2292, -0.4158, -0.1677,  0.3354,\n","          0.0972, -0.4670, -0.0269, -0.0677, -0.1921, -0.1337,  0.0163, -0.2083,\n","          0.6486, -0.1102, -0.0510,  0.0722,  0.1877,  0.2711, -0.3142,  0.1832,\n","          0.3915, -0.2255, -0.3819,  0.3306, -0.0899, -0.3763,  0.0480, -0.2050,\n","         -0.5489,  0.3044, -0.1887, -0.3034, -0.1157, -0.3487,  0.2800,  0.0501,\n","         -0.2814, -0.2335, -0.3683, -0.1204, -0.2833,  0.1857,  0.1036,  0.2531,\n","         -0.0340,  0.1051,  0.1214, -0.1630, -0.3318,  0.1731,  0.1076, -0.9936,\n","         -0.1171,  0.4223,  0.1512,  0.3106,  0.2674, -0.4927,  1.8049,  1.0738,\n","          0.3442,  0.1128, -0.1049,  0.3694,  0.4082, -0.4037,  0.3233, -0.0939,\n","         -0.0290,  0.3825, -0.3389, -0.6132,  0.8434,  0.1593, -0.1174,  0.0806,\n","         -0.2899, -0.4439, -0.1183,  0.1658,  0.1525,  0.2386, -0.3295, -0.3199,\n","         -0.3118, -0.1919,  0.2847,  0.2568,  0.4379, -0.0233,  0.1891, -0.0850,\n","         -0.1164, -0.1102, -0.0595,  0.1155,  0.2070,  0.5587,  0.8177, -0.2563,\n","         -0.0181, -0.0410, -0.2660, -0.4568, -0.0374,  0.3325,  0.1414, -0.0630,\n","         -0.0866, -0.3327, -0.0092, -0.0355, -2.8871,  0.2453,  0.2974,  0.6599,\n","         -0.0134, -0.1089,  0.1155,  0.0526, -0.0430,  0.2285,  0.4021, -0.4891,\n","          0.0441, -0.1368, -0.7181,  0.2526, -0.5788, -0.4807, -0.2409,  0.0427,\n","         -0.0946, -0.3034, -0.3197,  0.3554,  0.0629, -0.2043, -0.2978, -0.1545,\n","          0.2443,  0.0489, -0.0773,  0.3643, -0.1513, -0.4539, -0.3431,  0.1069,\n","          0.4292, -0.0260,  0.4825,  0.3361, -0.5032,  0.2241, -0.2737, -0.4904,\n","         -0.1173,  1.0537, -0.2023,  0.0490, -0.1223,  0.1100,  0.4155, -0.1183,\n","          0.1148, -0.2663,  0.2908,  0.2541,  0.3535,  0.3172, -0.1517, -0.5050,\n","         -0.2202,  0.1163, -0.2513,  0.2280,  0.2628,  0.2107,  0.0236,  0.0769,\n","         -0.1486,  0.0720,  0.3767,  0.3536, -0.3933, -0.1338,  0.5593,  0.0337,\n","         -0.4850, -0.3276,  0.2587,  0.4876, -0.2649,  0.0329, -0.0838, -0.0638,\n","          0.1076, -0.1855, -0.0523,  0.0767, -0.2148,  0.9646, -0.2479, -0.1211,\n","          0.0394,  0.4471, -0.1380, -0.0278, -0.4937, -0.5163,  0.3386,  0.5921,\n","         -0.2013, -0.0832, -0.3758, -0.2127, -0.3856,  0.2259, -0.3722, -0.1872,\n","         -0.6052, -0.1279,  0.2344, -0.4222, -0.2354,  0.2968,  0.0678,  0.0780,\n","          0.3195, -0.0348,  0.2981,  0.4400,  0.1174,  0.0550,  0.2368,  0.8982,\n","         -0.4097,  0.0752, -0.1103, -0.4099, -0.9572,  0.5275, -0.0427,  0.2662,\n","          0.3053, -0.5190, -0.4604, -0.0938,  0.1301,  0.0193,  0.0102,  0.0076,\n","          0.2955,  0.2316, -0.0349, -0.1169, -0.3273,  0.2049,  0.4750,  0.5131,\n","         -0.1458, -0.1851, -0.0154,  0.3929, -0.0348, -0.7203, -0.3653,  0.7405,\n","          0.1084, -0.3658, -0.2882,  0.1146],\n","        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.0000]])"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"A2XUoGKXm6bu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"ok","timestamp":1589383146976,"user_tz":-330,"elapsed":1264,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"492d4acd-34f3-4ba7-e431-75db36c221ee"},"source":["data['m0'][0][11]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"VB2STaT2SzyW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589370183806,"user_tz":-330,"elapsed":1311,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"b337bbc4-9adc-4234-c976-8006afce7033"},"source":["m = nn.MaxPool1d(1)\n","input = torch.randn(6, 5)\n","input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 5])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"xTHe3bx83kR6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1589370748582,"user_tz":-330,"elapsed":1446,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"035245a9-3273-4e41-ead4-fde0c6edb090"},"source":["input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7378,  1.7368,  0.0198,  0.8431,  0.9046],\n","        [-1.5884, -1.1110,  0.8694,  0.3053,  0.3550],\n","        [ 0.1539, -0.4941, -0.0704,  1.3168,  0.9116],\n","        [ 1.2474,  0.6942,  0.1928, -0.5697, -0.8765],\n","        [-0.5326, -0.9174,  0.2422, -0.1825,  0.2426],\n","        [-1.5224, -1.7681, -1.8564, -1.0241, -1.3065]])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"YytbQVTy2LTs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1589371055905,"user_tz":-330,"elapsed":1936,"user":{"displayName":"Nyg line","photoUrl":"","userId":"16627810253525004666"}},"outputId":"d23b8943-a917-4490-8178-78e3b4bfa8f8"},"source":["input.to(torch.float32)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.7378,  1.7368,  0.0198,  0.8431,  0.9046],\n","        [-1.5884, -1.1110,  0.8694,  0.3053,  0.3550],\n","        [ 0.1539, -0.4941, -0.0704,  1.3168,  0.9116],\n","        [ 1.2474,  0.6942,  0.1928, -0.5697, -0.8765],\n","        [-0.5326, -0.9174,  0.2422, -0.1825,  0.2426],\n","        [-1.5224, -1.7681, -1.8564, -1.0241, -1.3065]])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"c4ifcUQ-rE-z","colab_type":"code","colab":{}},"source":["output = m(input)\n","output.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtNIYGWArTMW","colab_type":"code","colab":{}},"source":["out= torch.flatten(output, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KNDFi6QhK3V","colab_type":"code","colab":{}},"source":["out.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa8AVUN1TFka","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vo28Dj7EhNUl","colab_type":"code","colab":{}},"source":["a=torch.tensor(np.array([1,2,3]))\n","b=torch.tensor(np.array([4,5,6]))\n","a*b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec595DaW2i6W","colab_type":"code","colab":{}},"source":["c=abs(a-b)\n","\n","c"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcJ9pxdi3tIc","colab_type":"code","colab":{}},"source":["import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-r14qRP595v","colab_type":"code","colab":{}},"source":["torch.cat((a,b),1).shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-F3HFrZ_ASV5","colab_type":"code","colab":{}},"source":["c= torch.randn(2, 5)\n","d= torch.randn(2,5)\n","e= torch.cat((c,d),1)\n","e.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sk0E5F22DpCX","colab_type":"code","colab":{}},"source":["(c-d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwGrQJ4TENvS","colab_type":"code","colab":{}},"source":["-1.5705-1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9NMh84DEcqd","colab_type":"code","colab":{}},"source":["(c*d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-V2_tVDEsj4","colab_type":"code","colab":{}},"source":["-1.5705*1.4329"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSrDjaRbEw58","colab_type":"code","colab":{}},"source":["-0.6561*-0.2841"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3FunLaWZdOb","colab_type":"code","colab":{}},"source":["'''blocksize=2\n","k= ((li[block:block+blocksize], block) for block in range(0,len(li),blocksize))\n","for i,j in k:\n","    print(i,j)'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKmW1OrSE5Fi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIw11E00ZdOp","colab_type":"code","colab":{}},"source":["'''def worker(args):\n","        print(args[0])\n","        print(args[1])'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFRV8fpxq6_H","colab_type":"code","colab":{}},"source":["p= np.random.randn(1,5)\n","p"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIxJzwg4rFr7","colab_type":"code","colab":{}},"source":["plt.plot(p,'-*')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uA4LFKOErSjU","colab_type":"code","colab":{}},"source":["p[1:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2pIVqMUrnEk","colab_type":"code","colab":{}},"source":["d={'a':[1],'b':[2],'c':[3]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utzQBcocDKgw","colab_type":"code","colab":{}},"source":["d1={}\n","d1= d.keys\n","d1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StnIcTfHDNOr","colab_type":"code","colab":{}},"source":["d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ILOBRLaDUoR","colab_type":"code","colab":{}},"source":["d2={}\n","d3=d2.fromkeys(d.keys(),[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYqLiw7OFti_","colab_type":"code","colab":{}},"source":["d3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDD4QynwF1mT","colab_type":"code","colab":{}},"source":["d3['b'].append(909)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gW5xs9TOF2gQ","colab_type":"code","colab":{}},"source":["d4 = copy.deepcopy(d3)\n","d4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzfN1pbYF3t4","colab_type":"code","colab":{}},"source":["d4['a'].append(78)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f8gYRILJJVMk","colab_type":"code","colab":{}},"source":["d4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATDR9bO1JZYi","colab_type":"code","colab":{}},"source":["d['a'].append(909)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6_Vlp8KJmtO","colab_type":"code","colab":{}},"source":["d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2ZuH1ZyJt7W","colab_type":"code","colab":{}},"source":["d5={}\n","for i in d.keys():\n","  d5[i]=[]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ownN6bJmJ2-e","colab_type":"code","colab":{}},"source":["d5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUD2KxkvJ8Ap","colab_type":"code","colab":{}},"source":["\n","d5['a'].append(78)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vCw3STpKA01","colab_type":"code","colab":{}},"source":["d5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdtczaL6KBuo","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}